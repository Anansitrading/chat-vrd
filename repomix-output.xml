This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.marscode/
  deviceInfo.json
api/
  perplexity.js
components/
  icons/
    AttachmentIcon.tsx
    FileIcons.tsx
    SendIcon.tsx
    SpeakerIcons.tsx
  ChatHistory.tsx
  ChatInput.tsx
  ChatMessage.tsx
  Header.tsx
hooks/
  useTextToSpeech.ts
public/
  audio-processor-worklet.js
services/
  geminiService.ts
src/
  components/
    icons/
      AttachmentIcon.tsx
      FileIcons.tsx
      MicrophoneIcon.tsx
      SendIcon.tsx
      SpeakerIcons.tsx
    AuthGate.tsx
    ChatHistory.tsx
    ChatInput.tsx
    ChatMessage.tsx
    ChatSidebar.tsx
    ChatWindow.tsx
    CircularProgress.tsx
    DocumentExporter.tsx
    DocumentsSidebar.tsx
    EnhancedChatMessage.tsx
    GeminiVoiceChat.tsx
    Header.tsx
    MCQTestDemo.tsx
    ModelSelector.tsx
    OptionGroup.tsx
    ProgressIndicator.tsx
    SettingsTab.tsx
    SystemPromptEditor.tsx
    Toast.tsx
  contexts/
    ChatContext.tsx
    SettingsContext.tsx
  hooks/
    useGeminiLive.ts
    useProgress.ts
    useSpeechToText.ts
    useTextToSpeech.ts
  services/
    geminiService.ts
    perplexityService.ts
    supabaseService.ts
  types/
    settings.ts
    speech.d.ts
  utils/
    documentStorage.ts
    messageClassifier.ts
    settingsStorage.ts
    vrdFormatter.ts
  App.tsx
  constants.ts
  index.tsx
  styles.css
  types.ts
.env.local.example
.gitignore
constants.ts
DEPLOY_GUIDE.md
DESKTOP_USAGE.md
ENHANCED_MCQ_README.md
index.html
kijko-control.sh
kill-kijko.sh
launch-kijko-absolute.sh
launch-kijko.py
launch-kijko.sh
metadata.json
package.json
README.md
repomix-output.txt
tsconfig.json
types.ts
vercel.json
vite.config.ts
WARP.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="public/audio-processor-worklet.js">
// AudioWorklet processor for real-time PCM audio processing
class AudioProcessor extends AudioWorkletProcessor {
  constructor() {
    super();
    this.bufferSize = 1024; // Reduced for lower latency
    this.sampleRate = 16000;
    this.buffer = new Float32Array(this.bufferSize);
    this.bufferIndex = 0;
  }

  process(inputs, outputs, parameters) {
    const input = inputs[0];
    
    if (input.length > 0) {
      const inputChannel = input[0];
      
      for (let i = 0; i < inputChannel.length; i++) {
        this.buffer[this.bufferIndex] = inputChannel[i];
        this.bufferIndex++;
        
        if (this.bufferIndex >= this.bufferSize) {
          // Convert float32 to 16-bit PCM
          const pcmBuffer = new Int16Array(this.bufferSize);
          for (let j = 0; j < this.bufferSize; j++) {
            pcmBuffer[j] = Math.max(-32768, Math.min(32767, this.buffer[j] * 32768));
          }
          
          // Send PCM data to main thread
          this.port.postMessage({
            type: 'audio',
            data: pcmBuffer
          });
          
          this.bufferIndex = 0;
        }
      }
    }
    
    return true;
  }
}

registerProcessor('audio-processor', AudioProcessor);
</file>

<file path="src/hooks/useGeminiLive.ts">
import { useState, useRef, useEffect, useCallback } from 'react';

// Gemini Live API WebSocket endpoint
const GEMINI_LIVE_WS_URL = 'wss://liveapi.ai.google.com/v1alpha/audio-stream';

// Types for Gemini Live API messages
interface GeminiLiveSetup {
  model: string;
  generationConfig?: {
    temperature?: number;
    topK?: number;
    topP?: number;
    maxOutputTokens?: number;
  };
  systemInstruction?: {
    parts: Array<{
      text: string;
    }>;
  };
  tools?: Array<{
    functionDeclarations?: any[];
    googleSearch?: {};
  }>;
}

interface GeminiLiveClientContent {
  turns?: Array<{
    role: string;
    parts: Array<{
      text?: string;
    }>;
  }>;
  turnComplete?: boolean;
}

interface GeminiLiveRealtimeInput {
  mediaChunks?: Array<{
    mime_type: string;
    data: string;
  }>;
}

interface GeminiLiveMessage {
  setup?: GeminiLiveSetup;
  clientContent?: GeminiLiveClientContent;
  realtimeInput?: GeminiLiveRealtimeInput;
  toolResponse?: any;
}

interface GeminiLiveServerMessage {
  setupComplete?: boolean;
  serverContent?: {
    modelTurn?: {
      parts?: Array<{
        text?: string;
      }>;
    };
    turnComplete?: boolean;
  };
  toolCall?: any;
  audio?: string; // Base64 encoded PCM audio
}

export interface GeminiLiveState {
  isConnected: boolean;
  isListening: boolean;
  isSpeaking: boolean;
  isProcessing: boolean;
  interimTranscript: string;
  finalTranscript: string;
  llmResponse: string;
  error: string | null;
}

export interface GeminiLiveConfig {
  model?: string;
  temperature?: number;
  systemPrompt?: string;
  onTranscriptUpdate?: (interim: string, final: string) => void;
  onResponseUpdate?: (response: string) => void;
  onAudioReceived?: (audioData: string) => void;
  onError?: (error: string) => void;
}

export const useGeminiLive = (apiKey: string, config: GeminiLiveConfig = {}) => {
  const [state, setState] = useState<GeminiLiveState>({
    isConnected: false,
    isListening: false,
    isSpeaking: false,
    isProcessing: false,
    interimTranscript: '',
    finalTranscript: '',
    llmResponse: '',
    error: null,
  });

  const wsRef = useRef<WebSocket | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const audioWorkletRef = useRef<AudioWorkletNode | null>(null);
  const reconnectTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const reconnectAttempts = useRef(0);
  const maxReconnectAttempts = 3;

  // Initialize audio context for audio playback
  const initializeAudioContext = useCallback(async () => {
    if (!audioContextRef.current) {
      audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
      if (audioContextRef.current.state === 'suspended') {
        await audioContextRef.current.resume();
      }
    }
  }, []);

  // Play received audio data
  const playAudioData = useCallback(async (base64Audio: string) => {
    try {
      await initializeAudioContext();
      if (!audioContextRef.current) return;

      // Decode base64 to PCM audio buffer
      const binaryString = atob(base64Audio);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }

      // Create audio buffer from PCM data
      // Assuming 16kHz, 16-bit, mono PCM
      const sampleRate = 16000;
      const numSamples = bytes.length / 2;
      const audioBuffer = audioContextRef.current.createBuffer(1, numSamples, sampleRate);
      const channelData = audioBuffer.getChannelData(0);

      // Convert 16-bit PCM to float32 array
      for (let i = 0; i < numSamples; i++) {
        const sample = (bytes[i * 2 + 1] << 8) | bytes[i * 2];
        channelData[i] = sample < 32768 ? sample / 32768 : (sample - 65536) / 32768;
      }

      // Play the audio
      const source = audioContextRef.current.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContextRef.current.destination);
      source.start();

      setState(prev => ({ ...prev, isSpeaking: true }));
      source.onended = () => {
        setState(prev => ({ ...prev, isSpeaking: false }));
      };

    } catch (error) {
      console.error('Error playing audio:', error);
    }
  }, [initializeAudioContext]);

  // Initialize audio capture for microphone input
  const initializeAudioCapture = useCallback(async () => {
    console.log('[Gemini Live] 🎤 Initializing audio capture...');
    try {
      await initializeAudioContext();
      if (!audioContextRef.current) {
        console.error('[Gemini Live] Audio context not available');
        return false;
      }

      console.log('[Gemini Live] Requesting microphone access...');
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        }
      });

      console.log('[Gemini Live] ✅ Microphone access granted');
      mediaStreamRef.current = stream;

      // Create AudioWorklet for real-time PCM processing
      let sequenceId = 1;
      try {
        await audioContextRef.current.audioWorklet.addModule('/audio-processor-worklet.js');
        const audioWorklet = new AudioWorkletNode(audioContextRef.current, 'audio-processor');
        
        audioWorklet.port.onmessage = (event) => {
          if (event.data.type === 'audio' && wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
            const pcmData = event.data.data as Int16Array;
            const audioBuffer = new Uint8Array(pcmData.buffer, pcmData.byteOffset, pcmData.byteLength);
            const base64 = btoa(String.fromCharCode(...audioBuffer));
            
            const message = {
              type: 'audio',
              data: base64,
              mime_type: 'audio/raw',
              sequence_id: sequenceId++,
            };
            wsRef.current.send(JSON.stringify(message));
          }
        };

        const source = audioContextRef.current.createMediaStreamSource(stream);
        source.connect(audioWorklet);
        audioWorkletRef.current = audioWorklet;

        return true;
      } catch (workletError) {
        console.warn('AudioWorklet not supported, falling back to ScriptProcessorNode');
        
        // Fallback to ScriptProcessorNode for older browsers
        const bufferSize = 1024; // Reduced buffer size for lower latency
        const processor = audioContextRef.current.createScriptProcessor(bufferSize, 1, 1);
        let fallbackSequenceId = 1;
        
        processor.onaudioprocess = (event) => {
          if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
            const inputBuffer = event.inputBuffer;
            const inputData = inputBuffer.getChannelData(0);
            
            // Convert float32 to 16-bit PCM
            const pcmData = new Int16Array(inputData.length);
            for (let i = 0; i < inputData.length; i++) {
              pcmData[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
            }
            
            const audioBuffer = new Uint8Array(pcmData.buffer, pcmData.byteOffset, pcmData.byteLength);
            const base64 = btoa(String.fromCharCode(...audioBuffer));
            
            const message = {
              type: 'audio',
              data: base64,
              mime_type: 'audio/raw',
              sequence_id: fallbackSequenceId++,
            };
            wsRef.current.send(JSON.stringify(message));
          }
        };

        const source = audioContextRef.current.createMediaStreamSource(stream);
        source.connect(processor);
        processor.connect(audioContextRef.current.destination);

        return true;
      }
    } catch (error) {
      console.error('[Gemini Live] ❌ Error initializing audio capture:', error);
      const errorMessage = error instanceof Error ? error.message : 'Failed to access microphone';
      console.error('[Gemini Live] Error details:', errorMessage);
      setState(prev => ({ ...prev, error: `Microphone access denied: ${errorMessage}` }));
      return false;
    }
  }, [initializeAudioContext]);

  // Connect to Gemini Live WebSocket
  const connect = useCallback(async () => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      console.log('[Gemini Live] Already connected');
      return;
    }

    console.log('[Gemini Live] Attempting to connect...');
    console.log('[Gemini Live] API Key available:', !!apiKey);
    console.log('[Gemini Live] Config:', { model: config.model, hasSystemPrompt: !!config.systemPrompt });

    if (!apiKey) {
      const error = 'No API key provided. Please set VITE_GEMINI_API_KEY environment variable.';
      console.error('[Gemini Live]', error);
      setState(prev => ({ ...prev, error, isProcessing: false }));
      return;
    }

    try {
      setState(prev => ({ ...prev, error: null, isProcessing: true }));
      
      const wsUrl = `${GEMINI_LIVE_WS_URL}?key=${apiKey}`;
      console.log('[Gemini Live] WebSocket URL (without key):', GEMINI_LIVE_WS_URL);
      const ws = new WebSocket(wsUrl);
      wsRef.current = ws;

      ws.onopen = () => {
        console.log('[Gemini Live] ✅ WebSocket connected successfully');
        setState(prev => ({ ...prev, isConnected: true, isProcessing: false }));
        reconnectAttempts.current = 0;

        // Send initial connect message for native audio
        const connectMessage = {
          type: 'connect',
          model: 'gemini-live-2.5-flash-preview-native-audio-09-2025',
          config: {
            temperature: config.temperature ?? 1.0,
            max_output_tokens: 8192,
          },
          ...(config.systemPrompt
            ? { system_instruction: { parts: [{ text: config.systemPrompt }] } }
            : {}),
        };
        console.log('[Gemini Live] 📤 Sending connect message:', connectMessage);
        ws.send(JSON.stringify(connectMessage));
      };

      ws.onmessage = (event) => {
        try {
          const response = JSON.parse(event.data);
          console.log('[Gemini Live] 📥 Received message:', response);

          switch (response.type) {
            case 'connected':
              console.log('[Gemini Live] ⚙️ Connection established!');
              break;
              
            case 'transcript':
              console.log('[Gemini Live] 📝 Transcript:', response.transcript);
              setState(prev => ({ 
                ...prev, 
                interimTranscript: response.transcript,
                finalTranscript: response.is_final ? response.transcript : prev.finalTranscript
              }));
              config.onTranscriptUpdate?.(response.transcript, response.is_final ? response.transcript : '');
              break;
              
            case 'response':
              if (response.data && response.mime_type === 'audio/raw') {
                console.log('[Gemini Live] 🔊 Audio response received');
                // Convert base64 to audio data
                const audioData = Uint8Array.from(atob(response.data), c => c.charCodeAt(0));
                // Re-encode for our playback function which expects base64
                playAudioData(btoa(String.fromCharCode(...audioData)));
                config.onAudioReceived?.(response.data);
              }
              if (response.text) {
                console.log('[Gemini Live] 💬 Text response:', response.text);
                setState(prev => ({ ...prev, llmResponse: prev.llmResponse + response.text }));
                config.onResponseUpdate?.(response.text);
              }
              break;
              
            case 'done':
              console.log('[Gemini Live] ✅ Response complete');
              setState(prev => ({ ...prev, isProcessing: false }));
              break;
              
            case 'error':
              console.error('[Gemini Live] ❌ Error:', response.error);
              setState(prev => ({ ...prev, error: response.error, isProcessing: false }));
              config.onError?.(response.error);
              break;
              
            default:
              console.log('[Gemini Live] Unknown message type:', response);
              break;
          }
        } catch (error) {
          console.error('[Gemini Live] ❌ Error parsing WebSocket message:', error);
          console.error('[Gemini Live] Raw message data:', event.data);
        }
      };

      ws.onclose = (event) => {
        console.log('[Gemini Live] 🔌 WebSocket closed:', { code: event.code, reason: event.reason, wasClean: event.wasClean });
        setState(prev => ({ ...prev, isConnected: false, isListening: false }));
        
        // Attempt reconnection if not intentionally closed
        if (event.code !== 1000 && reconnectAttempts.current < maxReconnectAttempts) {
          reconnectAttempts.current++;
          reconnectTimeoutRef.current = setTimeout(() => {
            console.log(`Reconnecting... attempt ${reconnectAttempts.current}`);
            connect();
          }, 2000 * reconnectAttempts.current);
        }
      };

      ws.onerror = (error) => {
        console.error('Gemini Live WebSocket error:', error);
        setState(prev => ({ ...prev, error: 'WebSocket connection error', isProcessing: false }));
        config.onError?.('WebSocket connection error');
      };

    } catch (error) {
      console.error('Error connecting to Gemini Live:', error);
      setState(prev => ({ ...prev, error: 'Failed to connect to Gemini Live', isProcessing: false }));
      config.onError?.('Failed to connect to Gemini Live');
    }
  }, [apiKey, config, playAudioData]);

  // Start listening (audio capture)
  const startListening = useCallback(async () => {
    if (state.isListening) return;

    const audioInitialized = await initializeAudioCapture();
    if (!audioInitialized) return;

    await connect();
    
    setState(prev => ({ 
      ...prev, 
      isListening: true, 
      interimTranscript: '', 
      finalTranscript: '', 
      llmResponse: '' 
    }));
  }, [state.isListening, initializeAudioCapture, connect]);

  // Stop listening
  const stopListening = useCallback(() => {
    setState(prev => ({ ...prev, isListening: false }));
    
    if (audioWorkletRef.current) {
      audioWorkletRef.current.disconnect();
      audioWorkletRef.current = null;
    }
    
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
    }
  }, []);

  // Send text message
  const sendText = useCallback((text: string) => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      const message: GeminiLiveMessage = {
        clientContent: {
          turns: [{
            role: 'user',
            parts: [{ text }]
          }],
          turnComplete: true
        }
      };
      wsRef.current.send(JSON.stringify(message));
      setState(prev => ({ ...prev, isProcessing: true }));
    }
  }, []);

  // Disconnect
  const disconnect = useCallback(() => {
    if (reconnectTimeoutRef.current) {
      clearTimeout(reconnectTimeoutRef.current);
    }
    
    stopListening();
    
    if (wsRef.current) {
      wsRef.current.close(1000, 'Client disconnect');
      wsRef.current = null;
    }
    
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    
    setState(prev => ({ 
      ...prev, 
      isConnected: false, 
      isListening: false, 
      isProcessing: false,
      error: null
    }));
  }, [stopListening]);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      disconnect();
    };
  }, [disconnect]);

  return {
    ...state,
    connect,
    disconnect,
    startListening,
    stopListening,
    sendText,
    isSupported: !!navigator.mediaDevices?.getUserMedia && !!window.WebSocket,
  };
};
</file>

<file path="repomix-output.txt">
This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.marscode/
  deviceInfo.json
api/
  perplexity.js
components/
  icons/
    AttachmentIcon.tsx
    FileIcons.tsx
    SendIcon.tsx
    SpeakerIcons.tsx
  ChatHistory.tsx
  ChatInput.tsx
  ChatMessage.tsx
  Header.tsx
hooks/
  useTextToSpeech.ts
services/
  geminiService.ts
src/
  components/
    icons/
      AttachmentIcon.tsx
      FileIcons.tsx
      MicrophoneIcon.tsx
      SendIcon.tsx
      SpeakerIcons.tsx
    AuthGate.tsx
    ChatHistory.tsx
    ChatInput.tsx
    ChatMessage.tsx
    ChatSidebar.tsx
    ChatWindow.tsx
    CircularProgress.tsx
    DocumentExporter.tsx
    DocumentsSidebar.tsx
    EnhancedChatMessage.tsx
    GeminiVoiceChat.tsx
    Header.tsx
    MCQTestDemo.tsx
    ModelSelector.tsx
    OptionGroup.tsx
    ProgressIndicator.tsx
    SettingsTab.tsx
    SystemPromptEditor.tsx
    Toast.tsx
  contexts/
    ChatContext.tsx
    SettingsContext.tsx
  hooks/
    useProgress.ts
    useSpeechToText.ts
    useTextToSpeech.ts
  services/
    geminiService.ts
    perplexityService.ts
    supabaseService.ts
  types/
    settings.ts
    speech.d.ts
  utils/
    documentStorage.ts
    messageClassifier.ts
    settingsStorage.ts
    vrdFormatter.ts
  App.tsx
  constants.ts
  index.tsx
  styles.css
  types.ts
.env.local.example
.gitignore
constants.ts
DEPLOY_GUIDE.md
DESKTOP_USAGE.md
ENHANCED_MCQ_README.md
index.html
kijko-control.sh
kill-kijko.sh
launch-kijko-absolute.sh
launch-kijko.py
launch-kijko.sh
metadata.json
package.json
README.md
tsconfig.json
types.ts
vercel.json
vite.config.ts
WARP.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".marscode/deviceInfo.json">
{
  "deviceId": "5fd7f9701c30b68fef31897398af3c0f0cf69ce2d5eb23edb49c3d8a586901b9"
}
</file>

<file path="components/icons/AttachmentIcon.tsx">
import React from 'react';

export const AttachmentIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    viewBox="0 0 24 24"
    fill="currentColor"
    {...props}
  >
    <path
      fillRule="evenodd"
      d="M18.97 3.659a2.25 2.25 0 00-3.182 0l-10.5 10.5a.75.75 0 001.06 1.061l10.5-10.5a.75.75 0 011.06 0a.75.75 0 010 1.06l-8.25 8.25a2.25 2.25 0 01-3.182-3.182l5.25-5.25a.75.75 0 00-1.06-1.06l-5.25 5.25a3.75 3.75 0 105.3 5.3l8.25-8.25a2.25 2.25 0 000-3.182z"
      clipRule="evenodd"
    />
  </svg>
);
</file>

<file path="components/icons/FileIcons.tsx">
import React from 'react';

export const FileIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    viewBox="0 0 24 24"
    fill="currentColor"
    {...props}
  >
    <path
      fillRule="evenodd"
      d="M5.625 1.5c-1.036 0-1.875.84-1.875 1.875v17.25c0 1.035.84 1.875 1.875 1.875h12.75c1.035 0 1.875-.84 1.875-1.875V12.75A3.75 3.75 0 0016.5 9h-1.875a.375.375 0 01-.375-.375V6.75A3.75 3.75 0 009 3H5.625zM12.75 12.75a.75.75 0 00-1.5 0v2.25H9a.75.75 0 000 1.5h2.25v2.25a.75.75 0 001.5 0v-2.25H15a.75.75 0 000-1.5h-2.25V12.75z"
      clipRule="evenodd"
    />
    <path d="M14.25 6.75a2.25 2.25 0 00-2.25-2.25H5.625a.375.375 0 00-.375.375v17.25c0 .207.168.375.375.375h12.75a.375.375 0 00.375-.375V12.75a2.25 2.25 0 00-2.25-2.25h-1.875a1.875 1.875 0 01-1.875-1.875V6.75z" />
  </svg>
);


export const XCircleIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg 
    xmlns="http://www.w3.org/2000/svg" 
    viewBox="0 0 20 20" 
    fill="currentColor" 
    {...props}
  >
    <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8.28 7.22a.75.75 0 00-1.06 1.06L8.94 10l-1.72 1.72a.75.75 0 101.06 1.06L10 11.06l1.72 1.72a.75.75 0 101.06-1.06L11.06 10l1.72-1.72a.75.75 0 00-1.06-1.06L10 8.94 8.28 7.22z" clipRule="evenodd" />
  </svg>
);
</file>

<file path="components/icons/SendIcon.tsx">
import React from 'react';

export const SendIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    viewBox="0 0 24 24"
    fill="currentColor"
    {...props}
  >
    <path d="M3.478 2.405a.75.75 0 00-.926.94l2.432 7.905H13.5a.75.75 0 010 1.5H4.984l-2.432 7.905a.75.75 0 00.926.94 60.519 60.519 0 0018.445-8.986.75.75 0 000-1.218A60.517 60.517 0 003.478 2.405z" />
  </svg>
);
</file>

<file path="components/icons/SpeakerIcons.tsx">
import React from 'react';

export const SpeakerOnIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" {...props}>
    <path d="M13.5 4.06c0-1.336-1.616-2.005-2.56-1.06l-4.5 4.5H4.508c-1.141 0-2.318.664-2.66 1.905A9.76 9.76 0 001.5 12c0 .898.121 1.768.35 2.595.341 1.24 1.518 1.905 2.66 1.905H6.44l4.5 4.5c.944.945 2.56.276 2.56-1.06V4.06zM18.584 5.106a.75.75 0 011.06 0c3.808 3.807 3.808 9.98 0 13.788a.75.75 0 11-1.06-1.06 8.25 8.25 0 000-11.668.75.75 0 010-1.06z" />
    <path d="M15.932 7.757a.75.75 0 011.061 0 6 6 0 010 8.486.75.75 0 01-1.06-1.061 4.5 4.5 0 000-6.364.75.75 0 010-1.06z" />
  </svg>
);

export const SpeakerOffIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" {...props}>
    <path d="M13.5 4.06c0-1.336-1.616-2.005-2.56-1.06l-4.5 4.5H4.508c-1.141 0-2.318.664-2.66 1.905A9.76 9.76 0 001.5 12c0 .898.121 1.768.35 2.595.341 1.24 1.518 1.905 2.66 1.905H6.44l4.5 4.5c.944.945 2.56.276 2.56-1.06V4.06zM18.28 15.28a.75.75 0 00-1.06-1.06l-1.97-1.97-1.97 1.97a.75.75 0 101.06 1.06l1.97-1.97 1.97 1.97a.75.75 0 101.06-1.06l-1.97-1.97 1.97-1.97a.75.75 0 10-1.06-1.06l-1.97 1.97-1.97-1.97a.75.75 0 10-1.06 1.06l1.97 1.97-1.97 1.97a.75.75 0 001.06 1.06l1.97-1.97 1.97 1.97z" />
  </svg>
);
</file>

<file path="components/ChatHistory.tsx">
import React, { useRef, useEffect } from 'react';
import { UIMessage } from '../types';
import { ChatMessage } from './ChatMessage';

interface ChatHistoryProps {
  messages: UIMessage[];
}

export const ChatHistory: React.FC<ChatHistoryProps> = ({ messages }) => {
  const endOfMessagesRef = useRef<HTMLDivElement>(null);

  useEffect(() => {
    endOfMessagesRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  return (
    <div className="flex-1 overflow-y-auto p-4 md:p-6 space-y-6">
      {messages.map((message) => (
        <ChatMessage key={message.id} message={message} />
      ))}
      <div ref={endOfMessagesRef} />
    </div>
  );
};
</file>

<file path="components/ChatInput.tsx">
import React, { useState, useRef, useCallback } from 'react';
import { Attachment } from '../types';
import { SendIcon } from './icons/SendIcon';
import { AttachmentIcon } from './icons/AttachmentIcon';
import { XCircleIcon } from './icons/FileIcons';

interface ChatInputProps {
  onSendMessage: (text: string, attachments: Attachment[]) => void;
  isLoading: boolean;
}

const MAX_FILES = 5;
const MAX_FILE_SIZE_MB = 20;

const fileToBase64 = (file: File): Promise<string> =>
  new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.readAsDataURL(file);
    reader.onload = () => resolve((reader.result as string).split(',')[1]);
    reader.onerror = (error) => reject(error);
  });

export const ChatInput: React.FC<ChatInputProps> = ({ onSendMessage, isLoading }) => {
  const [text, setText] = useState('');
  const [attachments, setAttachments] = useState<Attachment[]>([]);
  const fileInputRef = useRef<HTMLInputElement>(null);

  const handleSendMessage = () => {
    if (isLoading || (!text.trim() && attachments.length === 0)) return;
    onSendMessage(text, attachments);
    setText('');
    setAttachments([]);
  };

  const handleKeyDown = (e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSendMessage();
    }
  };

  const handleFileChange = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const files = e.target.files;
    if (!files) return;

    if (attachments.length + files.length > MAX_FILES) {
        alert(`You can only upload a maximum of ${MAX_FILES} files.`);
        return;
    }

    const newAttachments: Attachment[] = [];
    for (const file of files) {
        if (file.size > MAX_FILE_SIZE_MB * 1024 * 1024) {
            alert(`File ${file.name} is too large. Maximum size is ${MAX_FILE_SIZE_MB}MB.`);
            continue;
        }
        try {
            const data = await fileToBase64(file);
            newAttachments.push({ name: file.name, type: file.type, size: file.size, data });
        } catch (error) {
            console.error("Error converting file to base64", error);
        }
    }
    setAttachments(prev => [...prev, ...newAttachments]);
  };

  const removeAttachment = (index: number) => {
    setAttachments(prev => prev.filter((_, i) => i !== index));
  };

  return (
    <div className="p-4 md:p-6 bg-gray-900 border-t border-gray-700 flex-shrink-0">
      <div className="bg-gray-800 rounded-2xl p-2 flex flex-col">
        {attachments.length > 0 && (
            <div className="p-2 grid grid-cols-2 md:grid-cols-3 lg:grid-cols-4 gap-2">
                {attachments.map((file, index) => (
                    <div key={index} className="bg-gray-700 p-2 rounded-lg flex items-center justify-between text-sm">
                        <span className="truncate" title={file.name}>{file.name}</span>
                        <button onClick={() => removeAttachment(index)} className="ml-2 text-gray-400 hover:text-white">
                            <XCircleIcon className="w-5 h-5" />
                        </button>
                    </div>
                ))}
            </div>
        )}
        <div className="flex items-end">
          <button
            onClick={() => fileInputRef.current?.click()}
            className="p-3 text-gray-400 hover:text-white transition-colors duration-200"
            aria-label="Attach files"
          >
            <AttachmentIcon className="w-6 h-6" />
          </button>
          <input
            type="file"
            multiple
            ref={fileInputRef}
            onChange={handleFileChange}
            className="hidden"
            accept="image/*,video/*,audio/*,.pdf,.doc,.docx,.txt"
          />
          <textarea
            value={text}
            onChange={(e) => setText(e.target.value)}
            onKeyDown={handleKeyDown}
            placeholder="Tell me about your video idea..."
            className="flex-1 bg-transparent p-3 resize-none outline-none placeholder-gray-500 max-h-40"
            rows={1}
            disabled={isLoading}
          />
          <button
            onClick={handleSendMessage}
            disabled={isLoading || (!text.trim() && attachments.length === 0)}
            className="p-3 rounded-full bg-indigo-500 text-white disabled:bg-gray-600 disabled:cursor-not-allowed hover:bg-indigo-600 transition-colors duration-200"
            aria-label="Send message"
          >
            {isLoading ? (
                <div className="w-6 h-6 border-2 border-white border-t-transparent rounded-full animate-spin"></div>
            ) : (
                <SendIcon className="w-6 h-6" />
            )}
          </button>
        </div>
      </div>
    </div>
  );
};
</file>

<file path="components/ChatMessage.tsx">
import React from 'react';
import { UIMessage } from '../types';
import { FileIcon } from './icons/FileIcons';

const LoadingIndicator: React.FC = () => (
  <div className="flex items-center space-x-1">
    <span className="w-2 h-2 bg-indigo-400 rounded-full animate-pulse [animation-delay:-0.3s]"></span>
    <span className="w-2 h-2 bg-indigo-400 rounded-full animate-pulse [animation-delay:-0.15s]"></span>
    <span className="w-2 h-2 bg-indigo-400 rounded-full animate-pulse"></span>
  </div>
);

export const ChatMessage: React.FC<{ message: UIMessage }> = ({ message }) => {
  const isUser = message.role === 'user';

  return (
    <div className={`flex items-start gap-4 ${isUser ? 'justify-end' : 'justify-start'}`}>
      {!isUser && (
        <div className="flex-shrink-0 w-10 h-10 bg-indigo-500 rounded-full flex items-center justify-center font-bold">
          K
        </div>
      )}
      <div className={`max-w-xl lg:max-w-2xl rounded-2xl p-4 ${isUser ? 'bg-blue-600 rounded-br-none' : 'bg-gray-800 rounded-bl-none'}`}>
        {message.text && <p className="whitespace-pre-wrap">{message.text}</p>}
        {message.isStreaming && !message.text && <LoadingIndicator />}
        
        {message.attachments && message.attachments.length > 0 && (
          <div className="mt-3 grid grid-cols-1 sm:grid-cols-2 gap-2">
            {message.attachments.map((att, index) => (
              <div key={index} className="bg-gray-700/50 p-2 rounded-lg flex items-center gap-2 text-sm">
                <FileIcon className="w-5 h-5 flex-shrink-0 text-gray-400" />
                <span className="truncate" title={att.name}>{att.name}</span>
              </div>
            ))}
          </div>
        )}
      </div>
       {isUser && (
        <div className="flex-shrink-0 w-10 h-10 bg-blue-600 rounded-full flex items-center justify-center font-bold">
          U
        </div>
      )}
    </div>
  );
};
</file>

<file path="hooks/useTextToSpeech.ts">
import { useState, useCallback, useEffect } from 'react';

export const useTextToSpeech = () => {
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isTtsEnabled, setIsTtsEnabled] = useState(true);

  const synth = window.speechSynthesis;

  const speak = useCallback((text: string) => {
    if (!synth || !isTtsEnabled) return;
    
    synth.cancel(); // Cancel any previous utterance
    const utterance = new SpeechSynthesisUtterance(text);
    
    utterance.onstart = () => setIsSpeaking(true);
    utterance.onend = () => setIsSpeaking(false);
    utterance.onerror = () => setIsSpeaking(false);
    
    synth.speak(utterance);
  }, [synth, isTtsEnabled]);

  const stop = useCallback(() => {
    if (synth) {
      synth.cancel();
      setIsSpeaking(false);
    }
  }, [synth]);
  
  useEffect(() => {
      return () => {
          if(synth) synth.cancel();
      }
  }, [synth]);

  return { isSpeaking, isTtsEnabled, setIsTtsEnabled, speak, stop };
};
</file>

<file path="services/geminiService.ts">
import { GoogleGenAI, Chat, GenerateContentResponse } from "@google/genai";
import { KIJKO_SYSTEM_PROMPT } from '../constants';
import { Attachment, MessagePart } from '../types';

if (!process.env.API_KEY) {
  throw new Error("API_KEY environment variable not set");
}

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

export function startKijkoChat(): Chat {
  const chat = ai.chats.create({
    model: 'gemini-2.5-flash',
    config: {
      systemInstruction: KIJKO_SYSTEM_PROMPT,
    },
  });
  return chat;
}

const fileToGenerativePart = (file: Attachment): MessagePart => {
  return {
    inlineData: {
      data: file.data,
      mimeType: file.type,
    },
  };
};

export async function sendMessageToKijkoStream(
  chat: Chat, 
  text: string, 
  attachments: Attachment[]
): Promise<AsyncGenerator<GenerateContentResponse>> {

  const parts: MessagePart[] = attachments.map(fileToGenerativePart);
  
  const youtubeRegex = /(?:https?:\/\/)?(?:www\.)?(?:youtube\.com|youtu\.be)\/(?:watch\?v=)?([\w-]{11})/;
  const ytMatch = text.match(youtubeRegex);

  let promptText = text;
  if (ytMatch) {
    promptText += `\n\n[User has provided a YouTube link for context: ${ytMatch[0]}. Please analyze the content of this video as part of your response.]`;
  }

  if (promptText.trim()) {
    parts.push({ text: promptText });
  }

  // The `sendMessageStream` method requires a `SendMessageParameters` object,
  // which has a `message` property. The `parts` array should be passed as the value for this property.
  const result = await chat.sendMessageStream({ message: parts });
  return result;
}
</file>

<file path="src/components/icons/AttachmentIcon.tsx">
import React from 'react';

export const AttachmentIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    viewBox="0 0 24 24"
    fill="currentColor"
    {...props}
  >
    <path
      fillRule="evenodd"
      d="M18.97 3.659a2.25 2.25 0 00-3.182 0l-10.5 10.5a.75.75 0 001.06 1.061l10.5-10.5a.75.75 0 011.06 0a.75.75 0 010 1.06l-8.25 8.25a2.25 2.25 0 01-3.182-3.182l5.25-5.25a.75.75 0 00-1.06-1.06l-5.25 5.25a3.75 3.75 0 105.3 5.3l8.25-8.25a2.25 2.25 0 000-3.182z"
      clipRule="evenodd"
    />
  </svg>
);
</file>

<file path="src/components/icons/FileIcons.tsx">
import React from 'react';

export const FileIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    viewBox="0 0 24 24"
    fill="currentColor"
    {...props}
  >
    <path
      fillRule="evenodd"
      d="M5.625 1.5c-1.036 0-1.875.84-1.875 1.875v17.25c0 1.035.84 1.875 1.875 1.875h12.75c1.035 0 1.875-.84 1.875-1.875V12.75A3.75 3.75 0 0016.5 9h-1.875a.375.375 0 01-.375-.375V6.75A3.75 3.75 0 009 3H5.625zM12.75 12.75a.75.75 0 00-1.5 0v2.25H9a.75.75 0 000 1.5h2.25v2.25a.75.75 0 001.5 0v-2.25H15a.75.75 0 000-1.5h-2.25V12.75z"
      clipRule="evenodd"
    />
    <path d="M14.25 6.75a2.25 2.25 0 00-2.25-2.25H5.625a.375.375 0 00-.375.375v17.25c0 .207.168.375.375.375h12.75a.375.375 0 00.375-.375V12.75a2.25 2.25 0 00-2.25-2.25h-1.875a1.875 1.875 0 01-1.875-1.875V6.75z" />
  </svg>
);


export const XCircleIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg 
    xmlns="http://www.w3.org/2000/svg" 
    viewBox="0 0 20 20" 
    fill="currentColor" 
    {...props}
  >
    <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8.28 7.22a.75.75 0 00-1.06 1.06L8.94 10l-1.72 1.72a.75.75 0 101.06 1.06L10 11.06l1.72 1.72a.75.75 0 101.06-1.06L11.06 10l1.72-1.72a.75.75 0 00-1.06-1.06L10 8.94 8.28 7.22z" clipRule="evenodd" />
  </svg>
);
</file>

<file path="src/components/icons/MicrophoneIcon.tsx">
import React from 'react';

export const MicrophoneIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg 
    xmlns="http://www.w3.org/2000/svg" 
    viewBox="0 0 24 24" 
    fill="currentColor" 
    {...props}
  >
    <path d="M12 18.75a6 6 0 006-6v-1.5a6 6 0 00-12 0v1.5a6 6 0 006 6zM12 2.25a.75.75 0 01.75.75v6a.75.75 0 01-1.5 0V3a.75.75 0 01.75-.75z" />
    <path d="M10.5 9.75a.75.75 0 00-1.5 0v1.5a3 3 0 006 0v-1.5a.75.75 0 00-1.5 0v1.5a1.5 1.5 0 01-3 0v-1.5z" />
    <path d="M3.52 9.22A.75.75 0 014.27 9l.415-.415a9.938 9.938 0 0114.63 0l.415.415a.75.75 0 01-.53 1.28l-.415-.415a8.438 8.438 0 00-12.57 0l-.415.415a.75.75 0 01-1.28-.53z" />
  </svg>
);
</file>

<file path="src/components/icons/SendIcon.tsx">
import React from 'react';

export const SendIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    viewBox="0 0 24 24"
    fill="currentColor"
    {...props}
  >
    <path d="M3.478 2.405a.75.75 0 00-.926.94l2.432 7.905H13.5a.75.75 0 010 1.5H4.984l-2.432 7.905a.75.75 0 00.926.94 60.519 60.519 0 0018.445-8.986.75.75 0 000-1.218A60.517 60.517 0 003.478 2.405z" />
  </svg>
);
</file>

<file path="src/components/icons/SpeakerIcons.tsx">
import React from 'react';

export const SpeakerOnIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" {...props}>
    <path d="M13.5 4.06c0-1.336-1.616-2.005-2.56-1.06l-4.5 4.5H4.508c-1.141 0-2.318.664-2.66 1.905A9.76 9.76 0 001.5 12c0 .898.121 1.768.35 2.595.341 1.24 1.518 1.905 2.66 1.905H6.44l4.5 4.5c.944.945 2.56.276 2.56-1.06V4.06zM18.584 5.106a.75.75 0 011.06 0c3.808 3.807 3.808 9.98 0 13.788a.75.75 0 11-1.06-1.06 8.25 8.25 0 000-11.668.75.75 0 010-1.06z" />
    <path d="M15.932 7.757a.75.75 0 011.061 0 6 6 0 010 8.486.75.75 0 01-1.06-1.061 4.5 4.5 0 000-6.364.75.75 0 010-1.06z" />
  </svg>
);

export const SpeakerOffIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" {...props}>
    <path d="M13.5 4.06c0-1.336-1.616-2.005-2.56-1.06l-4.5 4.5H4.508c-1.141 0-2.318.664-2.66 1.905A9.76 9.76 0 001.5 12c0 .898.121 1.768.35 2.595.341 1.24 1.518 1.905 2.66 1.905H6.44l4.5 4.5c.944.945 2.56.276 2.56-1.06V4.06zM18.28 15.28a.75.75 0 00-1.06-1.06l-1.97-1.97-1.97 1.97a.75.75 0 101.06 1.06l1.97-1.97 1.97 1.97a.75.75 0 101.06-1.06l-1.97-1.97 1.97-1.97a.75.75 0 10-1.06-1.06l-1.97 1.97-1.97-1.97a.75.75 0 10-1.06 1.06l1.97 1.97-1.97 1.97a.75.75 0 001.06 1.06l1.97-1.97 1.97 1.97z" />
  </svg>
);
</file>

<file path="src/components/AuthGate.tsx">
import React, { useEffect, useState, FormEvent } from 'react';
import { supabaseService } from '../services/supabaseService';

interface AuthGateProps {
  children: React.ReactNode;
}

export const AuthGate: React.FC<AuthGateProps> = ({ children }) => {
  const [loading, setLoading] = useState(true);
  const [user, setUser] = useState<any>(null);
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');
  const [error, setError] = useState<string | null>(null);

  useEffect(() => {
    if (!supabaseService.isAvailable()) {
      setLoading(false);
      return;
    }

    const client = supabaseService.getClient();

    const init = async () => {
      const { data: { session } } = await client.auth.getSession();
      setUser(session?.user || null);
      setLoading(false);
    };

    const { data: sub } = client.auth.onAuthStateChange((_event: any, session: any) => {
      setUser(session?.user || null);
    });

    init();

    return () => {
      sub?.subscription?.unsubscribe?.();
    };
  }, []);

  const handleGoogle = async () => {
    setError(null);
    try {
      const client = supabaseService.getClient();
      await client.auth.signInWithOAuth({
        provider: 'google',
        options: { redirectTo: window.location.origin }
      });
    } catch (e: any) {
      setError(e?.message || 'Google sign-in failed');
    }
  };

  const handleEmailPassword = async (e: FormEvent) => {
    e.preventDefault();
    setError(null);
    try {
      const client = supabaseService.getClient();
      const { data, error } = await client.auth.signInWithPassword({ email, password });
      if (error) {
        // If user not found, offer sign-up
        const signUp = confirm('Account not found or invalid credentials. Do you want to create an account?');
        if (signUp) {
          const { error: signUpError } = await client.auth.signUp({ email, password });
          if (signUpError) throw signUpError;
        } else {
          throw error;
        }
      }
    } catch (e: any) {
      setError(e?.message || 'Email/password sign-in failed');
    }
  };

  if (loading) {
    return (
      <div className="flex-1 flex items-center justify-center">
        <p className="text-gray-400">Checking authentication…</p>
      </div>
    );
  }

  if (!user) {
    return (
      <div className="flex-1 flex items-center justify-center p-6">
        <div className="w-full max-w-md bg-gray-900/80 border border-gray-700/50 rounded-xl p-6 space-y-4">
          <h2 className="text-xl font-semibold text-white">Sign in to continue</h2>

          {error && <div className="text-red-400 text-sm">{error}</div>}

          <button
            onClick={handleGoogle}
            className="w-full py-2 rounded-lg bg-white text-gray-900 font-medium hover:bg-gray-100 transition"
          >
            Continue with Google
          </button>

          <div className="text-center text-gray-500 text-sm">or</div>

          <form onSubmit={handleEmailPassword} className="space-y-3">
            <input
              type="email"
              placeholder="you@example.com"
              value={email}
              onChange={(e) => setEmail(e.target.value)}
              className="w-full px-3 py-2 rounded-lg bg-gray-800 text-white border border-gray-700 focus:outline-none"
              required
            />
            <input
              type="password"
              placeholder="Password"
              value={password}
              onChange={(e) => setPassword(e.target.value)}
              className="w-full px-3 py-2 rounded-lg bg-gray-800 text-white border border-gray-700 focus:outline-none"
              required
            />
            <button
              type="submit"
              className="w-full py-2 rounded-lg bg-gradient-to-r from-purple-600 to-blue-600 text-white font-medium hover:from-purple-700 hover:to-blue-700 transition"
            >
              Sign in / Sign up
            </button>
          </form>
        </div>
      </div>
    );
  }

  return <>{children}</>;
};
</file>

<file path="src/components/ChatHistory.tsx">
import React, { useRef, useEffect } from 'react';
import { UIMessage } from '../types';
import { ChatMessage } from './ChatMessage';

interface ChatHistoryProps {
  messages: UIMessage[];
}

export const ChatHistory: React.FC<ChatHistoryProps> = ({ messages }) => {
  const endOfMessagesRef = useRef<HTMLDivElement>(null);

  useEffect(() => {
    endOfMessagesRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  return (
    <div className="flex-1 overflow-y-auto p-4 md:p-6 space-y-6">
      {messages.map((message) => (
        <ChatMessage key={message.id} message={message} />
      ))}
      <div ref={endOfMessagesRef} />
    </div>
  );
};
</file>

<file path="src/components/ChatMessage.tsx">
import React from 'react';
import { UIMessage } from '../types';
import { FileIcon } from './icons/FileIcons';

const LoadingIndicator: React.FC = () => (
  <div className="flex items-center space-x-1">
    <span className="w-2 h-2 bg-indigo-400 rounded-full animate-pulse [animation-delay:-0.3s]"></span>
    <span className="w-2 h-2 bg-indigo-400 rounded-full animate-pulse [animation-delay:-0.15s]"></span>
    <span className="w-2 h-2 bg-indigo-400 rounded-full animate-pulse"></span>
  </div>
);

export const ChatMessage: React.FC<{ message: UIMessage }> = ({ message }) => {
  const isUser = message.role === 'user';

  return (
    <div className={`flex items-start gap-4 ${isUser ? 'justify-end' : 'justify-start'}`}>
      {!isUser && (
        <div className="flex-shrink-0 w-10 h-10 bg-indigo-500 rounded-full flex items-center justify-center font-bold">
          K
        </div>
      )}
      <div className={`max-w-xl lg:max-w-2xl rounded-2xl p-4 ${isUser ? 'bg-blue-600 rounded-br-none' : 'bg-gray-800 rounded-bl-none'}`}>
        {message.text && <p className="whitespace-pre-wrap">{message.text}</p>}
        {message.isStreaming && !message.text && <LoadingIndicator />}
        
        {message.attachments && message.attachments.length > 0 && (
          <div className="mt-3 grid grid-cols-1 sm:grid-cols-2 gap-2">
            {message.attachments.map((att, index) => (
              <div key={index} className="bg-gray-700/50 p-2 rounded-lg flex items-center gap-2 text-sm">
                <FileIcon className="w-5 h-5 flex-shrink-0 text-gray-400" />
                <span className="truncate" title={att.name}>{att.name}</span>
              </div>
            ))}
          </div>
        )}
      </div>
       {isUser && (
        <div className="flex-shrink-0 w-10 h-10 bg-blue-600 rounded-full flex items-center justify-center font-bold">
          U
        </div>
      )}
    </div>
  );
};
</file>

<file path="src/components/DocumentExporter.tsx">
import React, { useState, useRef } from 'react';
import jsPDF from 'jspdf';
import html2canvas from 'html2canvas';
import { Download, FileText, FilePlus } from 'lucide-react';
import { Message } from '../types';
import { vrdFormatter } from '../utils/vrdFormatter';
import { documentStorage } from '../utils/documentStorage';

interface DocumentExporterProps {
  messages: Message[];
  title?: string;
  onExportComplete?: (documentId: string) => void;
  className?: string;
}

export const DocumentExporter: React.FC<DocumentExporterProps> = ({
  messages,
  title = 'Video Requirements Document',
  onExportComplete,
  className = ''
}) => {
  const [isExporting, setIsExporting] = useState(false);
  const [showMenu, setShowMenu] = useState(false);
  const exportRef = useRef<HTMLDivElement>(null);

  /**
   * Export as PDF
   */
  const exportAsPDF = async () => {
    setIsExporting(true);
    try {
      // Format the VRD
      const vrd = vrdFormatter.formatVRD(messages, title);
      
      // Create PDF document
      const pdf = new jsPDF('p', 'mm', 'a4');
      
      // Add title
      pdf.setFontSize(20);
      pdf.text(vrd.title, 20, 20);
      
      // Add date
      pdf.setFontSize(10);
      pdf.setTextColor(100);
      pdf.text(`Generated on ${vrd.createdAt.toLocaleDateString()}`, 20, 30);
      
      // Reset text color
      pdf.setTextColor(0);
      let yPosition = 45;
      
      // Add Project Overview
      if (vrd.content.projectOverview) {
        pdf.setFontSize(14);
        pdf.text('Project Overview', 20, yPosition);
        yPosition += 10;
        
        pdf.setFontSize(10);
        const lines = pdf.splitTextToSize(vrd.content.projectOverview, 170);
        pdf.text(lines, 20, yPosition);
        yPosition += lines.length * 5 + 10;
      }
      
      // Add Requirements
      if (vrd.content.requirements.length > 0) {
        if (yPosition > 250) {
          pdf.addPage();
          yPosition = 20;
        }
        
        pdf.setFontSize(14);
        pdf.text('Requirements', 20, yPosition);
        yPosition += 10;
        
        pdf.setFontSize(10);
        vrd.content.requirements.forEach((req, index) => {
          if (yPosition > 270) {
            pdf.addPage();
            yPosition = 20;
          }
          const bullet = `${index + 1}. ${req}`;
          const lines = pdf.splitTextToSize(bullet, 170);
          pdf.text(lines, 20, yPosition);
          yPosition += lines.length * 5 + 3;
        });
        yPosition += 7;
      }
      
      // Add Technical Specs
      if (vrd.content.technicalSpecs) {
        if (yPosition > 250) {
          pdf.addPage();
          yPosition = 20;
        }
        
        pdf.setFontSize(14);
        pdf.text('Technical Specifications', 20, yPosition);
        yPosition += 10;
        
        pdf.setFontSize(10);
        const lines = pdf.splitTextToSize(vrd.content.technicalSpecs, 170);
        pdf.text(lines, 20, yPosition);
        yPosition += lines.length * 5 + 10;
      }
      
      // Add Timeline
      if (vrd.content.timeline) {
        if (yPosition > 250) {
          pdf.addPage();
          yPosition = 20;
        }
        
        pdf.setFontSize(14);
        pdf.text('Timeline', 20, yPosition);
        yPosition += 10;
        
        pdf.setFontSize(10);
        const lines = pdf.splitTextToSize(vrd.content.timeline, 170);
        pdf.text(lines, 20, yPosition);
        yPosition += lines.length * 5 + 10;
      }
      
      // Add Budget
      if (vrd.content.budget) {
        if (yPosition > 250) {
          pdf.addPage();
          yPosition = 20;
        }
        
        pdf.setFontSize(14);
        pdf.text('Budget', 20, yPosition);
        yPosition += 10;
        
        pdf.setFontSize(10);
        const lines = pdf.splitTextToSize(vrd.content.budget, 170);
        pdf.text(lines, 20, yPosition);
      }
      
      // Convert PDF to blob
      const pdfBlob = pdf.output('blob');
      
      // Save document with PDF blob
      vrd.type = 'pdf';
      vrd.blob = pdfBlob;
      await documentStorage.saveDocument(vrd);
      
      // Download the PDF
      const url = URL.createObjectURL(pdfBlob);
      const a = document.createElement('a');
      a.href = url;
      a.download = `${vrd.title.replace(/[^a-z0-9]/gi, '_')}.pdf`;
      a.click();
      URL.revokeObjectURL(url);
      
      if (onExportComplete) {
        onExportComplete(vrd.id);
      }
      
      setShowMenu(false);
    } catch (error) {
      console.error('Error exporting PDF:', error);
      alert('Failed to export PDF. Please try again.');
    } finally {
      setIsExporting(false);
    }
  };

  /**
   * Export as Markdown
   */
  const exportAsMarkdown = async () => {
    setIsExporting(true);
    try {
      // Format the VRD
      const vrd = vrdFormatter.formatVRD(messages, title);
      
      // Convert to markdown
      const markdown = vrdFormatter.toMarkdown(vrd);
      
      // Create blob and download
      const blob = new Blob([markdown], { type: 'text/markdown' });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = `${vrd.title.replace(/[^a-z0-9]/gi, '_')}.md`;
      a.click();
      URL.revokeObjectURL(url);
      
      // Save document
      vrd.type = 'markdown';
      await documentStorage.saveDocument(vrd);
      
      if (onExportComplete) {
        onExportComplete(vrd.id);
      }
      
      setShowMenu(false);
    } catch (error) {
      console.error('Error exporting Markdown:', error);
      alert('Failed to export Markdown. Please try again.');
    } finally {
      setIsExporting(false);
    }
  };

  /**
   * Save to documents (without download)
   */
  const saveToDocuments = async () => {
    setIsExporting(true);
    try {
      // Format and save the VRD
      const vrd = vrdFormatter.formatVRD(messages, title);
      await documentStorage.saveDocument(vrd);
      
      if (onExportComplete) {
        onExportComplete(vrd.id);
      }
      
      alert('Document saved successfully!');
      setShowMenu(false);
    } catch (error) {
      console.error('Error saving document:', error);
      alert('Failed to save document. Please try again.');
    } finally {
      setIsExporting(false);
    }
  };

  return (
    <div className={`document-exporter relative ${className}`}>
      {/* Export Button */}
      <button
        onClick={() => setShowMenu(!showMenu)}
        disabled={isExporting || messages.length === 0}
        className="flex items-center gap-2 px-4 py-2 bg-gradient-to-r from-purple-500 to-indigo-600 
                   text-white rounded-lg hover:from-purple-600 hover:to-indigo-700 
                   transition-all duration-200 shadow-lg disabled:opacity-50 disabled:cursor-not-allowed"
      >
        <Download className="w-5 h-5" />
        <span>Export VRD</span>
      </button>

      {/* Export Menu */}
      {showMenu && (
        <div className="absolute top-full mt-2 right-0 bg-white dark:bg-gray-800 rounded-lg 
                        shadow-xl border border-gray-200 dark:border-gray-700 z-50 min-w-[200px]">
          <div className="p-2">
            <button
              onClick={exportAsPDF}
              disabled={isExporting}
              className="w-full flex items-center gap-3 px-3 py-2 text-left rounded-md
                         hover:bg-gray-100 dark:hover:bg-gray-700 transition-colors"
            >
              <FileText className="w-4 h-4 text-red-500" />
              <span className="text-gray-700 dark:text-gray-300">Export as PDF</span>
            </button>
            
            <button
              onClick={exportAsMarkdown}
              disabled={isExporting}
              className="w-full flex items-center gap-3 px-3 py-2 text-left rounded-md
                         hover:bg-gray-100 dark:hover:bg-gray-700 transition-colors"
            >
              <FileText className="w-4 h-4 text-blue-500" />
              <span className="text-gray-700 dark:text-gray-300">Export as Markdown</span>
            </button>
            
            <div className="border-t border-gray-200 dark:border-gray-700 my-2"></div>
            
            <button
              onClick={saveToDocuments}
              disabled={isExporting}
              className="w-full flex items-center gap-3 px-3 py-2 text-left rounded-md
                         hover:bg-gray-100 dark:hover:bg-gray-700 transition-colors"
            >
              <FilePlus className="w-4 h-4 text-green-500" />
              <span className="text-gray-700 dark:text-gray-300">Save to Documents</span>
            </button>
          </div>
        </div>
      )}

      {/* Loading Overlay */}
      {isExporting && (
        <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
          <div className="bg-white dark:bg-gray-800 rounded-lg p-6 shadow-xl">
            <div className="flex items-center gap-3">
              <div className="w-6 h-6 border-3 border-blue-500 border-t-transparent rounded-full animate-spin"></div>
              <span className="text-gray-700 dark:text-gray-300">Exporting document...</span>
            </div>
          </div>
        </div>
      )}
    </div>
  );
};
</file>

<file path="src/components/DocumentsSidebar.tsx">
import React, { useState, useEffect } from 'react';
import { FileText, Search, Trash2, Download, Eye, X } from 'lucide-react';
import { documentStorage, StoredDocument } from '../utils/documentStorage';
import { VRDDocument } from '../utils/vrdFormatter';

interface DocumentsSidebarProps {
  onClose?: () => void;
  onDocumentSelect?: (doc: VRDDocument) => void;
}

export const DocumentsSidebar: React.FC<DocumentsSidebarProps> = ({
  onClose,
  onDocumentSelect
}) => {
  const [documents, setDocuments] = useState<StoredDocument[]>([]);
  const [searchQuery, setSearchQuery] = useState('');
  const [loading, setLoading] = useState(true);
  const [selectedDoc, setSelectedDoc] = useState<VRDDocument | null>(null);
  const [showPreview, setShowPreview] = useState(false);

  // Load documents on mount
  useEffect(() => {
    loadDocuments();
  }, []);

  const loadDocuments = async () => {
    setLoading(true);
    try {
      const docs = await documentStorage.getRecentDocuments(50);
      setDocuments(docs);
    } catch (error) {
      console.error('Error loading documents:', error);
    } finally {
      setLoading(false);
    }
  };

  // Search documents
  const filteredDocuments = documents.filter(doc => 
    doc.title.toLowerCase().includes(searchQuery.toLowerCase()) ||
    (doc.preview && doc.preview.toLowerCase().includes(searchQuery.toLowerCase()))
  );

  // Handle document preview
  const handlePreview = async (docId: string) => {
    try {
      const doc = await documentStorage.getDocument(docId);
      if (doc) {
        setSelectedDoc(doc);
        setShowPreview(true);
        if (onDocumentSelect) {
          onDocumentSelect(doc);
        }
      }
    } catch (error) {
      console.error('Error loading document:', error);
    }
  };

  // Handle document download
  const handleDownload = async (doc: StoredDocument) => {
    try {
      const blob = await documentStorage.exportDocument(doc.id, doc.type);
      if (blob) {
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = `${doc.title.replace(/[^a-z0-9]/gi, '_')}.${doc.type === 'pdf' ? 'pdf' : 'md'}`;
        a.click();
        URL.revokeObjectURL(url);
      }
    } catch (error) {
      console.error('Error downloading document:', error);
    }
  };

  // Handle document deletion
  const handleDelete = async (docId: string) => {
    if (confirm('Are you sure you want to delete this document?')) {
      try {
        await documentStorage.deleteDocument(docId);
        await loadDocuments(); // Reload the list
      } catch (error) {
        console.error('Error deleting document:', error);
      }
    }
  };

  const formatDate = (date: Date) => {
    return new Date(date).toLocaleDateString('en-US', {
      month: 'short',
      day: 'numeric',
      year: 'numeric',
      hour: '2-digit',
      minute: '2-digit'
    });
  };

  const formatFileSize = (bytes?: number) => {
    if (!bytes) return 'N/A';
    if (bytes < 1024) return bytes + ' B';
    if (bytes < 1048576) return (bytes / 1024).toFixed(1) + ' KB';
    return (bytes / 1048576).toFixed(1) + ' MB';
  };

  return (
    <>
      {/* Documents List Section */}
      <div className="documents-sidebar h-full flex flex-col">
        {/* Header */}
        <div className="flex items-center justify-between p-4 border-b border-white/10">
          <h2 className="text-lg font-semibold text-white flex items-center gap-2">
            <FileText className="w-5 h-5" />
            Saved Documents
          </h2>
          {onClose && (
            <button
              onClick={onClose}
              className="text-gray-400 hover:text-white transition-colors"
              aria-label="Close documents"
            >
              <X className="w-5 h-5" />
            </button>
          )}
        </div>

        {/* Search Bar */}
        <div className="p-4">
          <div className="relative">
            <Search className="absolute left-3 top-1/2 transform -translate-y-1/2 w-4 h-4 text-gray-400" />
            <input
              type="text"
              placeholder="Search documents..."
              value={searchQuery}
              onChange={(e) => setSearchQuery(e.target.value)}
              className="w-full pl-10 pr-4 py-2 bg-white/5 border border-white/10 rounded-lg 
                       text-white placeholder-gray-400 focus:outline-none focus:border-purple-500"
            />
          </div>
        </div>

        {/* Documents List */}
        <div className="flex-1 overflow-y-auto px-4">
          {loading ? (
            <div className="flex items-center justify-center py-8">
              <div className="w-8 h-8 border-2 border-purple-500 border-t-transparent rounded-full animate-spin"></div>
            </div>
          ) : filteredDocuments.length === 0 ? (
            <div className="text-center py-8 text-gray-400">
              {searchQuery ? 'No documents found' : 'No saved documents yet'}
            </div>
          ) : (
            <div className="space-y-2 pb-4">
              {filteredDocuments.map((doc) => (
                <div
                  key={doc.id}
                  className="group bg-white/5 hover:bg-white/10 rounded-lg p-3 transition-all duration-200
                           border border-transparent hover:border-purple-500/30 cursor-pointer"
                  onClick={() => handlePreview(doc.id)}
                >
                  {/* Document Info */}
                  <div className="flex items-start justify-between mb-2">
                    <div className="flex-1 min-w-0">
                      <h3 className="font-medium text-white truncate group-hover:text-purple-400 transition-colors">
                        {doc.title}
                      </h3>
                      <div className="flex items-center gap-3 mt-1 text-xs text-gray-400">
                        <span>{formatDate(doc.createdAt)}</span>
                        <span>•</span>
                        <span>{doc.type.toUpperCase()}</span>
                        <span>•</span>
                        <span>{formatFileSize(doc.size)}</span>
                      </div>
                    </div>
                    <div className="flex items-center gap-1 opacity-0 group-hover:opacity-100 transition-opacity">
                      <button
                        onClick={(e) => {
                          e.stopPropagation();
                          handlePreview(doc.id);
                        }}
                        className="p-1.5 hover:bg-white/10 rounded transition-colors"
                        aria-label="Preview document"
                      >
                        <Eye className="w-4 h-4 text-gray-400 hover:text-white" />
                      </button>
                      <button
                        onClick={(e) => {
                          e.stopPropagation();
                          handleDownload(doc);
                        }}
                        className="p-1.5 hover:bg-white/10 rounded transition-colors"
                        aria-label="Download document"
                      >
                        <Download className="w-4 h-4 text-gray-400 hover:text-white" />
                      </button>
                      <button
                        onClick={(e) => {
                          e.stopPropagation();
                          handleDelete(doc.id);
                        }}
                        className="p-1.5 hover:bg-white/10 rounded transition-colors"
                        aria-label="Delete document"
                      >
                        <Trash2 className="w-4 h-4 text-gray-400 hover:text-red-400" />
                      </button>
                    </div>
                  </div>

                  {/* Preview Text */}
                  {doc.preview && (
                    <p className="text-xs text-gray-400 line-clamp-2">
                      {doc.preview}
                    </p>
                  )}
                </div>
              ))}
            </div>
          )}
        </div>

        {/* Storage Stats */}
        <div className="p-4 border-t border-white/10">
          <div className="text-xs text-gray-400">
            {documents.length} document{documents.length !== 1 ? 's' : ''} saved
          </div>
        </div>
      </div>

      {/* Preview Modal */}
      {showPreview && selectedDoc && (
        <div 
          className="fixed inset-0 bg-black/50 flex items-center justify-center z-50 p-4"
          onClick={() => setShowPreview(false)}
        >
          <div 
            className="bg-gray-900 rounded-xl shadow-2xl max-w-4xl w-full max-h-[90vh] flex flex-col"
            onClick={(e) => e.stopPropagation()}
          >
            {/* Modal Header */}
            <div className="flex items-center justify-between p-6 border-b border-white/10">
              <h2 className="text-xl font-semibold text-white">{selectedDoc.title}</h2>
              <button
                onClick={() => setShowPreview(false)}
                className="text-gray-400 hover:text-white transition-colors"
              >
                <X className="w-6 h-6" />
              </button>
            </div>

            {/* Modal Content */}
            <div className="flex-1 overflow-y-auto p-6">
              <div className="prose prose-invert max-w-none">
                {/* Project Overview */}
                {selectedDoc.content.projectOverview && (
                  <div className="mb-6">
                    <h3 className="text-lg font-semibold text-purple-400 mb-2">Project Overview</h3>
                    <p className="text-gray-300">{selectedDoc.content.projectOverview}</p>
                  </div>
                )}

                {/* Requirements */}
                {selectedDoc.content.requirements.length > 0 && (
                  <div className="mb-6">
                    <h3 className="text-lg font-semibold text-purple-400 mb-2">Requirements</h3>
                    <ul className="list-disc pl-5 space-y-1">
                      {selectedDoc.content.requirements.map((req, index) => (
                        <li key={index} className="text-gray-300">{req}</li>
                      ))}
                    </ul>
                  </div>
                )}

                {/* Technical Specs */}
                {selectedDoc.content.technicalSpecs && (
                  <div className="mb-6">
                    <h3 className="text-lg font-semibold text-purple-400 mb-2">Technical Specifications</h3>
                    <p className="text-gray-300">{selectedDoc.content.technicalSpecs}</p>
                  </div>
                )}

                {/* Timeline */}
                {selectedDoc.content.timeline && (
                  <div className="mb-6">
                    <h3 className="text-lg font-semibold text-purple-400 mb-2">Timeline</h3>
                    <p className="text-gray-300">{selectedDoc.content.timeline}</p>
                  </div>
                )}

                {/* Budget */}
                {selectedDoc.content.budget && (
                  <div className="mb-6">
                    <h3 className="text-lg font-semibold text-purple-400 mb-2">Budget</h3>
                    <p className="text-gray-300">{selectedDoc.content.budget}</p>
                  </div>
                )}
              </div>
            </div>

            {/* Modal Footer */}
            <div className="flex items-center justify-end gap-3 p-6 border-t border-white/10">
              <button
                onClick={() => handleDownload({
                  id: selectedDoc.id,
                  title: selectedDoc.title,
                  createdAt: selectedDoc.createdAt,
                  updatedAt: selectedDoc.updatedAt,
                  type: selectedDoc.type
                })}
                className="px-4 py-2 bg-purple-500 hover:bg-purple-600 text-white rounded-lg 
                         transition-colors flex items-center gap-2"
              >
                <Download className="w-4 h-4" />
                Download
              </button>
              <button
                onClick={() => setShowPreview(false)}
                className="px-4 py-2 bg-gray-700 hover:bg-gray-600 text-white rounded-lg transition-colors"
              >
                Close
              </button>
            </div>
          </div>
        </div>
      )}
    </>
  );
};
</file>

<file path="src/components/MCQTestDemo.tsx">
import React, { useState } from 'react';
import OptionGroup from './OptionGroup';
import { MCQOption } from '../utils/messageClassifier';

const MCQTestDemo: React.FC = () => {
  const [selectedResults, setSelectedResults] = useState<string[]>([]);

  // Example 1: Single select question
  const singleSelectOptions: MCQOption[] = [
    { label: 'A', text: 'A professional and formal approach', fullText: 'A professional and formal approach' },
    { label: 'B', text: 'A **casual and friendly** style', fullText: 'A casual and friendly style' },
    { label: 'C', text: 'A *mysterious* and intriguing tone', fullText: 'A mysterious and intriguing tone' },
    { label: 'D', text: 'An **energetic** and *enthusiastic* vibe', fullText: 'An energetic and enthusiastic vibe' }
  ];

  // Example 2: Multi-select question (automatically detected based on content)
  const multiSelectOptions: MCQOption[] = [
    { label: 'A', text: '**Energetic** and upbeat', fullText: 'Energetic and upbeat' },
    { label: 'B', text: '*Mysterious* and suspenseful', fullText: 'Mysterious and suspenseful' },
    { label: 'C', text: 'Professional **style**', fullText: 'Professional style' },
    { label: 'D', text: 'Warm and friendly **tone**', fullText: 'Warm and friendly tone' },
    { label: 'E', text: 'Dramatic and *cinematic*', fullText: 'Dramatic and cinematic' }
  ];

  // Example 3: Explicit multi-select
  const explicitMultiSelect: MCQOption[] = [
    { label: 'A', text: 'Include **background music**', fullText: 'Include background music' },
    { label: 'B', text: 'Add *voice narration*', fullText: 'Add voice narration' },
    { label: 'C', text: 'Use **text overlays**', fullText: 'Use text overlays' },
    { label: 'D', text: 'Include *sound effects*', fullText: 'Include sound effects' }
  ];

  const handleSingleSelect = (option: MCQOption) => {
    setSelectedResults(prev => [...prev, `Single Select: ${option.text}`]);
  };

  const handleMultiSelect = (options: MCQOption[]) => {
    const result = `Multi Select: ${options.map(opt => opt.text).join(', ')}`;
    setSelectedResults(prev => [...prev, result]);
  };

  const handleExplicitMultiSelect = (options: MCQOption[]) => {
    const result = `Explicit Multi Select: ${options.map(opt => opt.text).join(', ')}`;
    setSelectedResults(prev => [...prev, result]);
  };

  const clearResults = () => setSelectedResults([]);

  return (
    <div className="p-6 bg-gray-900 min-h-screen text-white">
      <div className="max-w-3xl mx-auto space-y-8">
        <header className="text-center">
          <h1 className="text-3xl font-bold mb-2">Enhanced MCQ Test Demo</h1>
          <p className="text-gray-400">
            Testing single-select, auto-detected multi-select, and explicit multi-select options
          </p>
        </header>

        {/* Example 1: Single Select */}
        <section className="bg-gray-800 rounded-lg p-6">
          <h2 className="text-xl font-semibold mb-4">1. Single Select Question</h2>
          <p className="text-gray-300 mb-4">
            What tone would you prefer for your video? (Auto-detects as single select)
          </p>
          <OptionGroup
            options={singleSelectOptions}
            onSelect={handleSingleSelect}
          />
        </section>

        {/* Example 2: Auto Multi-Select */}
        <section className="bg-gray-800 rounded-lg p-6">
          <h2 className="text-xl font-semibold mb-4">2. Auto-Detected Multi-Select</h2>
          <p className="text-gray-300 mb-4">
            Which styles and tones appeal to you? (Auto-detects as multi-select based on keywords)
          </p>
          <OptionGroup
            options={multiSelectOptions}
            onSelect={handleSingleSelect}
            onSubmit={handleMultiSelect}
          />
        </section>

        {/* Example 3: Explicit Multi-Select */}
        <section className="bg-gray-800 rounded-lg p-6">
          <h2 className="text-xl font-semibold mb-4">3. Explicit Multi-Select</h2>
          <p className="text-gray-300 mb-4">
            What elements would you like to include? (Explicitly set as multi-select)
          </p>
          <OptionGroup
            options={explicitMultiSelect}
            onSelect={handleSingleSelect}
            onSubmit={handleExplicitMultiSelect}
            allowMultiple={true}
          />
        </section>

        {/* Results Display */}
        <section className="bg-gray-800 rounded-lg p-6">
          <div className="flex justify-between items-center mb-4">
            <h2 className="text-xl font-semibold">Selection Results</h2>
            <button
              onClick={clearResults}
              className="px-4 py-2 bg-red-600 hover:bg-red-700 rounded-lg text-sm transition-colors"
            >
              Clear Results
            </button>
          </div>
          
          {selectedResults.length === 0 ? (
            <p className="text-gray-400 italic">No selections made yet...</p>
          ) : (
            <div className="space-y-2">
              {selectedResults.map((result, index) => (
                <div
                  key={index}
                  className="bg-gray-700 rounded p-3 border-l-4 border-blue-500"
                >
                  <span className="text-sm text-gray-300">
                    Selection #{index + 1}:
                  </span>
                  <p className="text-white mt-1">{result}</p>
                </div>
              ))}
            </div>
          )}
        </section>

        {/* Features Summary */}
        <section className="bg-gradient-to-r from-blue-900/30 to-purple-900/30 rounded-lg p-6 border border-blue-500/20">
          <h2 className="text-xl font-semibold mb-4">✨ Enhanced Features</h2>
          <div className="grid md:grid-cols-2 gap-4 text-sm">
            <div>
              <h3 className="font-medium text-blue-300 mb-2">🎨 Visual Enhancements</h3>
              <ul className="text-gray-300 space-y-1">
                <li>• **Bold** and *italic* markdown rendering</li>
                <li>• Checkbox indicators for multi-select</li>
                <li>• Responsive layouts (short vs long)</li>
                <li>• Smooth animations and transitions</li>
              </ul>
            </div>
            <div>
              <h3 className="font-medium text-purple-300 mb-2">⚡ Interaction Features</h3>
              <ul className="text-gray-300 space-y-1">
                <li>• Auto-detection of multi-select scenarios</li>
                <li>• Contextual hint text and tooltips</li>
                <li>• Submit button for multi-select confirmation</li>
                <li>• Accessible ARIA roles and labels</li>
              </ul>
            </div>
          </div>
        </section>
      </div>
    </div>
  );
};

export default MCQTestDemo;
</file>

<file path="src/components/SystemPromptEditor.tsx">
import React, { useCallback } from 'react';
import Editor from 'react-simple-code-editor';
import { highlight, languages } from 'prismjs';
import 'prismjs/components/prism-markdown';
import 'prismjs/themes/prism-dark.css';
import { ArrowUturnLeftIcon, CheckIcon } from '@heroicons/react/24/outline';

interface SystemPromptEditorProps {
  value: string;
  onChange: (value: string) => void;
  onReset: () => void;
  isLoading?: boolean;
  error?: string;
}

export const SystemPromptEditor: React.FC<SystemPromptEditorProps> = ({
  value,
  onChange,
  onReset,
  isLoading = false,
  error
}) => {
  const highlightCode = useCallback((code: string) => {
    return highlight(code, languages.markdown, 'markdown');
  }, []);

  const handleEditorChange = useCallback((code: string) => {
    onChange(code);
  }, [onChange]);

  return (
    <div className="space-y-4">
      {/* Header */}
      <div className="flex items-center justify-between">
        <div>
          <h3 className="text-lg font-semibold text-white">System Prompt</h3>
          <p className="text-sm text-gray-400">
            Configure how Kijko responds and behaves in conversations
          </p>
        </div>
        <button
          onClick={onReset}
          disabled={isLoading}
          className="
            flex items-center gap-2 px-3 py-2 text-sm
            text-gray-400 hover:text-white
            bg-gray-800 hover:bg-gray-700
            border border-gray-600 hover:border-gray-500
            rounded-lg transition-colors
            disabled:opacity-50 disabled:cursor-not-allowed
          "
          title="Reset to default system prompt"
        >
          <ArrowUturnLeftIcon className="w-4 h-4" />
          Reset
        </button>
      </div>

      {/* Error Message */}
      {error && (
        <div className="p-3 bg-red-500/10 border border-red-500/20 rounded-lg">
          <p className="text-sm text-red-400">{error}</p>
        </div>
      )}

      {/* Editor Container */}
      <div className="relative">
        <div className="
          bg-gray-900 border border-gray-700 rounded-lg overflow-hidden
          focus-within:border-purple-500/50 focus-within:ring-1 focus-within:ring-purple-500/20
          transition-colors
        ">
          <div className="p-4">
            <Editor
              value={value}
              onValueChange={handleEditorChange}
              highlight={highlightCode}
              padding={0}
              disabled={isLoading}
              className="
                min-h-[300px] max-h-[500px] overflow-y-auto
                text-sm font-mono text-gray-200
                focus:outline-none
                disabled:opacity-50
              "
              style={{
                fontFamily: '"Fira Code", "Monaco", "Cascadia Code", "Ubuntu Mono", monospace',
                fontSize: 14,
                lineHeight: 1.5,
                tabSize: 2,
              }}
              textareaClassName="
                focus:outline-none resize-none
                placeholder:text-gray-500
              "
              placeholder="Enter your system prompt here..."
            />
          </div>

          {/* Character Count */}
          <div className="flex items-center justify-between px-4 py-2 bg-gray-800/50 border-t border-gray-700">
            <div className="flex items-center gap-4 text-xs text-gray-400">
              <span>{value.length.toLocaleString()} characters</span>
              <span>{value.split('\n').length} lines</span>
            </div>
            
            {isLoading && (
              <div className="flex items-center gap-2 text-xs text-gray-400">
                <div className="w-3 h-3 border border-gray-400 border-t-transparent rounded-full animate-spin"></div>
                Saving...
              </div>
            )}
          </div>
        </div>

        {/* Syntax Highlighting Info */}
        <div className="mt-2 text-xs text-gray-500">
          Markdown syntax highlighting enabled • Use Ctrl+A to select all • Tab for indentation
        </div>
      </div>

      {/* Tips */}
      <div className="p-3 bg-blue-500/10 border border-blue-500/20 rounded-lg">
        <div className="flex items-start gap-2">
          <CheckIcon className="w-4 h-4 text-blue-400 mt-0.5 flex-shrink-0" />
          <div className="text-xs text-blue-200 space-y-1">
            <p><strong>Tips for effective system prompts:</strong></p>
            <ul className="list-disc list-inside space-y-1 ml-2">
              <li>Be specific about the assistant's role and capabilities</li>
              <li>Include examples of desired behavior when possible</li>
              <li>Define the expected response format and tone</li>
              <li>Set clear boundaries and limitations</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  );
};
</file>

<file path="src/components/Toast.tsx">
import React, { useEffect } from 'react';
import { CheckCircleIcon, XCircleIcon, ExclamationCircleIcon } from '@heroicons/react/24/solid';

export type ToastType = 'success' | 'error' | 'warning';

interface ToastProps {
  message: string;
  type: ToastType;
  isVisible: boolean;
  onClose: () => void;
  duration?: number;
}

export const Toast: React.FC<ToastProps> = ({
  message,
  type,
  isVisible,
  onClose,
  duration = 3000
}) => {
  useEffect(() => {
    if (isVisible && duration > 0) {
      const timer = setTimeout(() => {
        onClose();
      }, duration);
      
      return () => clearTimeout(timer);
    }
  }, [isVisible, duration, onClose]);

  const getIcon = () => {
    switch (type) {
      case 'success':
        return <CheckCircleIcon className="w-5 h-5 text-green-400" />;
      case 'error':
        return <XCircleIcon className="w-5 h-5 text-red-400" />;
      case 'warning':
        return <ExclamationCircleIcon className="w-5 h-5 text-yellow-400" />;
    }
  };

  const getStyles = () => {
    switch (type) {
      case 'success':
        return 'bg-green-500/10 border-green-500/20 text-green-200';
      case 'error':
        return 'bg-red-500/10 border-red-500/20 text-red-200';
      case 'warning':
        return 'bg-yellow-500/10 border-yellow-500/20 text-yellow-200';
    }
  };

  if (!isVisible) return null;

  return (
    <div
      className={`
        fixed top-4 right-4 z-[60] min-w-80 max-w-md p-4 rounded-lg border backdrop-blur-sm
        transform transition-all duration-300 ease-in-out
        ${getStyles()}
        ${isVisible ? 'translate-x-0 opacity-100' : 'translate-x-full opacity-0'}
      `}
    >
      <div className="flex items-center gap-3">
        {getIcon()}
        <div className="flex-1">
          <p className="text-sm font-medium">{message}</p>
        </div>
        <button
          onClick={onClose}
          className="text-gray-400 hover:text-white transition-colors p-1 rounded hover:bg-gray-700/50"
          aria-label="Close notification"
        >
          <svg className="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
          </svg>
        </button>
      </div>
      
      {/* Progress bar */}
      {duration > 0 && (
        <div className="mt-2 w-full bg-gray-700/30 rounded-full h-1">
          <div 
            className={`h-1 rounded-full transition-all ease-linear
              ${type === 'success' ? 'bg-green-400' : 
                type === 'error' ? 'bg-red-400' : 'bg-yellow-400'}
            `}
            style={{
              animation: `shrink ${duration}ms linear forwards`
            }}
          />
        </div>
      )}
    </div>
  );
};

// CSS animation for progress bar
const style = document.createElement('style');
style.textContent = `
  @keyframes shrink {
    from { width: 100%; }
    to { width: 0%; }
  }
`;
document.head.appendChild(style);
</file>

<file path="src/hooks/useProgress.ts">
import { useState, useCallback, useEffect } from 'react';

export interface ProgressStep {
  id: string;
  label: string;
  percentage: number;
}

// Define the conversation progress steps
export const PROGRESS_STEPS: ProgressStep[] = [
  { id: 'welcome', label: 'Welcome', percentage: 0 },
  { id: 'initial_rating', label: 'Initial Rating', percentage: 10 },
  { id: 'project_overview', label: 'Project Overview', percentage: 20 },
  { id: 'primary_goal', label: 'Primary Goal', percentage: 30 },
  { id: 'target_audience', label: 'Target Audience', percentage: 40 },
  { id: 'video_style', label: 'Video Style & Tone', percentage: 50 },
  { id: 'narrative_approach', label: 'Narrative Approach', percentage: 60 },
  { id: 'visual_elements', label: 'Visual Elements', percentage: 70 },
  { id: 'technical_specs', label: 'Technical Specs', percentage: 80 },
  { id: 'production_constraints', label: 'Production Details', percentage: 90 },
  { id: 'review', label: 'Review & Finalize', percentage: 100 }
];

export const useProgress = () => {
  const [currentStepIndex, setCurrentStepIndex] = useState(0);
  const [isVisible, setIsVisible] = useState(true);

  const currentStep = PROGRESS_STEPS[currentStepIndex];
  const nextStep = PROGRESS_STEPS[currentStepIndex + 1] || null;
  const totalSteps = PROGRESS_STEPS.length - 1; // Exclude welcome step from count

  // Calculate display values
  const displayStep = Math.max(currentStepIndex, 1); // Don't show step 0
  const percentage = currentStep.percentage;

  // Update progress based on message content
  const updateProgressByContent = useCallback((messageContent: string) => {
    const lowerContent = messageContent.toLowerCase();
    
    // Map keywords to progress steps
    if (lowerContent.includes('rate your') || lowerContent.includes('scale of')) {
      setCurrentStepIndex(1); // Initial Rating
    } else if (lowerContent.includes('project overview') || lowerContent.includes('tell me about your video')) {
      setCurrentStepIndex(2); // Project Overview
    } else if (lowerContent.includes('primary goal') || lowerContent.includes('main objective')) {
      setCurrentStepIndex(3); // Primary Goal
    } else if (lowerContent.includes('target audience') || lowerContent.includes('who is this for')) {
      setCurrentStepIndex(4); // Target Audience
    } else if (lowerContent.includes('video style') || lowerContent.includes('tone')) {
      setCurrentStepIndex(5); // Video Style
    } else if (lowerContent.includes('narrative') || lowerContent.includes('storytelling')) {
      setCurrentStepIndex(6); // Narrative Approach
    } else if (lowerContent.includes('visual') && lowerContent.includes('element')) {
      setCurrentStepIndex(7); // Visual Elements
    } else if (lowerContent.includes('technical') || lowerContent.includes('specification')) {
      setCurrentStepIndex(8); // Technical Specs
    } else if (lowerContent.includes('production') || lowerContent.includes('constraint')) {
      setCurrentStepIndex(9); // Production Constraints
    } else if (lowerContent.includes('review') || lowerContent.includes('finalize')) {
      setCurrentStepIndex(10); // Review
    }
  }, []);

  // Manual progress control
  const goToNextStep = useCallback(() => {
    if (currentStepIndex < PROGRESS_STEPS.length - 1) {
      setCurrentStepIndex(prev => prev + 1);
    }
  }, [currentStepIndex]);

  const goToPreviousStep = useCallback(() => {
    if (currentStepIndex > 0) {
      setCurrentStepIndex(prev => prev - 1);
    }
  }, [currentStepIndex]);

  const resetProgress = useCallback(() => {
    setCurrentStepIndex(0);
    setIsVisible(true);
  }, []);

  const hideProgress = useCallback(() => {
    setIsVisible(false);
  }, []);

  const showProgress = useCallback(() => {
    setIsVisible(true);
  }, []);

  // Auto-hide when complete
  useEffect(() => {
    if (percentage === 100) {
      const timer = setTimeout(() => {
        setIsVisible(false);
      }, 3000); // Hide after 3 seconds at 100%
      return () => clearTimeout(timer);
    }
  }, [percentage]);

  return {
    currentStep: displayStep,
    totalSteps,
    currentStepLabel: currentStep.label,
    nextStepLabel: nextStep?.label,
    percentage,
    isVisible,
    updateProgressByContent,
    goToNextStep,
    goToPreviousStep,
    resetProgress,
    hideProgress,
    showProgress
  };
};
</file>

<file path="src/hooks/useSpeechToText.ts">
import { useState, useEffect, useRef, useCallback } from 'react';

// Manually define types for the Web Speech API to address TypeScript errors,
// as these are not standard in all TypeScript DOM library versions.
interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  maxAlternatives: number;
  onaudiostart: ((this: SpeechRecognition, ev: Event) => any) | null;
  onaudioend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => any) | null;
  onnomatch: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null;
  onsoundstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  onsoundend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onspeechstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  onspeechend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  abort(): void;
  start(): void;
  stop(): void;
}

interface SpeechRecognitionEvent extends Event {
  readonly resultIndex: number;
  readonly results: SpeechRecognitionResultList;
}

interface SpeechRecognitionResultList {
  readonly length: number;
  item(index: number): SpeechRecognitionResult;
  [index: number]: SpeechRecognitionResult;
}

interface SpeechRecognitionResult {
  readonly isFinal: boolean;
  readonly length: number;
  item(index: number): SpeechRecognitionAlternative;
  [index: number]: SpeechRecognitionAlternative;
}

interface SpeechRecognitionAlternative {
  readonly transcript: string;
  readonly confidence: number;
}

interface SpeechRecognitionErrorEvent extends Event {
  readonly error: string;
  readonly message: string;
}

const getSpeechRecognition = () => {
  if (typeof window !== 'undefined') {
    // Cast `window` to `any` to access non-standard SpeechRecognition APIs
    // without causing TypeScript compilation errors.
    return (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
  }
  return undefined;
};

export const useSpeechToText = () => {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  // Use the defined `SpeechRecognition` interface as the type for the ref.
  const recognitionRef = useRef<SpeechRecognition | null>(null);

  // Rename the `SpeechRecognition` constant to `SpeechRecognitionAPI` to avoid a naming
  // conflict with the `SpeechRecognition` interface type.
  const SpeechRecognitionAPI = getSpeechRecognition();

  const stopListening = useCallback(() => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }
  }, []);

  const startListening = useCallback(() => {
    if (isListening || !SpeechRecognitionAPI) {
      return;
    }

    const recognition = new SpeechRecognitionAPI();
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'en-US';

    recognition.onstart = () => {
      setIsListening(true);
      setTranscript('');
    };

    recognition.onend = () => {
      setIsListening(false);
      recognitionRef.current = null;
    };

    recognition.onerror = (event) => {
      console.error('Speech recognition error', event.error);
      stopListening();
    };

    recognition.onresult = (event) => {
      const fullTranscript = Array.from(event.results)
        .map((result) => result[0].transcript)
        .join('');
      setTranscript(fullTranscript);
    };
    
    recognitionRef.current = recognition;
    recognition.start();
  }, [SpeechRecognitionAPI, isListening, stopListening]);

  useEffect(() => {
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.abort();
      }
    };
  }, []);

  return {
    isListening,
    transcript,
    startListening,
    stopListening,
    isSttSupported: !!SpeechRecognitionAPI,
    setTranscript,
  };
};
</file>

<file path="src/hooks/useTextToSpeech.ts">
import { useState, useCallback, useEffect } from 'react';

export const useTextToSpeech = () => {
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isTtsEnabled, setIsTtsEnabled] = useState(true);

  const synth = window.speechSynthesis;

  const speak = useCallback((text: string) => {
    if (!synth || !isTtsEnabled) return;
    
    synth.cancel(); // Cancel any previous utterance
    const utterance = new SpeechSynthesisUtterance(text);
    
    utterance.onstart = () => setIsSpeaking(true);
    utterance.onend = () => setIsSpeaking(false);
    utterance.onerror = () => setIsSpeaking(false);
    
    synth.speak(utterance);
  }, [synth, isTtsEnabled]);

  const stop = useCallback(() => {
    if (synth) {
      synth.cancel();
      setIsSpeaking(false);
    }
  }, [synth]);
  
  useEffect(() => {
      return () => {
          if(synth) synth.cancel();
      }
  }, [synth]);

  return { isSpeaking, isTtsEnabled, setIsTtsEnabled, speak, stop };
};
</file>

<file path="src/types/speech.d.ts">
// TypeScript declarations for Web Speech API
declare global {
  interface Window {
    SpeechRecognition: typeof SpeechRecognition;
    webkitSpeechRecognition: typeof SpeechRecognition;
  }
}

export {};
</file>

<file path="src/utils/documentStorage.ts">
import { get, set, del, entries, clear } from 'idb-keyval';
import { VRDDocument } from './vrdFormatter';

const DOCUMENTS_KEY = 'vrd_documents';
const DOCUMENT_PREFIX = 'vrd_doc_';

export interface StoredDocument {
  id: string;
  title: string;
  createdAt: Date;
  updatedAt: Date;
  type: 'pdf' | 'markdown';
  size?: number;
  preview?: string; // First few lines for preview
}

class DocumentStorage {
  /**
   * Save a VRD document
   */
  async saveDocument(doc: VRDDocument): Promise<void> {
    try {
      // Save the full document
      await set(`${DOCUMENT_PREFIX}${doc.id}`, doc);

      // Update the documents index
      const index = await this.getDocumentsIndex();
      const storedDoc: StoredDocument = {
        id: doc.id,
        title: doc.title,
        createdAt: doc.createdAt,
        updatedAt: doc.updatedAt,
        type: doc.type,
        size: doc.blob ? doc.blob.size : 0,
        preview: this.generatePreview(doc)
      };

      const existingIndex = index.findIndex(d => d.id === doc.id);
      if (existingIndex !== -1) {
        index[existingIndex] = storedDoc;
      } else {
        index.push(storedDoc);
      }

      await set(DOCUMENTS_KEY, index);
    } catch (error) {
      console.error('Error saving document:', error);
      throw error;
    }
  }

  /**
   * Get a document by ID
   */
  async getDocument(id: string): Promise<VRDDocument | null> {
    try {
      const doc = await get(`${DOCUMENT_PREFIX}${id}`);
      if (doc) {
        // Convert dates back from strings
        doc.createdAt = new Date(doc.createdAt);
        doc.updatedAt = new Date(doc.updatedAt);
      }
      return doc || null;
    } catch (error) {
      console.error('Error getting document:', error);
      return null;
    }
  }

  /**
   * Get all documents index
   */
  async getDocumentsIndex(): Promise<StoredDocument[]> {
    try {
      const index = await get(DOCUMENTS_KEY);
      if (index) {
        // Convert dates back from strings
        return index.map((doc: any) => ({
          ...doc,
          createdAt: new Date(doc.createdAt),
          updatedAt: new Date(doc.updatedAt)
        }));
      }
      return [];
    } catch (error) {
      console.error('Error getting documents index:', error);
      return [];
    }
  }

  /**
   * Delete a document
   */
  async deleteDocument(id: string): Promise<void> {
    try {
      // Delete the document
      await del(`${DOCUMENT_PREFIX}${id}`);

      // Update the index
      const index = await this.getDocumentsIndex();
      const updatedIndex = index.filter(d => d.id !== id);
      await set(DOCUMENTS_KEY, updatedIndex);
    } catch (error) {
      console.error('Error deleting document:', error);
      throw error;
    }
  }

  /**
   * Delete all documents
   */
  async clearAllDocuments(): Promise<void> {
    try {
      // Get all entries to find document keys
      const allEntries = await entries();
      
      // Delete all document entries
      for (const [key] of allEntries) {
        if (typeof key === 'string' && key.startsWith(DOCUMENT_PREFIX)) {
          await del(key);
        }
      }

      // Clear the index
      await set(DOCUMENTS_KEY, []);
    } catch (error) {
      console.error('Error clearing all documents:', error);
      throw error;
    }
  }

  /**
   * Search documents by title
   */
  async searchDocuments(query: string): Promise<StoredDocument[]> {
    try {
      const index = await this.getDocumentsIndex();
      const searchTerm = query.toLowerCase();
      return index.filter(doc => 
        doc.title.toLowerCase().includes(searchTerm) ||
        (doc.preview && doc.preview.toLowerCase().includes(searchTerm))
      );
    } catch (error) {
      console.error('Error searching documents:', error);
      return [];
    }
  }

  /**
   * Get recent documents
   */
  async getRecentDocuments(limit: number = 10): Promise<StoredDocument[]> {
    try {
      const index = await this.getDocumentsIndex();
      return index
        .sort((a, b) => b.updatedAt.getTime() - a.updatedAt.getTime())
        .slice(0, limit);
    } catch (error) {
      console.error('Error getting recent documents:', error);
      return [];
    }
  }

  /**
   * Export a document as a file
   */
  async exportDocument(id: string, format: 'pdf' | 'markdown'): Promise<Blob | null> {
    try {
      const doc = await this.getDocument(id);
      if (!doc) return null;

      if (format === 'pdf' && doc.blob) {
        return doc.blob;
      }

      if (format === 'markdown') {
        // Convert to markdown if needed
        const { vrdFormatter } = await import('./vrdFormatter');
        const markdown = vrdFormatter.toMarkdown(doc);
        return new Blob([markdown], { type: 'text/markdown' });
      }

      return null;
    } catch (error) {
      console.error('Error exporting document:', error);
      return null;
    }
  }

  /**
   * Generate preview text for a document
   */
  private generatePreview(doc: VRDDocument): string {
    const preview = [];
    
    if (doc.content.projectOverview) {
      preview.push(doc.content.projectOverview.substring(0, 100));
    }
    
    if (doc.content.requirements.length > 0) {
      preview.push(doc.content.requirements[0]);
    }

    return preview.join(' ').substring(0, 200) + '...';
  }

  /**
   * Get storage usage stats
   */
  async getStorageStats(): Promise<{
    documentCount: number;
    totalSize: number;
  }> {
    try {
      const index = await this.getDocumentsIndex();
      const totalSize = index.reduce((acc, doc) => acc + (doc.size || 0), 0);
      
      return {
        documentCount: index.length,
        totalSize
      };
    } catch (error) {
      console.error('Error getting storage stats:', error);
      return { documentCount: 0, totalSize: 0 };
    }
  }
}

export const documentStorage = new DocumentStorage();
</file>

<file path="src/utils/settingsStorage.ts">
import { AppSettings, DEFAULT_SETTINGS } from '../types/settings';
import { KIJKO_SYSTEM_PROMPT } from '../constants';

const SETTINGS_KEY = 'kijko_app_settings';

// Initialize default settings with actual system prompt
const getDefaultSettings = (): AppSettings => ({
  ...DEFAULT_SETTINGS,
  systemPrompt: KIJKO_SYSTEM_PROMPT
});

/**
 * Load settings from localStorage with type safety and error handling
 */
export const loadSettings = (): AppSettings => {
  try {
    const stored = localStorage.getItem(SETTINGS_KEY);
    
    if (!stored) {
      return getDefaultSettings();
    }

    const parsed = JSON.parse(stored) as AppSettings;
    
    // Validate that all required properties exist
    if (
      typeof parsed.systemPrompt !== 'string' ||
      typeof parsed.selectedModel !== 'string' ||
      !parsed.systemPrompt.trim()
    ) {
      console.warn('Invalid settings found in localStorage, using defaults');
      return getDefaultSettings();
    }

    return {
      ...getDefaultSettings(),
      ...parsed
    };
  } catch (error) {
    console.error('Failed to load settings from localStorage:', error);
    return getDefaultSettings();
  }
};

/**
 * Save settings to localStorage with error handling
 */
export const saveSettings = (settings: AppSettings): boolean => {
  try {
    const serialized = JSON.stringify(settings);
    localStorage.setItem(SETTINGS_KEY, serialized);
    console.log('Settings saved successfully');
    return true;
  } catch (error) {
    console.error('Failed to save settings to localStorage:', error);
    return false;
  }
};

/**
 * Reset settings to default values
 */
export const resetSettings = (): AppSettings => {
  try {
    localStorage.removeItem(SETTINGS_KEY);
    console.log('Settings reset to defaults');
    return getDefaultSettings();
  } catch (error) {
    console.error('Failed to reset settings:', error);
    return getDefaultSettings();
  }
};

/**
 * Check if settings exist in localStorage
 */
export const hasStoredSettings = (): boolean => {
  try {
    return localStorage.getItem(SETTINGS_KEY) !== null;
  } catch (error) {
    return false;
  }
};

/**
 * Validate settings object structure
 */
export const validateSettings = (settings: unknown): settings is AppSettings => {
  if (!settings || typeof settings !== 'object') {
    return false;
  }

  const s = settings as Record<string, unknown>;
  
  return (
    typeof s.systemPrompt === 'string' &&
    typeof s.selectedModel === 'string' &&
    s.systemPrompt.trim().length > 0
  );
};
</file>

<file path="src/utils/vrdFormatter.ts">
import { Message } from '../types';
import TurndownService from 'turndown';

export interface VRDContent {
  projectOverview: string;
  requirements: string[];
  technicalSpecs: string;
  timeline: string;
  budget: string;
  additionalNotes?: string;
}

export interface VRDDocument {
  id: string;
  title: string;
  createdAt: Date;
  updatedAt: Date;
  content: VRDContent;
  conversationHistory: Message[];
  type: 'pdf' | 'markdown';
  blob?: Blob;
}

class VrdFormatter {
  private turndown: TurndownService;

  constructor() {
    this.turndown = new TurndownService({
      headingStyle: 'atx',
      hr: '---',
      bulletListMarker: '-',
      codeBlockStyle: 'fenced'
    });

    // Customize Turndown for better Markdown output
    this.turndown.addRule('emphasis', {
      filter: ['em', 'i'],
      replacement: function (content) {
        return '*' + content + '*';
      }
    });
  }

  /**
   * Formats chat messages into a structured VRD document
   */
  public formatVRD(messages: Message[], title: string): VRDDocument {
    const vrd: VRDDocument = {
      id: crypto.randomUUID(),
      title,
      createdAt: new Date(),
      updatedAt: new Date(),
      content: this.extractContent(messages),
      conversationHistory: messages,
      type: 'markdown'
    };

    return vrd;
  }

  /**
   * Extracts structured content from chat messages
   */
  private extractContent(messages: Message[]): VRDContent {
    // Initialize content sections
    const content: VRDContent = {
      projectOverview: '',
      requirements: [],
      technicalSpecs: '',
      timeline: '',
      budget: '',
      additionalNotes: ''
    };

    // Find relevant messages for each section
    messages.forEach(msg => {
      if (msg.role === 'assistant') {
        // Project Overview - usually at the start
        if (msg.text.toLowerCase().includes('project overview') || 
            msg.text.toLowerCase().includes('project description')) {
          content.projectOverview = this.extractSection(msg.text, 'project overview');
        }

        // Requirements - look for bullet points and numbered lists
        if (msg.text.toLowerCase().includes('requirements') ||
            msg.text.toLowerCase().includes('features needed')) {
          content.requirements = this.extractRequirements(msg.text);
        }

        // Technical Specs
        if (msg.text.toLowerCase().includes('technical') || 
            msg.text.toLowerCase().includes('specifications')) {
          content.technicalSpecs = this.extractSection(msg.text, 'technical specifications');
        }

        // Timeline
        if (msg.text.toLowerCase().includes('timeline') || 
            msg.text.toLowerCase().includes('schedule')) {
          content.timeline = this.extractSection(msg.text, 'timeline');
        }

        // Budget
        if (msg.text.toLowerCase().includes('budget') || 
            msg.text.toLowerCase().includes('cost')) {
          content.budget = this.extractSection(msg.text, 'budget');
        }
      }
    });

    return content;
  }

  /**
   * Extracts a specific section from text
   */
  private extractSection(text: string, sectionName: string): string {
    const sections = text.split(/(?=##?\s+[A-Z])/);
    const section = sections.find(s => 
      s.toLowerCase().includes(sectionName.toLowerCase())
    );
    return section ? this.cleanText(section) : '';
  }

  /**
   * Extracts requirements from text
   */
  private extractRequirements(text: string): string[] {
    const requirements: string[] = [];
    const lines = text.split('\n');

    let inRequirementsList = false;
    lines.forEach(line => {
      // Check if this is a requirement (starts with bullet or number)
      if (line.match(/^[-*•]|\d+\./)) {
        inRequirementsList = true;
        requirements.push(this.cleanText(line));
      } else if (inRequirementsList && line.trim() === '') {
        inRequirementsList = false;
      }
    });

    return requirements;
  }

  /**
   * Cleans and formats text
   */
  private cleanText(text: string): string {
    return text
      .replace(/^[-*•]\s+/, '') // Remove bullet points
      .replace(/^\d+\.\s+/, '') // Remove numbering
      .trim();
  }

  /**
   * Converts VRD to Markdown format
   */
  public toMarkdown(vrd: VRDDocument): string {
    let md = `# ${vrd.title}\n\n`;
    md += `_Generated on ${vrd.createdAt.toLocaleDateString()}_\n\n`;

    // Project Overview
    if (vrd.content.projectOverview) {
      md += `## Project Overview\n\n${vrd.content.projectOverview}\n\n`;
    }

    // Requirements
    if (vrd.content.requirements.length > 0) {
      md += '## Requirements\n\n';
      vrd.content.requirements.forEach(req => {
        md += `- ${req}\n`;
      });
      md += '\n';
    }

    // Technical Specifications
    if (vrd.content.technicalSpecs) {
      md += `## Technical Specifications\n\n${vrd.content.technicalSpecs}\n\n`;
    }

    // Timeline
    if (vrd.content.timeline) {
      md += `## Timeline\n\n${vrd.content.timeline}\n\n`;
    }

    // Budget
    if (vrd.content.budget) {
      md += `## Budget\n\n${vrd.content.budget}\n\n`;
    }

    // Additional Notes
    if (vrd.content.additionalNotes) {
      md += `## Additional Notes\n\n${vrd.content.additionalNotes}\n\n`;
    }

    return md;
  }

  /**
   * Converts HTML content to Markdown
   */
  public htmlToMarkdown(html: string): string {
    return this.turndown.turndown(html);
  }
}

export const vrdFormatter = new VrdFormatter();
</file>

<file path="constants.ts">
export const KIJKO_SYSTEM_PROMPT = `
You are Kijko, a multimodal, speech-enabled Video Brief Assistant that expertly guides users through creating comprehensive Video Requirements Documents (VRDs) and managing the entire video production process. You adapt your guidance level based on each user's clarity and experience, ensuring everyone—from complete beginners to seasoned professionals—can articulate and realize their video vision.

Your primary capabilities are:
1.  **Adaptive Discovery Engine**:
    *   **Vision Assessment**: Early in the conversation (within the first 3 exchanges), gauge the user's clarity level on a 1-10 scale. The prompt is: "To help me tailor our session perfectly for you, could you rate your current vision clarity on a scale of 1-10? 1 = 'I just know I need a video to achieve a business goal', 5 = 'I have a general concept and some specific ideas', 10 = 'I have detailed requirements including script, style, and technical specs'. Your answer helps me adjust my guidance level to match your needs."
    *   **Dynamic Adjustment**: Modify questioning depth and guidance based on the assessed level.
    *   **Intelligent Extraction**: Pull relevant information from vague ideas or detailed specifications.
    *   **Context Building**: Accumulate understanding through natural conversation flow.

2.  **Multi-Modal Processing**:
    *   **Language Detection**: Automatically detect and respond in the user's spoken/written language.
    *   **File Analysis**: Process images, videos, documents, and audio for context and reference. You will receive these as base64 encoded data. When a user provides a YouTube URL, analyze its content as a video reference.
    *   **Visual Understanding**: Extract style, mood, and composition from uploaded references.
    *   **Document Parsing**: Extract requirements from existing briefs, scripts, or guidelines.

3.  **VRD Generation Pipeline**:
    *   **Structured Documentation**: Create professional VRDs matching industry standards.
    *   **Component Assembly**: Build all required sections from gathered information.
    *   **Format Flexibility**: Adjust the detail level based on user needs and project scope.
    *   **Export Ready**: Generate publication-ready documents for stakeholder review when requested via the /export command.

**Conversation Framework & Questioning Strategy:**

*   **Phase 1: Initial Assessment (First 2-3 exchanges)**: Start with the opening engagement: "Hello! I'm Kijko, your video brief assistant. I'll help you create a comprehensive production plan for your video project. To get started, could you tell me about your video idea? Feel free to share as much or as little as you have in mind, and we'll build from there." Then, perform the Vision Clarity Assessment.
*   **Phase 2: Adaptive Discovery (Based on Clarity Score)**:
    *   **Low Clarity (1-3)**: Start with fundamental business questions, provide multiple-choice options, offer industry examples, use analogies, and provide heavy scaffolding with pre-filled suggestions.
    *   **Medium Clarity (4-7)**: Mix open and guided questions, probe for specifics, suggest options for uncertain areas, validate assumptions explicitly, and provide moderate guidance.
    *   **High Clarity (8-10)**: Ask direct, specific questions, focus on technical requirements, validate completeness with minimal hand-holding, and use expert-level terminology.
*   **Phase 3: Information Gathering (Core Discovery Questions adapted to clarity level)**: Cover Purpose & Goals, Audience, Message, Style & Tone, and Practical Constraints.
*   **Phase 4: Intelligent Assistance**: When the user is unclear, offer help: "I notice you might need some help with [specific aspect]. Would you like me to: A) Generate suggestions based on our conversation so far, B) Show you similar examples from other projects, C) Research best practices for your industry, D) Move on and revisit this later. Just pick a letter or describe what would help most."

**Interaction Commands (User Commands you must recognize and act upon):**
*   \`/clarity\` [1-10]: User adjusts guidance level mid-session.
*   \`/research\` [topic]: User invokes a research agent. You should perform a targeted search on the topic and provide a summary.
*   \`/example\` [type]: User requests relevant examples.
*   \`/template\` [industry]: User wants to load an industry template.
*   \`/review\`: User wants to see the current VRD draft. Summarize the collected information in the standard VRD sections.
*   \`/missing\`: User wants to know what's missing. Show incomplete sections.
*   \`/suggest\`: User wants suggestions for the current section.
*   \`/export\`: User wants the final VRD document. Present the complete VRD in a well-formatted, clean way, ready for copying.

**System Behaviors:**
*   **Progress Indicator**: Periodically, show the completion percentage of the VRD.
*   **Smart Prompts**: Offer pre-written options when detecting hesitation.
*   **Validation Loops**: Confirm your understanding of critical points.
*   **Information Display**: Use bullet points for clarity, provide inline examples, summarize periodically, and confirm before moving to new sections.

**Tone Adaptation:**
*   **Low clarity users**: Be encouraging, educational, and patient.
*   **Medium clarity users**: Be collaborative, validating, and guiding.
*   **High clarity users**: Be efficient, professional, and technical.

Your ultimate goal is to extract a professional, comprehensive VRD from any user, regardless of their initial clarity or experience level. Be adaptive, intelligent, and supportive while maintaining efficiency and professionalism.
`;
</file>

<file path="DEPLOY_GUIDE.md">
# Vercel Deployment Checklist

## Steps for React/Next.js MVP Deployment to Vercel via GitHub

• **Create GitHub Repository**: Initialize repo with main/master branch, add .gitignore for node_modules, .env.local, .vercel
• **Project Structure**: Ensure package.json in root with build/dev scripts, Next.js pages/app directory structure
• **Local Environment Setup**: Create .env.local for development variables, add to .gitignore 
• **Build Command**: Set "build": "next build" in package.json scripts
• **Output Directory**: Next.js outputs to .next/ (auto-detected by Vercel)
• **Connect to Vercel**: Import GitHub repo via Vercel dashboard, auto-detects Next.js framework
• **Environment Variables**: Add via Vercel dashboard Settings > Environment Variables
• **Sensitive Variables**: Toggle "Sensitive" switch for API keys (production/preview only)
• **Deploy Trigger**: Push to main branch triggers automatic production deployment
• **Preview Deployments**: Every PR/branch push creates preview URL automatically

## Common Pitfalls to Avoid

• **Missing .env Variables**: Add all required env vars in Vercel dashboard before deployment
• **Build Size Limits**: Keep bundle under 250MB, optimize images and dependencies  
• **Static Assets**: Place in public/ directory, not in pages or components
• **API Routes**: Use pages/api/ or app/api/ structure for serverless functions
• **Build Errors**: Test "npm run build" locally before pushing to GitHub
• **Wrong Branch**: Ensure main/master is default branch in GitHub settings

```yaml
# Vercel Deployment Checklist
vercel_deployment_checklist:
  pre_deployment:
    - task: "Create GitHub repo with main branch"
      status: "completed"
    - task: "Add .gitignore (node_modules, .env.local, .vercel)"  
      status: "completed"
    - task: "Verify package.json build script"
      status: "pending"
    - task: "Test local build with npm run build"
      status: "pending"
      
  vercel_setup:
    - task: "Import GitHub repo to Vercel dashboard"
      status: "pending"
    - task: "Add environment variables in Settings"
      status: "pending" 
    - task: "Mark sensitive vars (API keys) as Sensitive"
      status: "pending"
    - task: "Verify framework detection (Next.js)"
      status: "pending"
      
  post_deployment:
    - task: "Test production deployment URL"
      status: "pending"
    - task: "Verify environment variables loaded"  
      status: "pending"
    - task: "Check build logs for errors"
      status: "pending"
    - task: "Test preview deployment on PR"
      status: "pending"
```
</file>

<file path="DESKTOP_USAGE.md">
# Kijko Desktop Integration

This setup provides desktop shortcut functionality and app closing capabilities for the Kijko Video Brief Assistant.

## Files Created

1. **`launch-kijko.sh`** - Starts the Kijko app
2. **`kill-kijko.sh`** - Stops the app and frees all ports  
3. **`/home/david/Desktop/Kijko.desktop`** - Desktop shortcut (updated)

## How to Use

### Starting Kijko
- **Double-click** the "Kijko" desktop icon
- Or run: `./launch-kijko.sh` from terminal in this directory
- The app will start on `http://localhost:5173` and open automatically in your browser

### Closing Kijko

#### Method 1: Close Button (Recommended)
- Click the red **×** button in the top-right corner of the app
- Confirm when prompted
- The app will display a shutdown message and the browser will close
- The launcher script automatically detects the shutdown signal and kills all processes

#### Method 2: Terminal Command
- Run: `./kill-kijko.sh` from terminal in this directory
- This forcefully kills all app processes and frees ports

#### Method 3: Manual Cleanup
- If the app gets stuck, you can always run the kill script directly

## Features

### Desktop Shortcut
- **Name**: Kijko Video Brief Assistant
- **Location**: `/home/david/Desktop/Kijko.desktop`
- **Function**: Launches the app and opens browser automatically
- **Categories**: Development, AudioVideo, Graphics

### Process Management
- **PID Tracking**: App process ID saved to `/tmp/kijko-app.pid`
- **Port Management**: Automatically frees ports 5173, 3000, 4173, 8080
- **Process Cleanup**: Kills all related Vite/Node processes

### Shutdown Monitoring
- The launcher script monitors for shutdown signals
- Creates shutdown signal file in Downloads folder
- Automatically triggers cleanup when signal detected

## Troubleshooting

### App Won't Start
```bash
# Check if ports are in use
lsof -i :5173

# Kill any existing processes
./kill-kijko.sh

# Try starting again
./launch-kijko.sh
```

### App Won't Close
```bash
# Force kill all processes
./kill-kijko.sh

# Check if ports are free
lsof -i :5173
```

### Desktop Shortcut Not Working
```bash
# Make sure the desktop file is executable
chmod +x /home/david/Desktop/Kijko.desktop

# Test the launcher script directly
./launch-kijko.sh
```

## Technical Details

- **Framework**: React + Vite + TypeScript
- **Default Port**: 5173 (Vite dev server)
- **Process Monitoring**: PID file + signal file approach
- **Browser Integration**: Automatic opening via `xdg-open`
- **Cleanup**: Comprehensive process and port cleanup
</file>

<file path="ENHANCED_MCQ_README.md">
# Enhanced MCQ System Implementation

## Overview

The Multiple Choice Question (MCQ) system has been significantly enhanced to address the issues with irrelevant button options and improve user experience. The new implementation includes:

1. **Markdown Rendering**: Raw markdown asterisks are now properly rendered as **bold** and *italic* text
2. **Multi-Select Capability**: Support for checkbox-style multi-select options
3. **Auto-Detection**: Intelligent detection of multi-select scenarios based on content keywords
4. **Visual Enhancements**: Improved UI with proper indicators and animations
5. **Accessibility**: Better ARIA labels and semantic HTML structure

## Key Features

### 🎨 Visual Enhancements

- **Markdown Support**: Uses `react-markdown` to render option text with proper formatting
- **Checkbox Indicators**: Visual checkboxes for multi-select options
- **Radio Buttons**: Traditional radio buttons for single-select scenarios  
- **Responsive Layouts**: Adaptive short vs long option layouts
- **Smooth Animations**: Subtle transitions and hover effects
- **Loading States**: Visual feedback during processing

### ⚡ Interaction Features

- **Auto-Detection**: Automatically detects multi-select scenarios based on keywords:
  - `energetic`, `mysterious`, `style`, `tone` trigger multi-select mode
- **Contextual Hints**: "Select all that apply" tooltip for multi-select questions
- **Submit Button**: Confirmation button for multi-select with selection count
- **Immediate Response**: Single-select options trigger immediately
- **Multiple Selection Support**: Array-based state management for multiple choices

### 🔧 Technical Implementation

#### Component Structure

```typescript
interface OptionGroupProps {
  options: MCQOption[];
  onSelect: (option: MCQOption) => void;
  onSubmit?: (selectedOptions: MCQOption[]) => void; // For multi-select
  disabled?: boolean;
  short?: boolean; // Force short layout
  allowMultiple?: boolean; // Explicit multi-select override
}
```

#### Auto-Detection Logic

```typescript
const shouldAllowMultiple = allowMultiple || options.some(opt => 
  opt.text.toLowerCase().includes('energetic') || 
  opt.text.toLowerCase().includes('mysterious') ||
  opt.text.toLowerCase().includes('style') ||
  opt.text.toLowerCase().includes('tone')
);
```

#### Markdown Rendering

```typescript
<ReactMarkdown 
  components={{ 
    p: React.Fragment,
    strong: ({ children }) => <strong className="font-bold">{children}</strong>,
    em: ({ children }) => <em className="italic">{children}</em>
  }}
>
  {option.text}
</ReactMarkdown>
```

## Usage Examples

### Single Select (Default)
```jsx
<OptionGroup
  options={singleSelectOptions}
  onSelect={handleSingleSelect}
/>
```

### Auto-Detected Multi-Select
```jsx
<OptionGroup
  options={multiSelectOptions} // Contains keywords like "style", "tone"
  onSelect={handleSingleSelect} // Fallback for single selections
  onSubmit={handleMultiSelect} // For multi-select submissions
/>
```

### Explicit Multi-Select
```jsx
<OptionGroup
  options={explicitMultiSelect}
  onSelect={handleSingleSelect}
  onSubmit={handleExplicitMultiSelect}
  allowMultiple={true} // Force multi-select mode
/>
```

## Testing

A comprehensive test demo is available at `/mcq-test` route which demonstrates:

1. **Single Select Questions**: Traditional radio button behavior
2. **Auto-Detected Multi-Select**: Keywords trigger multi-select mode
3. **Explicit Multi-Select**: Manually enabled multi-select
4. **Markdown Rendering**: Bold and italic text formatting
5. **Selection Results**: Real-time feedback of user choices

## Files Modified

- `src/components/OptionGroup.tsx`: Core MCQ component with multi-select logic
- `src/components/MCQTestDemo.tsx`: Test demo component (new)
- `src/index.tsx`: Added router for test routes
- `package.json`: Added react-router-dom dependencies

## Benefits

### User Experience
- **Cleaner Interface**: No more raw markdown asterisks in button text
- **Intuitive Selection**: Clear visual indicators for single vs multi-select
- **Contextual Guidance**: Helpful hints and tooltips
- **Confirmation Flow**: Submit button prevents accidental submissions

### Developer Experience
- **Flexible API**: Supports both single and multi-select modes
- **Auto-Detection**: Reduces need for manual configuration
- **Type Safety**: Full TypeScript support with proper interfaces
- **Maintainable Code**: Clean separation of concerns

### Accessibility
- **Proper ARIA Roles**: `checkbox`, `radio`, `group`, `radiogroup`
- **Keyboard Navigation**: Full keyboard accessibility
- **Screen Reader Support**: Descriptive labels and states
- **Focus Management**: Clear focus indicators

## Future Enhancements

- **Conditional Logic**: Sequential question flows based on responses
- **Custom Input Fields**: Text input options alongside MCQ choices
- **Advanced Auto-Detection**: Machine learning-based detection
- **Analytics**: Track user interaction patterns
- **Themes**: Customizable visual themes for different contexts

## Demo Access

Visit `http://localhost:5174/mcq-test` to see the enhanced MCQ system in action with various test scenarios demonstrating all the new features.
</file>

<file path="index.html">
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Kijko Video Brief Assistant</title>
    <script src="https://cdn.tailwindcss.com"></script>
  <script type="importmap">
{
  "imports": {
    "react": "https://aistudiocdn.com/react@^19.1.1",
    "react/": "https://aistudiocdn.com/react@^19.1.1/",
    "react-dom/": "https://aistudiocdn.com/react-dom@^19.1.1/",
    "@google/genai": "https://aistudiocdn.com/@google/genai@^1.16.0"
  }
}
</script>
</head>
  <body class="bg-gray-900 text-white">
    <div id="root"></div>
    <script type="module" src="/src/index.tsx"></script>
  </body>
</html>
</file>

<file path="kijko-control.sh">
#!/bin/bash

# Kijko Control Script
# Provides easy commands to start/stop Kijko from anywhere

APP_DIR="/home/david/Projects/Kijko/MVP/MVP_Kijko"

case "$1" in
    start|launch|run)
        echo "Starting Kijko..."
        bash "$APP_DIR/launch-kijko.sh"
        ;;
    stop|kill|close)
        echo "Stopping Kijko..."
        bash "$APP_DIR/kill-kijko.sh"
        ;;
    restart)
        echo "Restarting Kijko..."
        bash "$APP_DIR/kill-kijko.sh"
        sleep 2
        bash "$APP_DIR/launch-kijko.sh"
        ;;
    status)
        PID_FILE="/tmp/kijko-app.pid"
        if [ -f "$PID_FILE" ] && ps -p "$(cat $PID_FILE)" > /dev/null 2>&1; then
            echo "Kijko is running (PID: $(cat $PID_FILE))"
            echo "App should be available at: http://localhost:5173"
        else
            echo "Kijko is not running"
        fi
        ;;
    *)
        echo "Kijko Control Script"
        echo ""
        echo "Usage: $0 {start|stop|restart|status}"
        echo ""
        echo "Commands:"
        echo "  start    - Launch Kijko app"
        echo "  stop     - Stop Kijko app and free all ports"
        echo "  restart  - Stop and start Kijko app"
        echo "  status   - Check if Kijko is running"
        echo ""
        echo "Desktop shortcut: Double-click Kijko icon on desktop"
        exit 1
        ;;
esac
</file>

<file path="kill-kijko.sh">
#!/bin/bash

# Kijko App Killer Script
# This script stops the Kijko application and frees up all ports

PID_FILE="/tmp/kijko-app.pid"
APP_NAME="kijko"

echo "Stopping Kijko app..."

# Kill process by PID file if it exists
if [ -f "$PID_FILE" ]; then
    PID=$(cat "$PID_FILE")
    if ps -p "$PID" > /dev/null 2>&1; then
        echo "Killing main process (PID: $PID)..."
        kill -TERM "$PID" 2>/dev/null || kill -KILL "$PID" 2>/dev/null
        sleep 1
    fi
    rm "$PID_FILE"
    echo "PID file removed"
fi

# Kill any remaining vite/node processes related to the app
echo "Killing any remaining Vite/Node processes..."
pkill -f "vite.*kijko" 2>/dev/null || true
pkill -f "node.*vite" 2>/dev/null || true
pkill -f "npm.*dev" 2>/dev/null || true

# Free up common development ports (5173 is Vite's default)
echo "Freeing up ports..."
for port in 5173 3000 4173 8080; do
    PID_ON_PORT=$(lsof -ti:$port 2>/dev/null)
    if [ -n "$PID_ON_PORT" ]; then
        echo "Killing process on port $port (PID: $PID_ON_PORT)"
        kill -TERM "$PID_ON_PORT" 2>/dev/null || kill -KILL "$PID_ON_PORT" 2>/dev/null
    fi
done

# Wait a moment for cleanup
sleep 1

# Verify ports are free
echo "Checking if ports are free..."
for port in 5173 3000 4173 8080; do
    if lsof -ti:$port > /dev/null 2>&1; then
        echo "Warning: Port $port is still in use"
    else
        echo "Port $port is free"
    fi
done

echo "Kijko app has been stopped and all ports freed!"
</file>

<file path="launch-kijko-absolute.sh">
#!/bin/bash

# Kijko App Launcher Script (Absolute Paths Version)
# This version uses absolute paths to avoid PATH issues

APP_DIR="/home/david/Projects/Kijko/MVP/MVP_Kijko"
PID_FILE="/tmp/kijko-app.pid"
NODE_BIN="/home/david/.nvm/versions/node/v24.4.1/bin"
NPM="$NODE_BIN/npm"
NODE="$NODE_BIN/node"

# Change to app directory
cd "$APP_DIR"

echo "=== Kijko Launcher (Absolute Paths) ==="
echo "App Directory: $APP_DIR"
echo "Node Binary: $NODE"
echo "NPM Binary: $NPM"

# Check if binaries exist
if [ ! -f "$NODE" ]; then
    echo "Error: Node.js not found at $NODE"
    echo "Please check your Node.js installation"
    exit 1
fi

if [ ! -f "$NPM" ]; then
    echo "Error: NPM not found at $NPM"
    echo "Please check your NPM installation"
    exit 1
fi

# Check if app is already running
if [ -f "$PID_FILE" ]; then
    if ps -p "$(cat $PID_FILE)" > /dev/null 2>&1; then
        echo "Kijko app is already running (PID: $(cat $PID_FILE))"
        # Open browser to the app
        xdg-open "http://localhost:5173" &
        exit 0
    else
        # Remove stale PID file
        rm "$PID_FILE"
    fi
fi

echo "Starting Kijko app..."

# Source NVM and start the development server
# This ensures the Node.js environment is properly set up
source /home/david/.nvm/nvm.sh
nvm use 24.4.1
npm run dev &
DEV_PID=$!

# Save the main process ID
echo $DEV_PID > "$PID_FILE"

echo "Kijko app started with PID: $DEV_PID"
echo "PID saved to $PID_FILE"

# Wait a moment for server to start
sleep 3

# Open browser to the app
echo "Opening browser..."
xdg-open "http://localhost:5173" &

echo "Kijko app is now running!"
echo "Use the close button in the app or run kill-kijko.sh to stop it."

# Monitor for shutdown signals in background
{
    while true; do
        # Check if PID file still exists and process is running
        if [ ! -f "$PID_FILE" ] || ! ps -p "$(cat $PID_FILE 2>/dev/null)" > /dev/null 2>&1; then
            break
        fi
        
        # Check for shutdown signal file in Downloads (where browser downloads go)
        if [ -f "/home/david/Downloads/kijko-shutdown-signal.txt" ]; then
            echo "Shutdown signal detected, stopping app..."
            rm "/home/david/Downloads/kijko-shutdown-signal.txt" 2>/dev/null
            bash "$APP_DIR/kill-kijko.sh"
            break
        fi
        
        sleep 2
    done
} &
</file>

<file path="launch-kijko.py">
#!/usr/bin/env python3

import os
import sys
import subprocess
import time
import webbrowser
from pathlib import Path

def main():
    # Configuration
    APP_DIR = "/home/david/Projects/Kijko/MVP/MVP_Kijko"
    PID_FILE = "/tmp/kijko-app.pid"
    NODE_BIN = "/home/david/.nvm/versions/node/v24.4.1/bin"
    NPM = f"{NODE_BIN}/npm"
    NODE = f"{NODE_BIN}/node"
    PORT = 5173
    
    print("=== Kijko Python Launcher ===")
    print(f"App Directory: {APP_DIR}")
    print(f"Node Binary: {NODE}")
    print(f"NPM Binary: {NPM}")
    
    # Change to app directory
    os.chdir(APP_DIR)
    
    # Check if binaries exist
    if not os.path.exists(NODE):
        print(f"Error: Node.js not found at {NODE}")
        print("Please check your Node.js installation")
        return 1
        
    if not os.path.exists(NPM):
        print(f"Error: NPM not found at {NPM}")
        print("Please check your NPM installation")
        return 1
    
    # Check if app is already running
    if os.path.exists(PID_FILE):
        try:
            with open(PID_FILE, 'r') as f:
                pid = int(f.read().strip())
            
            # Check if process is still running
            try:
                os.kill(pid, 0)  # Doesn't actually kill, just checks if process exists
                print(f"Kijko app is already running (PID: {pid})")
                webbrowser.open(f"http://localhost:{PORT}")
                return 0
            except OSError:
                # Process doesn't exist, remove stale PID file
                os.remove(PID_FILE)
        except (ValueError, FileNotFoundError):
            # Invalid or missing PID file
            if os.path.exists(PID_FILE):
                os.remove(PID_FILE)
    
    print("Starting Kijko app...")
    
    # Set up environment with proper NVM configuration
    env = os.environ.copy()
    env['PATH'] = f"{NODE_BIN}:{env.get('PATH', '')}"
    env['NVM_BIN'] = NODE_BIN
    env['NVM_DIR'] = "/home/david/.nvm"
    
    try:
        # Start the development server using bash with NVM sourcing
        # This ensures the Node.js environment is properly set up
        process = subprocess.Popen(
            [
                "bash", "-c",
                f"source /home/david/.nvm/nvm.sh && nvm use 24.4.1 && npm run dev"
            ],
            cwd=APP_DIR,
            env=env,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True
        )
        
        # Save the process ID
        with open(PID_FILE, 'w') as f:
            f.write(str(process.pid))
        
        print(f"Kijko app started with PID: {process.pid}")
        print(f"PID saved to {PID_FILE}")
        
        # Wait for server to start
        print("Waiting for server to start...")
        time.sleep(3)
        
        # Open browser
        print("Opening browser...")
        webbrowser.open(f"http://localhost:{PORT}")
        
        print("Kijko app is now running!")
        print("Use the close button in the app or run kill-kijko.sh to stop it.")
        
        # Monitor the process and output
        while True:
            output = process.stdout.readline()
            if output == '' and process.poll() is not None:
                break
            if output:
                print(output.strip())
        
        # Clean up PID file when process ends
        if os.path.exists(PID_FILE):
            os.remove(PID_FILE)
            
    except FileNotFoundError:
        print(f"Error: Could not execute {NPM}")
        print("Please check your Node.js/NPM installation")
        return 1
    except Exception as e:
        print(f"Error starting Kijko app: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="launch-kijko.sh">
#!/bin/bash

# Kijko App Launcher Script
# This script starts the Kijko application and saves the process ID

# Source user's profile to get full environment (including nvm)
[ -f "$HOME/.bashrc" ] && source "$HOME/.bashrc"
[ -f "$HOME/.profile" ] && source "$HOME/.profile"
[ -f "$HOME/.bash_profile" ] && source "$HOME/.bash_profile"

# Load nvm environment to access node/npm
export NVM_DIR="$HOME/.nvm"
[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"  # This loads nvm
[ -s "$NVM_DIR/bash_completion" ] && \. "$NVM_DIR/bash_completion"  # This loads nvm bash_completion

# Fallback: Set PATH directly to node installation
export PATH="$HOME/.nvm/versions/node/v24.4.1/bin:$PATH"

APP_DIR="/home/david/Projects/Kijko/MVP/MVP_Kijko"
PID_FILE="/tmp/kijko-app.pid"

# Change to app directory
cd "$APP_DIR"

# Debug: Check if npm is available
echo "Checking npm availability..."
which npm || echo "npm not found in PATH"
echo "Current PATH: $PATH"
echo "Node version: $(node --version 2>/dev/null || echo 'node not found')"
echo "NPM version: $(npm --version 2>/dev/null || echo 'npm not found')"

# Check if app is already running
if [ -f "$PID_FILE" ]; then
    if ps -p "$(cat $PID_FILE)" > /dev/null 2>&1; then
        echo "Kijko app is already running (PID: $(cat $PID_FILE))"
        # Open browser to the app
        xdg-open "http://localhost:5173" &
        exit 0
    else
        # Remove stale PID file
        rm "$PID_FILE"
    fi
fi

echo "Starting Kijko app..."

# Start the development server in background
npm run dev &
DEV_PID=$!

# Save the main process ID
echo $DEV_PID > "$PID_FILE"

echo "Kijko app started with PID: $DEV_PID"
echo "PID saved to $PID_FILE"

# Wait a moment for server to start
sleep 3

# Open browser to the app
echo "Opening browser..."
xdg-open "http://localhost:5173" &

echo "Kijko app is now running!"
echo "Use the close button in the app or run kill-kijko.sh to stop it."

# Monitor for shutdown signals in background
{
    while true; do
        # Check if PID file still exists and process is running
        if [ ! -f "$PID_FILE" ] || ! ps -p "$(cat $PID_FILE 2>/dev/null)" > /dev/null 2>&1; then
            break
        fi
        
        # Check for shutdown signal file in Downloads (where browser downloads go)
        if [ -f "/home/david/Downloads/kijko-shutdown-signal.txt" ]; then
            echo "Shutdown signal detected, stopping app..."
            rm "/home/david/Downloads/kijko-shutdown-signal.txt" 2>/dev/null
            bash "$APP_DIR/kill-kijko.sh"
            break
        fi
        
        sleep 2
    done
} &
</file>

<file path="metadata.json">
{
  "name": "Kijko Video Brief Assistant",
  "description": "A multimodal, speech-enabled Video Brief Assistant that expertly guides users through creating comprehensive Video Requirements Documents (VRDs) and managing the entire video production process.",
  "requestFramePermissions": [
    "microphone"
  ]
}
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2022",
    "experimentalDecorators": true,
    "useDefineForClassFields": false,
    "module": "ESNext",
    "lib": [
      "ES2022",
      "DOM",
      "DOM.Iterable"
    ],
    "skipLibCheck": true,
    "types": [
      "node"
    ],
    "moduleResolution": "bundler",
    "isolatedModules": true,
    "moduleDetection": "force",
    "allowJs": true,
    "jsx": "react-jsx",
    "paths": {
      "@/*": [
        "./*"
      ]
    },
    "allowImportingTsExtensions": true,
    "noEmit": true
  }
}
</file>

<file path="types.ts">
export interface UIMessage {
  id: string;
  role: 'user' | 'model';
  text: string;
  attachments: UIAttachment[];
  isStreaming?: boolean;
}

export interface UIAttachment {
  name: string;
  type: string; 
  size: number;
}

export interface Attachment extends UIAttachment {
  data: string; // base64
}

export type MessagePart = {
  text?: string;
  inlineData?: {
    mimeType: string;
    data: string; // base64
  };
};
</file>

<file path="components/Header.tsx">
import React from 'react';
import { SpeakerOnIcon, SpeakerOffIcon } from './icons/SpeakerIcons';

interface HeaderProps {
    isTtsEnabled: boolean;
    setIsTtsEnabled: (enabled: boolean) => void;
    isSpeaking: boolean;
    stopSpeech: () => void;
}

export const Header: React.FC<HeaderProps> = ({ isTtsEnabled, setIsTtsEnabled, isSpeaking, stopSpeech }) => {
    const handleToggle = () => {
        if (isSpeaking) {
            stopSpeech();
        }
        setIsTtsEnabled(!isTtsEnabled);
    };

    const handleCloseApp = () => {
        if (confirm('Are you sure you want to close Kijko? This will stop the app and free all ports.')) {
            // Create a shutdown signal file that the launcher script will detect
            const shutdownSignal = new Blob(['shutdown-requested'], { type: 'text/plain' });
            const url = URL.createObjectURL(shutdownSignal);
            const a = document.createElement('a');
            a.href = url;
            a.download = 'kijko-shutdown-signal.txt';
            a.style.display = 'none';
            document.body.appendChild(a);
            a.click();
            
            // Clean up after a short delay
            setTimeout(() => {
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
            }, 1000);
            
            // Show shutdown message and close
            setTimeout(() => {
                document.body.innerHTML = '<div style="display:flex;align-items:center;justify-content:center;height:100vh;font-family:sans-serif;background:#111;color:white;flex-direction:column;text-align:center;"><h1 style="color:#ef4444;margin-bottom:20px;">🔴 Kijko Shutting Down</h1><p style="margin-bottom:10px;">The app is being closed and all processes will be terminated.</p><p style="margin-bottom:20px;">The server should stop automatically within a few seconds.</p><p style="font-size:14px;color:#888;">You can safely close this browser tab now.</p></div>';
            }, 500);
        }
    };

  return (
    <header className="flex items-center justify-between p-4 bg-gray-900 border-b border-gray-700 shadow-md flex-shrink-0">
      <div className="flex items-center space-x-2">
        <div className="w-8 h-8 bg-indigo-500 rounded-full"></div>
        <h1 className="text-2xl font-bold text-white tracking-wider">Kijko</h1>
      </div>
      <div className="flex items-center space-x-2">
        <button 
          onClick={handleToggle}
          className={`p-2 rounded-full transition-colors duration-200 ${isTtsEnabled ? 'bg-indigo-500 hover:bg-indigo-600' : 'bg-gray-600 hover:bg-gray-500'}`}
          aria-label={isTtsEnabled ? "Disable Text-to-Speech" : "Enable Text-to-Speech"}
        >
          {isTtsEnabled ? <SpeakerOnIcon className="w-6 h-6 text-white" /> : <SpeakerOffIcon className="w-6 h-6 text-white" />}
        </button>
        <button 
          onClick={handleCloseApp}
          className="p-2 rounded-full bg-red-500 hover:bg-red-600 transition-colors duration-200"
          aria-label="Close App"
          title="Close Kijko App"
        >
          <svg className="w-6 h-6 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
          </svg>
        </button>
      </div>
    </header>
  );
};
</file>

<file path="src/components/CircularProgress.tsx">
import React from 'react';

interface CircularProgressProps {
  percentage: number;
  size?: number;
  strokeWidth?: number;
  className?: string;
}

export const CircularProgress: React.FC<CircularProgressProps> = ({ 
  percentage, 
  size = 120,
  strokeWidth = 8,
  className = ''
}) => {
  const radius = (size - strokeWidth) / 2;
  const circumference = radius * 2 * Math.PI;
  const strokeDashoffset = circumference - (percentage / 100) * circumference;

  return (
    <svg 
      width={size} 
      height={size}
      className={className}
      role="progressbar"
      aria-valuenow={percentage}
      aria-valuemin={0}
      aria-valuemax={100}
      aria-label={`Progress: ${Math.round(percentage)}%`}
    >
      {/* Background circle */}
      <circle
        cx={size / 2}
        cy={size / 2}
        r={radius}
        fill="none"
        stroke="#374151"
        strokeWidth={strokeWidth}
        opacity={0.2}
      />
      
      {/* Progress circle */}
      <circle
        cx={size / 2}
        cy={size / 2}
        r={radius}
        fill="none"
        stroke="url(#progressGradient)"
        strokeWidth={strokeWidth}
        strokeDasharray={circumference}
        strokeDashoffset={strokeDashoffset}
        strokeLinecap="round"
        transform={`rotate(-90 ${size / 2} ${size / 2})`}
        style={{
          transition: 'stroke-dashoffset 0.5s cubic-bezier(0.4, 0, 0.2, 1)',
          filter: 'drop-shadow(0 0 6px rgba(147, 51, 234, 0.4))'
        }}
      />
      
      {/* Subtle glow effect on progress arc */}
      <circle
        cx={size / 2}
        cy={size / 2}
        r={radius}
        fill="none"
        stroke="url(#progressGradient)"
        strokeWidth={strokeWidth + 2}
        strokeDasharray={circumference}
        strokeDashoffset={strokeDashoffset}
        strokeLinecap="round"
        transform={`rotate(-90 ${size / 2} ${size / 2})`}
        opacity={0.2}
        style={{
          transition: 'stroke-dashoffset 0.5s cubic-bezier(0.4, 0, 0.2, 1)',
          filter: 'blur(4px)'
        }}
      />
      
      {/* Gradient definitions */}
      <defs>
        <linearGradient id="progressGradient" x1="0%" y1="0%" x2="100%" y2="100%">
          <stop offset="0%" stopColor="#9333ea">
            <animate attributeName="stop-color" values="#9333ea;#ec4899;#9333ea" dur="3s" repeatCount="indefinite" />
          </stop>
          <stop offset="100%" stopColor="#ec4899">
            <animate attributeName="stop-color" values="#ec4899;#9333ea;#ec4899" dur="3s" repeatCount="indefinite" />
          </stop>
        </linearGradient>
      </defs>
    </svg>
  );
};
</file>

<file path="src/components/GeminiVoiceChat.tsx">
import React, { useState, useRef, useEffect } from 'react';
import { GoogleGenerativeAI } from '@google/generative-ai';

interface Voice {
  id: string;
  name: string;
  description: string;
}

// Available browser speech synthesis voices (will be populated dynamically)
const getAvailableVoices = (): Voice[] => {
  if ('speechSynthesis' in window) {
    const voices = speechSynthesis.getVoices();
    return voices.map(voice => ({
      id: voice.name,
      name: voice.name,
      description: `${voice.lang} - ${voice.localService ? 'Local' : 'Remote'}`
    }));
  }
  return [
    { id: 'default', name: 'Default', description: 'System Default' }
  ];
};

const GeminiVoiceChat: React.FC = () => {
  const [availableVoices, setAvailableVoices] = useState<Voice[]>([]);
  const [selectedVoice, setSelectedVoice] = useState<string>('');
  const [inputText, setInputText] = useState<string>('');
  const [audioUrl, setAudioUrl] = useState<string | null>(null);
  const [loading, setLoading] = useState<boolean>(false);
  const [error, setError] = useState<string | null>(null);
  const [isListening, setIsListening] = useState<boolean>(false);
  const [responseText, setResponseText] = useState<string>('');
  const audioRef = useRef<HTMLAudioElement>(null);
  const recognitionRef = useRef<any>(null);

  // Initialize Gemini AI
  const genAI = new GoogleGenerativeAI(process.env.REACT_APP_GEMINI_API_KEY);

  // Load available voices
  useEffect(() => {
    const loadVoices = () => {
      const voices = getAvailableVoices();
      setAvailableVoices(voices);
      if (voices.length > 0 && !selectedVoice) {
        setSelectedVoice(voices[0].id);
      }
    };

    // Load voices immediately
    loadVoices();

    // Also load when voices change (some browsers load them asynchronously)
    if ('speechSynthesis' in window) {
      speechSynthesis.onvoiceschanged = loadVoices;
    }

    return () => {
      if ('speechSynthesis' in window) {
        speechSynthesis.onvoiceschanged = null;
      }
    };
  }, [selectedVoice]);

  // Initialize speech recognition
  useEffect(() => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognitionRef.current = new SpeechRecognition();
      recognitionRef.current.continuous = false;
      recognitionRef.current.interimResults = false;
      recognitionRef.current.lang = 'en-US';

      recognitionRef.current.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        setInputText(transcript);
        setIsListening(false);
      };

      recognitionRef.current.onerror = (event) => {
        console.error('Speech recognition error:', event.error);
        setIsListening(false);
        setError('Speech recognition failed. Please try again.');
      };

      recognitionRef.current.onend = () => {
        setIsListening(false);
      };
    }

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, []);

  // Handle voice selection
  const handleVoiceChange = (e: React.ChangeEvent<HTMLSelectElement>) => {
    setSelectedVoice(e.target.value);
  };

  // Start speech recognition
  const startListening = () => {
    if (recognitionRef.current && !isListening) {
      setError(null);
      setIsListening(true);
      recognitionRef.current.start();
    }
  };

  // Stop speech recognition
  const stopListening = () => {
    if (recognitionRef.current && isListening) {
      recognitionRef.current.stop();
      setIsListening(false);
    }
  };

  // Convert base64 to audio blob
  const base64ToBlob = (base64Data, mimeType = 'audio/wav') => {
    const byteCharacters = atob(base64Data);
    const byteNumbers = new Array(byteCharacters.length);
    for (let i = 0; i < byteCharacters.length; i++) {
      byteNumbers[i] = byteCharacters.charCodeAt(i);
    }
    const byteArray = new Uint8Array(byteNumbers);
    return new Blob([byteArray], { type: mimeType });
  };

  // Generate audio response using Gemini Live API
  const generateAudioResponse = async (text: string) => {
    try {
      setLoading(true);
      setError(null);
      setAudioUrl(null);
      setResponseText('');

      const model = genAI.getGenerativeModel({
        model: 'gemini-2.5-flash'
      });

      // First generate text response
      const result = await model.generateContent({
        contents: [{ 
          role: 'user', 
          parts: [{ text: text }] 
        }]
      });

      const textResponse = result.response.text();
      setResponseText(textResponse);
      
      // Then convert to speech using Web Speech API
      if ('speechSynthesis' in window) {
        const utterance = new SpeechSynthesisUtterance(textResponse);
        
        // Set voice based on selection
        const voices = speechSynthesis.getVoices();
        const selectedVoiceObj = voices.find(voice => voice.name === selectedVoice) || voices[0];
        if (selectedVoiceObj) {
          utterance.voice = selectedVoiceObj;
        }
        
        // Configure speech settings
        utterance.rate = 1.0;
        utterance.pitch = 1.0;
        utterance.volume = 1.0;
        
        // Speak the response
        speechSynthesis.speak(utterance);
        
        // Mark as playing
        setAudioUrl('speech-synthesis-playing');
        
        // Clear the playing status when done
        utterance.onend = () => {
          setAudioUrl(null);
        };
      } else {
        throw new Error('Speech synthesis not supported in this browser');
      }
    } catch (err: any) {
      console.error('Gemini API error:', err);
      setError(`Failed to generate audio: ${err.message}`);
    } finally {
      setLoading(false);
    }
  };

  // Handle form submission
  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!inputText.trim()) {
      setError('Please enter some text or use voice input');
      return;
    }
    await generateAudioResponse(inputText.trim());
  };

  // Cleanup audio URLs
  useEffect(() => {
    return () => {
      if (audioUrl) {
        URL.revokeObjectURL(audioUrl);
      }
    };
  }, [audioUrl]);

  return (
    <div className="max-w-2xl mx-auto p-6 bg-white rounded-lg shadow-lg">
      <h2 className="text-2xl font-bold mb-6 text-center text-gray-800">
        Gemini Voice Chat
      </h2>

      {/* Voice Selection */}
      <div className="mb-6">
        <label className="block text-sm font-medium text-gray-700 mb-2">
          Select Voice:
        </label>
        <select 
          value={selectedVoice}
          onChange={handleVoiceChange}
          className="w-full p-3 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
        >
          {availableVoices.map((voice) => (
            <option key={voice.id} value={voice.id}>
              {voice.name} ({voice.description})
            </option>
          ))}
        </select>
      </div>

      {/* Input Form */}
      <form onSubmit={handleSubmit} className="mb-6">
        <div className="mb-4">
          <label className="block text-sm font-medium text-gray-700 mb-2">
            Message:
          </label>
          <div className="flex gap-2">
            <textarea
              value={inputText}
              onChange={(e) => setInputText(e.target.value)}
              placeholder="Type your message here..."
              rows={3}
              className="flex-1 p-3 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
            />
            <div className="flex flex-col gap-2">
              {recognitionRef.current && (
                <button
                  type="button"
                  onClick={isListening ? stopListening : startListening}
                  className={`p-3 rounded-md text-white font-medium transition-colors ${
                    isListening 
                      ? 'bg-red-500 hover:bg-red-600' 
                      : 'bg-green-500 hover:bg-green-600'
                  }`}
                >
                  {isListening ? '🛑' : '🎤'}
                </button>
              )}
            </div>
          </div>
        </div>

        <button
          type="submit"
          disabled={loading || isListening}
          className={`w-full p-3 rounded-md text-white font-medium transition-colors ${
            loading || isListening
              ? 'bg-gray-400 cursor-not-allowed'
              : 'bg-blue-500 hover:bg-blue-600'
          }`}
        >
          {loading ? 'Generating Audio...' : 'Generate Voice Response'}
        </button>
      </form>

      {/* Status Messages */}
      {isListening && (
        <div className="mb-4 p-3 bg-blue-100 border border-blue-300 rounded-md text-blue-800">
          🎤 Listening... Speak now!
        </div>
      )}

      {error && (
        <div className="mb-4 p-3 bg-red-100 border border-red-300 rounded-md text-red-800">
          {error}
        </div>
      )}

      {/* Response Display */}
      {responseText && (
        <div className="mb-4">
          <div className="p-4 bg-green-50 border border-green-300 rounded-md">
            <div className="flex items-center justify-between mb-3">
              <p className="text-green-800">
                ✅ Response generated with voice: <strong>{availableVoices.find(v => v.id === selectedVoice)?.name || selectedVoice}</strong>
              </p>
              {audioUrl === 'speech-synthesis-playing' && (
                <span className="text-blue-600 text-sm flex items-center">
                  🔊 Speaking...
                </span>
              )}
            </div>
            <div className="bg-white p-3 rounded border text-gray-800">
              <strong>Response:</strong> {responseText}
            </div>
            <div className="mt-2 text-sm text-gray-600">
              Using browser speech synthesis
            </div>
          </div>
        </div>
      )}

      {/* Instructions */}
      <div className="text-sm text-gray-600 bg-gray-50 p-4 rounded-md">
        <h3 className="font-medium mb-2">Instructions:</h3>
        <ul className="list-disc list-inside space-y-1">
          <li>Select your preferred voice from the dropdown</li>
          <li>Type your message or use the microphone button for voice input</li>
          <li>Click "Generate Voice Response" to hear Gemini's reply</li>
          <li>The audio will auto-play when ready</li>
        </ul>
      </div>
    </div>
  );
};

export default GeminiVoiceChat;
</file>

<file path="src/components/ModelSelector.tsx">
import React, { useState, useRef, useEffect } from 'react';
import { ChevronDownIcon, SparklesIcon, CpuChipIcon, BeakerIcon, PhotoIcon, RocketLaunchIcon } from '@heroicons/react/24/outline';
import { GeminiModel, GEMINI_MODELS, ModelOption } from '../types/settings';

interface ModelSelectorProps {
  value: GeminiModel;
  onChange: (model: GeminiModel) => void;
  disabled?: boolean;
  error?: string;
}

export const ModelSelector: React.FC<ModelSelectorProps> = ({
  value,
  onChange,
  disabled = false,
  error
}) => {
  const [isOpen, setIsOpen] = useState(false);
  const dropdownRef = useRef<HTMLDivElement>(null);
  const buttonRef = useRef<HTMLButtonElement>(null);

  // Close dropdown when clicking outside
  useEffect(() => {
    const handleClickOutside = (event: MouseEvent) => {
      if (
        dropdownRef.current &&
        !dropdownRef.current.contains(event.target as Node) &&
        !buttonRef.current?.contains(event.target as Node)
      ) {
        setIsOpen(false);
      }
    };

    if (isOpen) {
      document.addEventListener('mousedown', handleClickOutside);
    }

    return () => {
      document.removeEventListener('mousedown', handleClickOutside);
    };
  }, [isOpen]);

  // Get selected model info
  const selectedModel = GEMINI_MODELS.find(model => model.value === value);

  // Group models by generation and category
  const modelsByGeneration = {
    '2.5': GEMINI_MODELS.filter(model => model.generation === '2.5'),
    '2.0': GEMINI_MODELS.filter(model => model.generation === '2.0'),
    '1.5': GEMINI_MODELS.filter(model => model.generation === '1.5')
  };

  const handleSelect = (model: GeminiModel) => {
    onChange(model);
    setIsOpen(false);
  };

  const getCategoryIcon = (category: ModelOption['category']) => {
    switch (category) {
      case 'pro':
        return <CpuChipIcon className="w-4 h-4 text-blue-400" />;
      case 'flash':
        return <SparklesIcon className="w-4 h-4 text-yellow-400" />;
      case 'flash-lite':
        return <RocketLaunchIcon className="w-4 h-4 text-green-400" />;
      case 'experimental':
        return <BeakerIcon className="w-4 h-4 text-purple-400" />;
      case 'image':
        return <PhotoIcon className="w-4 h-4 text-pink-400" />;
      default:
        return <SparklesIcon className="w-4 h-4 text-gray-400" />;
    }
  };

  const getModelTip = (category: ModelOption['category']) => {
    switch (category) {
      case 'pro':
        return 'Best for complex reasoning, analysis, and professional tasks requiring highest quality output.';
      case 'flash':
        return 'Perfect balance of speed and quality for most conversational AI applications.';
      case 'flash-lite':
        return 'Optimized for high-throughput scenarios where speed and cost efficiency are priorities.';
      case 'experimental':
        return 'Cutting-edge features but may have stability issues. Great for testing new capabilities.';
      case 'image':
        return 'Specialized for image understanding and analysis tasks with fast processing.';
      default:
        return 'General-purpose model suitable for various AI tasks.';
    }
  };

  const GenerationSection: React.FC<{ models: ModelOption[]; generation: string }> = ({
    models,
    generation
  }) => {
    if (models.length === 0) return null;
    
    const generationLabels = {
      '2.5': '2.5 Series - Latest & Most Powerful',
      '2.0': '2.0 Series - Current Generation', 
      '1.5': '1.5 Series - Legacy Support'
    };
    
    return (
      <div>
        <div className="flex items-center gap-2 px-3 py-2 text-xs font-medium text-gray-300 bg-gray-800/50 border-b border-gray-700">
          <span className="text-purple-400 font-bold">Gemini {generation}</span>
          <span className="text-gray-500">•</span>
          <span>{generationLabels[generation as keyof typeof generationLabels]}</span>
        </div>
        {models.map((model) => (
          <button
            key={model.value}
            onClick={() => handleSelect(model.value)}
            className={`
              w-full text-left px-4 py-3 hover:bg-gray-700/50 transition-colors border-b border-gray-800/50 last:border-b-0
              ${value === model.value ? 'bg-purple-600/20 text-purple-300' : 'text-gray-200'}
            `}
          >
            <div className="flex items-start justify-between gap-3">
              <div className="flex-1 min-w-0">
                <div className="flex items-center gap-2 mb-1">
                  {getCategoryIcon(model.category)}
                  <span className="font-medium">{model.label}</span>
                  {value === model.value && (
                    <div className="w-2 h-2 bg-purple-400 rounded-full"></div>
                  )}
                </div>
                <p className="text-sm text-gray-400 mb-2 line-clamp-2">
                  {model.description}
                </p>
                <div className="flex items-center gap-3 text-xs text-gray-500">
                  <span className="flex items-center gap-1">
                    <span className="w-1 h-1 bg-yellow-400 rounded-full"></span>
                    Speed: {model.performance}
                  </span>
                  <span className="flex items-center gap-1">
                    <span className="w-1 h-1 bg-green-400 rounded-full"></span>
                    Quality: {model.quality}
                  </span>
                  {model.contextLength && (
                    <span className="flex items-center gap-1">
                      <span className="w-1 h-1 bg-blue-400 rounded-full"></span>
                      Context: {model.contextLength}
                    </span>
                  )}
                </div>
              </div>
            </div>
          </button>
        ))}
      </div>
    );
  };

  return (
    <div className="space-y-4">
      {/* Header */}
      <div>
        <h3 className="text-lg font-semibold text-white">AI Model</h3>
        <p className="text-sm text-gray-400">
          Choose the Gemini model for conversation processing
        </p>
      </div>

      {/* Error Message */}
      {error && (
        <div className="p-3 bg-red-500/10 border border-red-500/20 rounded-lg">
          <p className="text-sm text-red-400">{error}</p>
        </div>
      )}

      {/* Model Selector */}
      <div className="relative">
        <button
          ref={buttonRef}
          onClick={() => !disabled && setIsOpen(!isOpen)}
          disabled={disabled}
          className={`
            w-full flex items-center justify-between gap-3 p-4
            bg-gray-800 border border-gray-700 rounded-lg
            hover:border-gray-600 focus:border-purple-500/50 focus:ring-1 focus:ring-purple-500/20
            transition-colors
            ${disabled ? 'opacity-50 cursor-not-allowed' : 'cursor-pointer'}
            ${isOpen ? 'border-purple-500/50 ring-1 ring-purple-500/20' : ''}
          `}
        >
          <div className="flex items-center gap-3 flex-1 min-w-0">
            {selectedModel && getCategoryIcon(selectedModel.category)}
            <div className="flex-1 min-w-0 text-left">
              <p className="font-medium text-white truncate">
                {selectedModel?.label || 'Select Model'}
              </p>
              {selectedModel && (
                <p className="text-sm text-gray-400 truncate">
                  {selectedModel.description}
                </p>
              )}
            </div>
          </div>
          <ChevronDownIcon 
            className={`w-5 h-5 text-gray-400 transition-transform ${
              isOpen ? 'rotate-180' : ''
            }`} 
          />
        </button>

        {/* Dropdown */}
        {isOpen && (
          <div
            ref={dropdownRef}
            className="
              absolute top-full left-0 right-0 mt-2 z-50
              bg-gray-800 border border-gray-700 rounded-lg
              shadow-xl shadow-black/20
              max-h-96 overflow-y-auto
            "
          >
            {Object.entries(modelsByGeneration).map(([generation, models]) => (
              <GenerationSection
                key={generation}
                models={models}
                generation={generation}
              />
            ))}
          </div>
        )}
      </div>

      {/* Model Information */}
      {selectedModel && (
        <div className="p-4 bg-gray-800/50 border border-gray-700 rounded-lg">
          <div className="flex items-center gap-3 mb-3">
            {getCategoryIcon(selectedModel.category)}
            <div>
              <span className="text-sm font-medium text-white block">
                Gemini {selectedModel.generation} • {selectedModel.category.charAt(0).toUpperCase() + selectedModel.category.slice(1).replace('-', ' ')}
              </span>
              <span className="text-xs text-gray-400">
                Performance: {selectedModel.performance} • Quality: {selectedModel.quality}
              </span>
            </div>
          </div>
          
          <div className="grid grid-cols-2 gap-3 text-xs">
            <div className="bg-gray-700/30 rounded p-2">
              <span className="text-gray-400 block">Speed</span>
              <span className="text-white font-medium">{selectedModel.performance}</span>
            </div>
            <div className="bg-gray-700/30 rounded p-2">
              <span className="text-gray-400 block">Quality</span>
              <span className="text-white font-medium">{selectedModel.quality}</span>
            </div>
            {selectedModel.contextLength && (
              <div className="bg-gray-700/30 rounded p-2 col-span-2">
                <span className="text-gray-400 block">Context Length</span>
                <span className="text-white font-medium">{selectedModel.contextLength}</span>
              </div>
            )}
          </div>
          
          <div className="mt-3 p-2 bg-blue-500/10 border border-blue-500/20 rounded text-xs text-blue-200">
            <strong>💡 Tip:</strong> {getModelTip(selectedModel.category)}
          </div>
        </div>
      )}
    </div>
  );
};
</file>

<file path="src/contexts/SettingsContext.tsx">
import React, { createContext, useContext, useReducer, useEffect, ReactNode } from 'react';
import { AppSettings, SettingsAction, GeminiModel } from '../types/settings';
import { loadSettings, saveSettings, resetSettings } from '../utils/settingsStorage';

// Settings reducer
const settingsReducer = (state: AppSettings, action: SettingsAction): AppSettings => {
  switch (action.type) {
    case 'SET_SYSTEM_PROMPT':
      return {
        ...state,
        systemPrompt: action.payload
      };
    
    case 'SET_MODEL':
      return {
        ...state,
        selectedModel: action.payload
      };
    
    case 'LOAD_SETTINGS':
      return action.payload;
    
    case 'RESET_TO_DEFAULTS':
      return resetSettings();
    
    default:
      return state;
  }
};

// Context interface
interface SettingsContextType {
  settings: AppSettings;
  updateSystemPrompt: (prompt: string) => Promise<boolean>;
  updateModel: (model: GeminiModel) => Promise<boolean>;
  updateSettings: (newSettings: AppSettings) => Promise<boolean>;
  resetToDefaults: () => Promise<boolean>;
  isLoading: boolean;
}

// Create context
const SettingsContext = createContext<SettingsContextType | undefined>(undefined);

// Provider props
interface SettingsProviderProps {
  children: ReactNode;
}

// Provider component
export const SettingsProvider: React.FC<SettingsProviderProps> = ({ children }) => {
  const [settings, dispatch] = useReducer(settingsReducer, loadSettings());
  const [isLoading, setIsLoading] = React.useState(false);

  // Load settings on mount
  useEffect(() => {
    const loadInitialSettings = async () => {
      setIsLoading(true);
      try {
        const loadedSettings = loadSettings();
        dispatch({ type: 'LOAD_SETTINGS', payload: loadedSettings });
      } catch (error) {
        console.error('Failed to load initial settings:', error);
      } finally {
        setIsLoading(false);
      }
    };

    loadInitialSettings();
  }, []);

  // Note: Auto-save removed - settings are only saved when user explicitly clicks Save

  // Context value methods
  const updateSystemPrompt = async (prompt: string): Promise<boolean> => {
    try {
      const newSettings = { ...settings, systemPrompt: prompt };
      const saved = saveSettings(newSettings);
      
      if (saved) {
        dispatch({ type: 'SET_SYSTEM_PROMPT', payload: prompt });
        return true;
      }
      return false;
    } catch (error) {
      console.error('Failed to update system prompt:', error);
      return false;
    }
  };

  const updateModel = async (model: GeminiModel): Promise<boolean> => {
    try {
      const newSettings = { ...settings, selectedModel: model };
      const saved = saveSettings(newSettings);
      
      if (saved) {
        dispatch({ type: 'SET_MODEL', payload: model });
        return true;
      }
      return false;
    } catch (error) {
      console.error('Failed to update model:', error);
      return false;
    }
  };

  const updateSettings = async (newSettings: AppSettings): Promise<boolean> => {
    try {
      const saved = saveSettings(newSettings);
      
      if (saved) {
        dispatch({ type: 'LOAD_SETTINGS', payload: newSettings });
        return true;
      }
      return false;
    } catch (error) {
      console.error('Failed to update settings:', error);
      return false;
    }
  };

  const resetToDefaults = async (): Promise<boolean> => {
    try {
      const defaultSettings = resetSettings();
      dispatch({ type: 'RESET_TO_DEFAULTS' });
      return true;
    } catch (error) {
      console.error('Failed to reset settings:', error);
      return false;
    }
  };

  const contextValue: SettingsContextType = {
    settings,
    updateSystemPrompt,
    updateModel,
    updateSettings,
    resetToDefaults,
    isLoading
  };

  return (
    <SettingsContext.Provider value={contextValue}>
      {children}
    </SettingsContext.Provider>
  );
};

// Hook to use settings context
export const useSettings = (): SettingsContextType => {
  const context = useContext(SettingsContext);
  
  if (context === undefined) {
    throw new Error('useSettings must be used within a SettingsProvider');
  }
  
  return context;
};
</file>

<file path="src/types/settings.ts">
export type GeminiModel = 
  // Latest 2.5 Series (Most Powerful)
  | 'gemini-2.5-pro'
  | 'gemini-2.5-flash'
  | 'gemini-2.5-flash-lite'
  | 'gemini-2.5-flash-image'
  // 2.0 Series (Current Generation)
  | 'gemini-2.0-flash'
  | 'gemini-2.0-flash-lite'
  | 'gemini-2.0-flash-experimental'
  // Legacy 1.5 Series
  | 'gemini-1.5-pro'
  | 'gemini-1.5-flash'
  | 'gemini-1.5-flash-8b';

export interface ModelOption {
  value: GeminiModel;
  label: string;
  description: string;
  category: 'pro' | 'flash' | 'flash-lite' | 'experimental' | 'image';
  generation: '1.5' | '2.0' | '2.5';
  contextLength?: string;
  performance: 'fastest' | 'fast' | 'medium' | 'high';
  quality: 'medium' | 'high' | 'very-high' | 'highest';
}

export const GEMINI_MODELS: ModelOption[] = [
  // Latest 2.5 Series - Most Powerful
  {
    value: 'gemini-2.5-pro',
    label: 'Gemini 2.5 Pro',
    description: 'Most powerful model with premium reasoning and extended context',
    category: 'pro',
    generation: '2.5',
    contextLength: '2M+ tokens',
    performance: 'medium',
    quality: 'highest'
  },
  {
    value: 'gemini-2.5-flash',
    label: 'Gemini 2.5 Flash',
    description: 'Latest fast model with improved cost and performance',
    category: 'flash',
    generation: '2.5',
    contextLength: '1M+ tokens',
    performance: 'fast',
    quality: 'high'
  },
  {
    value: 'gemini-2.5-flash-lite',
    label: 'Gemini 2.5 Flash Lite',
    description: 'Ultra-light model for maximum speed and economy',
    category: 'flash-lite',
    generation: '2.5',
    contextLength: '~1M tokens',
    performance: 'fastest',
    quality: 'medium'
  },
  {
    value: 'gemini-2.5-flash-image',
    label: 'Gemini 2.5 Flash Image',
    description: 'Specialized for high-speed image understanding tasks',
    category: 'image',
    generation: '2.5',
    performance: 'fast',
    quality: 'high'
  },
  
  // 2.0 Series - Current Generation
  {
    value: 'gemini-2.0-flash',
    label: 'Gemini 2.0 Flash',
    description: 'Fully multimodal with enhanced spatial and video understanding',
    category: 'flash',
    generation: '2.0',
    contextLength: '1-2M+ tokens',
    performance: 'fast',
    quality: 'high'
  },
  {
    value: 'gemini-2.0-flash-lite',
    label: 'Gemini 2.0 Flash Lite',
    description: 'Optimized for maximum speed with some quality trade-offs',
    category: 'flash-lite',
    generation: '2.0',
    contextLength: '~512K tokens',
    performance: 'fastest',
    quality: 'medium'
  },
  {
    value: 'gemini-2.0-flash-experimental',
    label: 'Gemini 2.0 Flash (Experimental)',
    description: 'Cutting-edge features with live multimodal API and agentic functions',
    category: 'experimental',
    generation: '2.0',
    contextLength: '1M+ tokens',
    performance: 'fast',
    quality: 'high'
  },
  
  // Legacy 1.5 Series - Still Supported
  {
    value: 'gemini-1.5-pro',
    label: 'Gemini 1.5 Pro',
    description: 'Large-scale context with strong reasoning (legacy)',
    category: 'pro',
    generation: '1.5',
    contextLength: 'Up to 1M tokens',
    performance: 'medium',
    quality: 'very-high'
  },
  {
    value: 'gemini-1.5-flash',
    label: 'Gemini 1.5 Flash',
    description: 'Fast multimodal processing (legacy)',
    category: 'flash',
    generation: '1.5',
    contextLength: 'Up to 1M tokens',
    performance: 'fast',
    quality: 'high'
  },
  {
    value: 'gemini-1.5-flash-8b',
    label: 'Gemini 1.5 Flash 8B',
    description: 'Smaller, high-speed model for basic tasks (legacy)',
    category: 'flash-lite',
    generation: '1.5',
    contextLength: 'Up to 1M tokens',
    performance: 'fastest',
    quality: 'medium'
  }
];

export interface AppSettings {
  systemPrompt: string;
  selectedModel: GeminiModel;
  // Future settings will be added here
  sttModel?: string;
  ttsModel?: string;
}

export interface SettingsFormData {
  systemPrompt: string;
  selectedModel: GeminiModel;
}

export type SettingsAction =
  | { type: 'SET_SYSTEM_PROMPT'; payload: string }
  | { type: 'SET_MODEL'; payload: GeminiModel }
  | { type: 'LOAD_SETTINGS'; payload: AppSettings }
  | { type: 'RESET_TO_DEFAULTS' };

export const DEFAULT_SETTINGS: AppSettings = {
  systemPrompt: '', // Will be set from KIJKO_SYSTEM_PROMPT constant
  selectedModel: 'gemini-2.5-pro' // Use the most powerful model by default
};
</file>

<file path="src/styles.css">
/* UI Overhaul - Dark Theme Variables & Animations */
:root {
  /* Core Color Palette */
  --bg-main: #0D0D12;
  --bg-bot: #1E1E28;
  --bg-input: #1E1E28;
  --text-primary: #FFFFFF;
  --text-secondary: #FFFFFFD6;
  
  /* Gradients */
  --gradient-user: linear-gradient(135deg, #FF2DBD 0%, #7D3CFD 100%);
  --gradient-accent: linear-gradient(135deg, #CF30FF 0%, #FF2DBD 100%);
  --gradient-send: linear-gradient(135deg, #7D3CFD 0%, #FF2DBD 100%);
  
  /* Layout & Spacing */
  --radius-xl: 18px;
  --radius-lg: 14px;
  --radius-md: 12px;
  --shadow-elev: 0 2px 6px #00000080;
  --spacing-outer: 1.25rem;
  --spacing-bubble: 0.9rem 1rem;
  
  /* Animation Timings */
  --timing-fast: 150ms;
  --timing-normal: 200ms;
  --timing-slow: 300ms;
}

/* Global Styles */
body {
  background-color: var(--bg-main);
  color: var(--text-primary);
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
  margin: 0;
  padding: 0;
  overflow-x: hidden;
}

/* Custom Animations */
@keyframes bounce-dots {
  0%, 20%, 50%, 80%, 100% { transform: translateY(0); }
  40% { transform: translateY(-6px); }
  60% { transform: translateY(-3px); }
}

@keyframes slide-up {
  from {
    opacity: 0;
    transform: translateY(8px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

@keyframes scale-press {
  from { transform: scale(1); }
  to { transform: scale(0.97); }
}

@keyframes glow-pulse {
  0% { box-shadow: 0 0 0 0 rgba(125, 60, 253, 0.4); }
  70% { box-shadow: 0 0 0 8px rgba(125, 60, 253, 0); }
  100% { box-shadow: 0 0 0 0 rgba(125, 60, 253, 0); }
}

@keyframes pulse {
  0% {
    opacity: 0.3;
    transform: scale(1);
  }
  50% {
    opacity: 0.5;
    transform: scale(1.03);
  }
  100% {
    opacity: 0.3;
    transform: scale(1);
  }
}

/* Utility Classes */
.gradient-user {
  background: var(--gradient-user);
}

.gradient-accent {
  background: var(--gradient-accent);
}

.gradient-send {
  background: var(--gradient-send);
}

.animate-slide-up {
  animation: slide-up var(--timing-fast) ease-out;
}

.animate-bounce-dots {
  animation: bounce-dots 0.8s infinite;
}

.animate-scale-press {
  animation: scale-press var(--timing-fast) ease-out;
}

.animate-glow-pulse {
  animation: glow-pulse 2s infinite;
}

/* Loading Dots */
.loading-dots {
  display: flex;
  gap: 4px;
  align-items: center;
}

.loading-dots .dot {
  width: 8px;
  height: 8px;
  border-radius: 50%;
  background-color: var(--text-secondary);
  animation: bounce-dots 0.8s infinite;
}

.loading-dots .dot:nth-child(2) {
  animation-delay: 0.1s;
}

.loading-dots .dot:nth-child(3) {
  animation-delay: 0.2s;
}

/* Scrollbar Styling */
::-webkit-scrollbar {
  width: 4px;
}

::-webkit-scrollbar-track {
  background: transparent;
}

::-webkit-scrollbar-thumb {
  background: var(--text-secondary);
  border-radius: 2px;
}

::-webkit-scrollbar-thumb:hover {
  background: var(--text-primary);
}

/* Focus States */
.focus-ring {
  @apply focus:outline-none focus:ring-2 focus:ring-purple-400 focus:ring-opacity-50;
}

/* Gradient Text */
.text-gradient {
  background: var(--gradient-accent);
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  background-clip: text;
}

/* Glass Effect */
.glass {
  backdrop-filter: blur(10px);
  background: rgba(30, 30, 40, 0.7);
  border: 1px solid rgba(255, 255, 255, 0.1);
}

/* Button Hover Effects */
.btn-interactive {
  transition: all var(--timing-fast) ease;
}

.btn-interactive:hover {
  transform: translateY(-1px);
  filter: brightness(1.1);
}

.btn-interactive:active {
  transform: translateY(0) scale(0.97);
}

/* Mobile Optimizations */
@media (max-width: 640px) {
  :root {
    --spacing-outer: 1rem;
    --spacing-bubble: 0.75rem 0.875rem;
  }
}

/* High contrast for accessibility */
@media (prefers-contrast: high) {
  :root {
    --text-secondary: #FFFFFF;
    --bg-bot: #000000;
  }
}

/* Reduced motion */
@media (prefers-reduced-motion: reduce) {
  * {
    animation-duration: 0.01ms !important;
    animation-iteration-count: 1 !important;
    transition-duration: 0.01ms !important;
  }
}
</file>

<file path="src/types.ts">
export interface UIMessage {
  id: string;
  role: 'user' | 'model';
  text: string;
  attachments?: Attachment[];
  isStreaming?: boolean;
  options?: MCQOption[];
  showOptions?: boolean; // Control whether to show MCQ options
}
export interface UIAttachment {
  name: string;
  type: string; 
  size: number;
}

export interface Attachment extends UIAttachment {
  data: string; // base64
}

export type MessagePart = {
  text?: string;
  inlineData?: {
    mimeType: string;
    data: string; // base64
  };
};
</file>

<file path=".gitignore">
# Dependencies
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Production builds
dist/
build/

# Environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local

# Vite
.vite/

# Cache directories
.npm/
.yarn/
.cache/

# Runtime data
*.pid
*.log
server.log

# IDE and editor files
.vscode/
.idea/
*.swp
*.swo
*~

# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Deployment
.vercel/

# Testing
coverage/

# Temporary files
*.tmp
*.temp

# Desktop integration
/tmp/kijko-app.pid
.vercel
</file>

<file path="vercel.json">
{
  "rewrites": [
    {
      "source": "/(.*)",
      "destination": "/index.html"
    }
  ]
}
</file>

<file path="api/perplexity.js">
/**
 * Vercel serverless function to proxy Perplexity API calls
 * This keeps the API key secure on the server-side and prevents exposure to the browser
 */
export default async function handler(req, res) {
  // Add CORS headers
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');
  
  // Handle preflight OPTIONS request
  if (req.method === 'OPTIONS') {
    return res.status(200).end();
  }
  
  // Only allow POST requests
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  // Get API key from environment variables (stored securely in Vercel)
  const apiKey = process.env.PERPLEXITY_API_KEY;
  
  if (!apiKey) {
    console.error('PERPLEXITY_API_KEY is not set in Vercel environment variables');
    return res.status(500).json({ error: 'Perplexity API key is not configured' });
  }

  try {
    // Extract request body with safety check
    const { model, messages, stream, max_tokens, temperature } = req.body || {};

    // Validate required fields
    if (!messages || !Array.isArray(messages)) {
      return res.status(400).json({ error: 'Messages array is required' });
    }

    // Call Perplexity API
    const response = await fetch('https://api.perplexity.ai/chat/completions', {
      method: 'POST',
      headers: {
        'Accept': 'application/json',
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model: model || 'pplx-7b-online',
        messages,
        stream: stream || false,
        max_tokens: max_tokens || 1024,
        temperature: temperature || 0.2,
      }),
    });

    // Get response data
    const data = await response.json();

    // Return response with same status code
    if (!response.ok) {
      console.error('Perplexity API error:', data);
      return res.status(response.status).json(data);
    }

    return res.status(200).json(data);
    
  } catch (error) {
    console.error('Error in Perplexity serverless function:', error);
    return res.status(500).json({ 
      error: 'Internal server error',
      message: error.message 
    });
  }
}
</file>

<file path="src/components/ProgressIndicator.tsx">
import React, { useEffect, useState } from 'react';
import { CircularProgress } from './CircularProgress';

interface ProgressIndicatorProps {
  currentStep: number;
  totalSteps: number;
  currentStepLabel: string;
  nextStepLabel?: string;
  percentage: number;
  isVisible?: boolean;
}

export const ProgressIndicator: React.FC<ProgressIndicatorProps> = ({
  currentStep,
  totalSteps,
  currentStepLabel,
  nextStepLabel,
  percentage,
  isVisible = true
}) => {
  const [isAnimating, setIsAnimating] = useState(false);
  const [isMobile, setIsMobile] = useState(false);

  useEffect(() => {
    // Trigger animation on percentage change
    setIsAnimating(true);
    const timer = setTimeout(() => setIsAnimating(false), 500);
    return () => clearTimeout(timer);
  }, [percentage]);

  useEffect(() => {
    // Check for mobile screen size
    const checkMobile = () => {
      setIsMobile(window.innerWidth < 768);
    };
    checkMobile();
    window.addEventListener('resize', checkMobile);
    return () => window.removeEventListener('resize', checkMobile);
  }, []);

  if (!isVisible) return null;

  const progressSize = isMobile ? 60 : 80;
  // Add 10% of diameter as top offset: 8px for 80px desktop, 6px for 60px mobile
  const topOffset = isMobile ? 'top-[76px]' : 'top-24';
  
  const containerClasses = `
    fixed z-50 
    ${topOffset} right-4 lg:right-6
    flex flex-col items-center gap-2
    transition-all duration-300 ease-out
    ${isAnimating ? 'scale-105' : 'scale-100'}
  `;

  return (
    <div className={containerClasses}>
      {/* Progress Ring */}
      <div className="relative">
        <CircularProgress 
          percentage={percentage} 
          size={progressSize}
          strokeWidth={isMobile ? 6 : 8}
        />
        
        {/* Center Content */}
        <div className="absolute inset-0 flex flex-col items-center justify-center">
          <span className={`${isMobile ? 'text-sm' : 'text-lg'} font-bold text-white drop-shadow-lg`}>
            {Math.round(percentage)}%
          </span>
          <span className="text-[10px] text-gray-300 font-medium drop-shadow">
            {currentStep}/{totalSteps}
          </span>
        </div>
      </div>
      
      {/* Step Labels - Show below the ring, smaller on mobile */}
      <div className={`text-center space-y-1 ${isMobile ? 'max-w-[80px]' : 'max-w-[120px]'} mt-2`}>
        {/* Current Step */}
        <div className="animate-slide-up">
          <p className={`${isMobile ? 'text-[9px]' : 'text-[10px]'} text-gray-400 uppercase tracking-wider font-medium`}>
            Current
          </p>
          <p className={`${isMobile ? 'text-[10px]' : 'text-xs'} font-semibold text-gray-200 truncate drop-shadow`}>
            {currentStepLabel}
          </p>
        </div>
        
        {/* Next Step - Only show if not on last step and on desktop */}
        {!isMobile && nextStepLabel && percentage < 90 && (
          <div className="animate-slide-up" style={{ animationDelay: '0.1s' }}>
            <p className="text-[10px] text-gray-500 uppercase tracking-wider font-medium">
              Next
            </p>
            <p className="text-xs text-gray-400 truncate">
              {nextStepLabel}
            </p>
          </div>
        )}
      </div>
      
      {/* Visual indicator dots for steps */}
      <div className={`flex gap-1 ${isMobile ? 'mt-1' : 'mt-1'}`}>
        {Array.from({ length: totalSteps }, (_, i) => (
          <div
            key={i}
            className={`
              ${isMobile ? 'h-[3px]' : 'h-1'} transition-all duration-300
              ${i < currentStep 
                ? `${isMobile ? 'w-1.5' : 'w-2'} bg-gradient-to-r from-purple-500 to-pink-500 opacity-80` 
                : i === currentStep
                  ? `${isMobile ? 'w-3' : 'w-4'} bg-gradient-to-r from-purple-400 to-pink-400 animate-pulse`
                  : `${isMobile ? 'w-[3px]' : 'w-1'} bg-gray-600 opacity-50`
              }
              rounded-full
            `}
          />
        ))}
      </div>
    </div>
  );
};
</file>

<file path="src/services/geminiService.ts">
import { GoogleGenAI, Chat, GenerateContentResponse } from "@google/genai";
import { KIJKO_SYSTEM_PROMPT } from '../constants';
import { Attachment, MessagePart } from '../types';
import { GeminiModel } from '../types/settings';

// Get API keys with fallback support
const getApiKeys = () => {
  const keys = [
    process.env.GEMINI_API_KEY || process.env.API_KEY,
    process.env.GEMINI_API_KEY_BACKUP_1,
    process.env.GEMINI_API_KEY_BACKUP_2
  ].filter(Boolean);
  
  if (keys.length === 0) {
    throw new Error("No valid API keys found. Please set GEMINI_API_KEY environment variable");
  }
  
  return keys;
};

const apiKeys = getApiKeys();
let currentKeyIndex = 0;

// Create AI instance with current key
let ai = new GoogleGenAI({ apiKey: apiKeys[currentKeyIndex] });

// Function to switch to next API key if current one fails
const switchToNextKey = () => {
  currentKeyIndex = (currentKeyIndex + 1) % apiKeys.length;
  ai = new GoogleGenAI({ apiKey: apiKeys[currentKeyIndex] });
  console.log(`Switched to backup API key ${currentKeyIndex + 1}`);
};

export function startKijkoChat(model?: GeminiModel, systemPrompt?: string): Chat {
  try {
    const selectedModel = model || 'gemini-2.5-flash';
    const selectedPrompt = systemPrompt || KIJKO_SYSTEM_PROMPT;
    
    const chat = ai.chats.create({
      model: selectedModel,
      config: {
        systemInstruction: selectedPrompt,
      },
    });
    return chat;
  } catch (error) {
    console.error('Failed to create chat with current API key:', error);
    if (apiKeys.length > 1) {
      switchToNextKey();
      return startKijkoChat(model, systemPrompt);
    }
    throw error;
  }
}

const fileToGenerativePart = (file: Attachment): MessagePart => {
  return {
    inlineData: {
      data: file.data,
      mimeType: file.type,
    },
  };
};

export async function sendMessageToKijkoStream(
  chat: Chat, 
  text: string, 
  attachments: Attachment[],
  retryCount = 0,
  model?: GeminiModel,
  systemPrompt?: string
): Promise<AsyncGenerator<GenerateContentResponse>> {
  try {
    const parts: MessagePart[] = attachments.map(fileToGenerativePart);
    
    const youtubeRegex = /(?:https?:\/\/)?(?:www\.)?(?:youtube\.com|youtu\.be)\/(?:watch\?v=)?([\w-]{11})/;
    const ytMatch = text.match(youtubeRegex);

    let promptText = text;
    if (ytMatch) {
      promptText += `\n\n[User has provided a YouTube link for context: ${ytMatch[0]}. Please analyze the content of this video as part of your response.]`;
    }

    if (promptText.trim()) {
      parts.push({ text: promptText });
    }
    
    const result = await chat.sendMessageStream({ message: parts });
    return result;
  } catch (error) {
    console.error('Failed to send message with current API key:', error);
    
    // If we have backup keys and haven't exceeded retry attempts
    if (apiKeys.length > 1 && retryCount < apiKeys.length - 1) {
      switchToNextKey();
      // Create new chat with the new API key and same settings
      const newChat = startKijkoChat(model, systemPrompt);
      return sendMessageToKijkoStream(newChat, text, attachments, retryCount + 1, model, systemPrompt);
    }
    
    throw error;
  }
}
</file>

<file path="src/constants.ts">
export const KIJKO_SYSTEM_PROMPT = `
### Structured-Output Requirement (MANDATORY - HIGHEST PRIORITY)
When you ask a multiple-choice question, respond in **one** of the two formats below—never mix them.

1. Plain-text block:
   QUESTION: <question text>
   OPTIONS:
   1 = '<option-1>'
   2 = '<option-2>'
   3 = '<option-3>'
   ...
   END_OPTIONS
   EXPLANATION: <optional commentary>

2. JSON block:
   <begin>{
     "question": "<question text>",
     "options": ["<option-1>", "<option-2>", "<option-3>"],
     "explanation": "<optional commentary>"
   }<end>

No other text may appear before, inside, or after the block.

Example (JSON format):
<begin>{
  "question": "How clear is your current video vision?",
  "options": ["1-3: I only know I need a video", "4-7: I have some ideas", "8-10: I have detailed specs"],
  "explanation": "Your selection tailors the depth of guidance."
}<end>

You are Kijko, a multimodal, speech-enabled Video Brief Assistant that expertly guides users through creating comprehensive Video Requirements Documents (VRDs) and managing the entire video production process. You adapt your guidance level based on each user's clarity and experience, ensuring everyone—from complete beginners to seasoned professionals—can articulate and realize their video vision.

Your primary capabilities are:
1.  **Adaptive Discovery Engine**:
    *   **Vision Assessment**: Early in the conversation (within the first 3 exchanges), gauge the user's clarity level on a 1-10 scale. The prompt is: "To help me tailor our session perfectly for you, could you rate your current vision clarity on a scale of 1-10? 1 = 'I just know I need a video to achieve a business goal', 5 = 'I have a general concept and some specific ideas', 10 = 'I have detailed requirements including script, style, and technical specs'. Your answer helps me adjust my guidance level to match your needs."
    *   **Dynamic Adjustment**: Modify questioning depth and guidance based on the assessed level.
    *   **Intelligent Extraction**: Pull relevant information from vague ideas or detailed specifications.
    *   **Context Building**: Accumulate understanding through natural conversation flow.

2.  **Multi-Modal Processing**:
    *   **Language Detection**: Automatically detect and respond in the user's spoken/written language.
    *   **File Analysis**: Process images, videos, documents, and audio for context and reference. You will receive these as base64 encoded data. When a user provides a YouTube URL, analyze its content as a video reference.
    *   **Visual Understanding**: Extract style, mood, and composition from uploaded references.
    *   **Document Parsing**: Extract requirements from existing briefs, scripts, or guidelines.

3.  **VRD Generation Pipeline**:
    *   **Structured Documentation**: Create professional VRDs matching industry standards.
    *   **Component Assembly**: Build all required sections from gathered information.
    *   **Format Flexibility**: Adjust the detail level based on user needs and project scope.
    *   **Export Ready**: Generate publication-ready documents for stakeholder review when requested via the /export command.

**Conversation Framework & Questioning Strategy:**

*   **Phase 1: Initial Assessment (First 2-3 exchanges)**: Start with the opening engagement: "Hello! I'm Kijko, your video brief assistant. I'll help you create a comprehensive production plan for your video project. To get started, could you tell me about your video idea? Feel free to share as much or as little as you have in mind, and we'll build from there." Then, perform the Vision Clarity Assessment.
*   **Phase 2: Adaptive Discovery (Based on Clarity Score)**:
    *   **Low Clarity (1-3)**: Start with fundamental business questions, provide multiple-choice options, offer industry examples, use analogies, and provide heavy scaffolding with pre-filled suggestions.
    *   **Medium Clarity (4-7)**: Mix open and guided questions, probe for specifics, suggest options for uncertain areas, validate assumptions explicitly, and provide moderate guidance.
    *   **High Clarity (8-10)**: Ask direct, specific questions, focus on technical requirements, validate completeness with minimal hand-holding, and use expert-level terminology.
*   **Phase 3: Information Gathering (Core Discovery Questions adapted to clarity level)**: Cover Purpose & Goals, Audience, Message, Style & Tone, and Practical Constraints.
*   **Phase 4: Intelligent Assistance**: When the user is unclear, offer help: "I notice you might need some help with [specific aspect]. Would you like me to: A) Generate suggestions based on our conversation so far, B) Show you similar examples from other projects, C) Research best practices for your industry, D) Move on and revisit this later. Just pick a letter or describe what would help most."

**Interaction Commands (User Commands you must recognize and act upon):**
*   \`/clarity\` [1-10]: User adjusts guidance level mid-session.
*   \`/research\` [topic]: User invokes a research agent. You should perform a targeted search on the topic and provide a summary.
*   \`/example\` [type]: User requests relevant examples.
*   \`/template\` [industry]: User wants to load an industry template.
*   \`/review\`: User wants to see the current VRD draft. Summarize the collected information in the standard VRD sections.
*   \`/missing\`: User wants to know what's missing. Show incomplete sections.
*   \`/suggest\`: User wants suggestions for the current section.
*   \`/export\`: User wants the final VRD document. Present the complete VRD in a well-formatted, clean way, ready for copying.

**System Behaviors:**
*   **Progress Indicator**: Periodically, show the completion percentage of the VRD.
*   **Smart Prompts**: Offer pre-written options when detecting hesitation.
*   **Validation Loops**: Confirm your understanding of critical points.
*   **Information Display**: Use bullet points for clarity, provide inline examples, summarize periodically, and confirm before moving to new sections.


**Tone Adaptation:**
*   **Low clarity users**: Be encouraging, educational, and patient.
*   **Medium clarity users**: Be collaborative, validating, and guiding.
*   **High clarity users**: Be efficient, professional, and technical.

Your ultimate goal is to extract a professional, comprehensive VRD from any user, regardless of their initial clarity or experience level. Be adaptive, intelligent, and supportive while maintaining efficiency and professionalism.
`;
</file>

<file path="src/index.tsx">
import React from 'react';
import ReactDOM from 'react-dom/client';
import { BrowserRouter, Routes, Route } from 'react-router-dom';
import App from './App';
import MCQTestDemo from './components/MCQTestDemo';
import './styles.css';

const rootElement = document.getElementById('root');
if (!rootElement) {
  throw new Error("Could not find root element to mount to");
}

const root = ReactDOM.createRoot(rootElement);
root.render(
  <React.StrictMode>
    <BrowserRouter>
      <Routes>
        <Route path="/" element={<App />} />
        <Route path="/mcq-test" element={<MCQTestDemo />} />
      </Routes>
    </BrowserRouter>
  </React.StrictMode>
);
</file>

<file path="vite.config.ts">
import path from 'path';
import { defineConfig, loadEnv } from 'vite';

export default defineConfig(({ mode }) => {
    const env = loadEnv(mode, '.', '');
    return {
      define: {
        // Support both local development and Vercel deployment
        'process.env.API_KEY': JSON.stringify(env.GEMINI_API_KEY || process.env.GEMINI_API_KEY),
        'process.env.GEMINI_API_KEY': JSON.stringify(env.GEMINI_API_KEY || process.env.GEMINI_API_KEY),
        'process.env.GEMINI_API_KEY_BACKUP_1': JSON.stringify(env.GEMINI_API_KEY_BACKUP_1 || process.env.GEMINI_API_KEY_BACKUP_1),
        'process.env.GEMINI_API_KEY_BACKUP_2': JSON.stringify(env.GEMINI_API_KEY_BACKUP_2 || process.env.GEMINI_API_KEY_BACKUP_2),
        'process.env.PERPLEXITY_API_KEY': JSON.stringify(env.PERPLEXITY_API_KEY || process.env.PERPLEXITY_API_KEY),
        'process.env.SUPABASE_URL': JSON.stringify(env.SUPABASE_URL || process.env.SUPABASE_URL),
        'process.env.SUPABASE_ANON_KEY': JSON.stringify(env.SUPABASE_ANON_KEY || process.env.SUPABASE_ANON_KEY)
      },
      resolve: {
        alias: {
          '@': path.resolve(__dirname, '.'),
        }
      }
    };
});
</file>

<file path="WARP.md">
# WARP.md

This file provides guidance to WARP (warp.dev) when working with the Chat VRD project.

## Project Overview

Chat VRD is a multimodal, speech-enabled Video Brief Assistant built with React 19, TypeScript, and Vite. It helps users create comprehensive Video Requirements Documents (VRDs) by guiding them through an adaptive discovery process using Google's Gemini AI.

### Key Features
- **Multimodal Chat Interface**: Text input with file attachments (images, videos, audio, documents)
- **Enhanced MCQ System**: Multi-select options with markdown rendering and auto-detection
- **Text-to-Speech**: Built-in speech synthesis for AI responses
- **Adaptive Discovery**: Adjusts guidance level based on user expertise (1-10 clarity scale)
- **YouTube Integration**: Automatic video URL detection and content analysis
- **Desktop Integration**: Native desktop launcher with process management

## Development Commands

### Essential Commands
```bash
# Install dependencies
npm install

# Start development server (default port 5173)
npm run dev

# Build for production
npm run build

# Preview production build
npm run preview
```

### Desktop Integration Commands
```bash
# Launch app with desktop integration
./launch-kijko.sh

# Stop all app processes and free ports
./kill-kijko.sh

# Check port usage
lsof -i :5173
```

### Environment Setup
1. Create `.env.local` file in project root
2. Add your Gemini API key: `GEMINI_API_KEY=your_api_key_here`
3. The Vite config automatically exposes this as `process.env.API_KEY` in the app

## Architecture

### Core Architecture Pattern
- **React 19** with TypeScript for type safety
- **Vite** for fast development and building
- **Component-based architecture** with clear separation of concerns
- **Service layer** for AI integration (Gemini API)
- **Custom hooks** for reusable functionality (Text-to-Speech)

### Key Architectural Concepts

#### 1. Adaptive AI System
The core innovation is the **Adaptive Discovery Engine** in `constants.ts` (KIJKO_SYSTEM_PROMPT):
- **Vision Clarity Assessment**: Rates user clarity 1-10 to adjust guidance level
- **Phase-based Conversation**: Initial Assessment → Adaptive Discovery → Information Gathering → Intelligent Assistance
- **Command System**: Special commands like `/clarity`, `/research`, `/review`, `/export` for advanced interactions

#### 2. Message Flow Architecture
```
User Input → ChatInput → App (state management) → GeminiService → Streaming Response → ChatHistory
```
- **Streaming responses** for real-time AI feedback
- **Attachment processing** converts files to base64 for AI analysis
- **YouTube URL detection** automatically analyzes video content

#### 3. Enhanced MCQ System
- **Markdown Rendering**: Uses `react-markdown` to properly display **bold** and *italic* text
- **Multi-Select Capability**: Checkbox-style options with array-based state management
- **Auto-Detection**: Intelligent detection of multi-select scenarios based on content keywords
- **Visual Indicators**: Clear checkboxes for multi-select, radio buttons for single-select
- **Accessibility**: Full ARIA support with proper roles and keyboard navigation
- **Testing Interface**: Comprehensive demo at `/mcq-test` route

#### 4. Desktop Integration System
- **Process management** via shell scripts with PID tracking
- **Port management** automatically handles 5173, 3000, 4173, 8080
- **Signal-based shutdown** using file-based communication
- **Browser automation** with `xdg-open` integration

### File Structure Significance

#### Component Architecture
- `components/`: Modular React components with single responsibilities
  - `ChatHistory.tsx`: Auto-scrolling message display
  - `ChatInput.tsx`: File upload + text input with validation
  - `EnhancedChatMessage.tsx`: Individual message rendering with MCQ integration
  - `OptionGroup.tsx`: Advanced MCQ system with multi-select and markdown support
  - `MCQTestDemo.tsx`: Comprehensive MCQ testing interface
  - `Header.tsx`: TTS controls and branding
  - `icons/`: UI icon components (SpeakerIcons, AttachmentIcon, SendIcon, FileIcons)

#### Core Services
- `services/geminiService.ts`: AI integration layer
  - Chat initialization with system prompts
  - Streaming message handling
  - File attachment processing
  - YouTube URL detection and context addition

#### Types & Configuration
- `types.ts`: TypeScript definitions for messages and attachments
- `constants.ts`: Contains the sophisticated AI system prompt (350+ lines)
- `hooks/useTextToSpeech.ts`: Web Speech API integration

### AI Integration Details

#### System Prompt Architecture
The system prompt in `constants.ts` implements:
- **Multi-phase conversation management**
- **Adaptive questioning based on user expertise**
- **Command recognition system**
- **VRD generation pipeline**
- **Tone adaptation for different user types**

#### Gemini Configuration
- Uses `gemini-2.5-flash` model
- Streaming responses for real-time feedback
- Multimodal support (text, images, video, audio)
- YouTube URL content analysis integration

## Development Patterns

### State Management
- React state with hooks (no external state management)
- Message state managed in main `App.tsx`
- Streaming state updates for real-time AI responses

### Error Handling
- Try-catch blocks around AI service calls
- User-friendly error messages
- Graceful fallbacks for TTS and file upload failures

### File Processing
- Client-side file conversion to base64
- File size limits (20MB) and count limits (5 files)
- Support for images, videos, audio, PDFs, and documents

## Desktop Integration Specifics

### Process Management
- PID tracking in `/tmp/kijko-app.pid`
- Signal file communication via `/home/david/Downloads/kijko-shutdown-signal.txt`
- Comprehensive port cleanup across common dev ports

### Desktop Shortcut
- Located at `/home/david/Desktop/Kijko.desktop`
- Categories: Development, AudioVideo, Graphics
- Automatic browser launching on startup

## Deployment Configuration

### Vercel Deployment
- Framework auto-detection for React/Vite
- Environment variables via Vercel dashboard
- Build command: `npm run build`
- Output directory: `dist/` (Vite default)

### Environment Variables Required
- `GEMINI_API_KEY`: Google Gemini API key (mark as sensitive in Vercel)

## Chat History Status

The chat history persistence exists at the service layer but is not accessible in the UI yet, and production writes are likely bypassed due to environment config.

Current implementation status:
- Database: `public.chat_sessions` and `public.messages` tables exist in Supabase with RLS enabled (policies allow users to manage their own sessions/messages).
- Writes: App attempts to create a session and write messages when Supabase is available.
- Reads: There is no UI to list previous chat sessions or load their messages.
- Config: The app uses `process.env.SUPABASE_URL` and `process.env.SUPABASE_ANON_KEY`, which do not work in a Vite React browser build. Vite requires `import.meta.env.VITE_*` variables. This likely makes Supabase unavailable in production, so no data is saved.
- Race condition: The initial welcome message is attempted to be saved using `currentChatId` immediately after setting state, so it never persists due to stale state in the `useEffect` closure.

Verified via Supabase MCP:
- Tables present with 0 rows (indicating no persisted history writes reached the DB in the targeted project).
- RLS policies present allowing authenticated users to manage their own data.

Action items to make Chat History accessible:
1) Environment variables (required)
   - Rename variables to Vite format and reference them via `import.meta.env` in code.
     - .env / Vercel:
       - VITE_SUPABASE_URL
       - VITE_SUPABASE_ANON_KEY
     - In `supabaseService.ts`:
       - `const supabaseUrl = import.meta.env.VITE_SUPABASE_URL;`
       - `const supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY;`
   - Update `.env.local.example` accordingly and add Vercel project envs.

2) Fix initialization race (should persist welcome message)
   - When creating a new chat session, use the returned `session.id` directly for the first writes instead of relying on `currentChatId` state inside the same effect.
   - Example pattern:
     - `const session = await supabaseService.createChatSession('Kijko Chat Session');`
     - `if (session) { await supabaseService.addMessage(session.id, welcomeMessage.text, 'assistant'); setCurrentChatId(session.id); }`

3) Add retrieval UI (make history accessible)
   - Add a Sessions list panel (e.g., left sidebar) that calls `supabaseService.getChatSessions()` and lets the user pick a session.
   - On session select, call `supabaseService.getMessages(sessionId)` and set `messages` in state to render past conversation.
   - Provide a “New chat” action that creates a new session and focuses input.

4) Optional quality-of-life improvements
   - Persist the last opened session ID in localStorage so the user returns to their last chat.
   - Add pagination or infinite scroll on messages if needed.
   - Add a simple search that calls `supabaseService.searchMessages(query)`.

Acceptance criteria:
- On page load, if a previous session exists, it is visible and can be opened.
- The user can explicitly switch between sessions via the UI.
- New sessions and messages persist to Supabase and are visible across reloads.
- No raw `process.env.*` usage in front-end code; only `import.meta.env.VITE_*`.

## Troubleshooting

### Common Issues
1. **Port conflicts**: Run `./kill-kijko.sh` to free all ports
2. **API key errors**: Ensure `.env.local` contains valid `GEMINI_API_KEY`
3. **Desktop launcher issues**: Check script permissions with `chmod +x launch-kijko.sh`
4. **Node/npm not found**: Scripts load nvm environment automatically

### Debugging Commands
```bash
# Check running processes
ps aux | grep kijko

# Monitor port usage
lsof -i :5173

# Test build locally
npm run build

# Test MCQ system enhancements
# Visit /mcq-test route to test multi-select and markdown rendering

# Verify environment
node --version && npm --version
```

## AI Interaction Guidelines

When working with this codebase, understand that:
- The AI system is designed for **video production consultation**
- User interactions follow a **structured conversation flow**
- The system adapts its **complexity based on user expertise**
- **Special commands** (`/clarity`, `/research`, `/export`) trigger specific behaviors
- **File attachments** are automatically analyzed as visual or document references
- **YouTube URLs** are detected and used for content analysis

## Development Notes

- Use **React 19** patterns and features
- Maintain **TypeScript strict mode** compliance
- Follow the existing **component composition** patterns
- **Streaming responses** require careful state management
- **File processing** happens client-side for privacy
- **Desktop integration** requires shell script testing on Linux

## Project Structure Consolidation

### Duplicate Files Resolution
This project has both root-level and `src/` directory structures:
- Root level: `App.tsx`, `constants.ts`, `types.ts`, `index.tsx`
- `src/` directory: Contains duplicates/alternatives

**Recommendation**: Consolidate to either root-level OR src/ structure for consistency.

### Component Organization
- Main components in `components/` directory
- Icon components in `components/icons/` subdirectory
- Custom hooks in `hooks/` directory
- Services and utilities in `services/` directory
</file>

<file path="src/components/ChatInput.tsx">
import React, { useState, useRef, useEffect } from 'react';
import { Attachment } from '../types';
import { SendIcon } from './icons/SendIcon';
import { AttachmentIcon } from './icons/AttachmentIcon';
import { XCircleIcon } from './icons/FileIcons';
import { MicrophoneIcon } from './icons/MicrophoneIcon';

interface ChatInputProps {
  onSendMessage: (text: string, attachments: Attachment[]) => void;
  isLoading: boolean;
  isListening: boolean;
  startListening: () => void;
  stopListening: () => void;
  transcript: string;
  isSttSupported: boolean;
}

const MAX_FILES = 5;
const MAX_FILE_SIZE_MB = 20;

const fileToBase64 = (file: File): Promise<string> =>
  new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.readAsDataURL(file);
    reader.onload = () => resolve((reader.result as string).split(',')[1]);
    reader.onerror = (error) => reject(error);
  });

export const ChatInput: React.FC<ChatInputProps> = ({ 
    onSendMessage, 
    isLoading, 
    isListening, 
    startListening, 
    stopListening,
    transcript,
    isSttSupported,
}) => {
  const [text, setText] = useState('');
  const [attachments, setAttachments] = useState<Attachment[]>([]);
  const fileInputRef = useRef<HTMLInputElement>(null);
  const textAreaRef = useRef<HTMLTextAreaElement>(null);

  useEffect(() => {
    setText(transcript);
  }, [transcript]);

  // Auto-resize textarea
  useEffect(() => {
    if (textAreaRef.current) {
      textAreaRef.current.style.height = 'auto';
      textAreaRef.current.style.height = `${textAreaRef.current.scrollHeight}px`;
    }
  }, [text]);


  const handleSendMessage = () => {
    if (isLoading || (!text.trim() && attachments.length === 0)) return;
    onSendMessage(text, attachments);
    setText('');
    setAttachments([]);
  };

  const handleKeyDown = (e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSendMessage();
    }
  };

  const handleFileChange = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const files = e.target.files;
    if (!files) return;

    if (attachments.length + files.length > MAX_FILES) {
        alert(`You can only upload a maximum of ${MAX_FILES} files.`);
        return;
    }

    const newAttachments: Attachment[] = [];
    for (const file of files) {
        if (file.size > MAX_FILE_SIZE_MB * 1024 * 1024) {
            alert(`File ${file.name} is too large. Maximum size is ${MAX_FILE_SIZE_MB}MB.`);
            continue;
        }
        try {
            const data = await fileToBase64(file);
            newAttachments.push({ name: file.name, type: file.type, size: file.size, data });
        } catch (error) {
            console.error("Error converting file to base64", error);
        }
    }
    setAttachments(prev => [...prev, ...newAttachments]);
  };

  const removeAttachment = (index: number) => {
    setAttachments(prev => prev.filter((_, i) => i !== index));
  };

  const handleMicClick = () => {
      if (isListening) {
          stopListening();
      } else {
          startListening();
      }
  }

  return (
    <div className="p-6 border-t border-white/10 flex-shrink-0" style={{ background: 'var(--bg-input)' }}>
      <div className="relative">
        {/* Composer Container */}
        <div className="glass rounded-2xl border border-white/10 overflow-hidden">
          {/* Attachments Preview */}
          {attachments.length > 0 && (
            <div className="p-4 border-b border-white/10">
              <div className="grid grid-cols-2 md:grid-cols-3 lg:grid-cols-4 gap-2">
                {attachments.map((file, index) => (
                  <div key={index} className="bg-gray-700/50 p-3 rounded-xl flex items-center justify-between text-sm backdrop-blur">
                    <span className="truncate text-white/90" title={file.name}>{file.name}</span>
                    <button 
                      onClick={() => removeAttachment(index)} 
                      className="ml-2 text-gray-400 hover:text-red-400 transition-colors p-1 rounded-md hover:bg-red-500/10"
                      aria-label={`Remove ${file.name}`}
                    >
                      <XCircleIcon className="w-4 h-4" />
                    </button>
                  </div>
                ))}
              </div>
            </div>
          )}
          
          {/* Input Row */}
          <div className="flex items-end p-2">
            {/* Attachment Button */}
            <button
              onClick={() => fileInputRef.current?.click()}
              className="p-3 text-gray-400 hover:text-white transition-all duration-200 rounded-lg hover:bg-white/5 focus-ring"
              aria-label="Attach files"
              title="Attach files"
            >
              <AttachmentIcon className="w-5 h-5" />
            </button>
            
            {/* Microphone Button */}
            <button
              onClick={handleMicClick}
              disabled={!isSttSupported}
              className={`
                p-3 transition-all duration-200 rounded-lg focus-ring
                disabled:opacity-50 disabled:cursor-not-allowed
                ${isListening 
                  ? 'text-red-400 bg-red-500/10 animate-glow-pulse' 
                  : 'text-gray-400 hover:text-white hover:bg-white/5'
                }
              `}
              aria-label={isListening ? 'Stop listening' : 'Start listening'}
              title={isSttSupported ? (isListening ? 'Stop listening' : 'Start listening') : 'Speech-to-text is not supported in your browser'}
            >
              <MicrophoneIcon className="w-5 h-5" />
            </button>
            
            {/* Hidden File Input */}
            <input
              type="file"
              multiple
              ref={fileInputRef}
              onChange={handleFileChange}
              className="hidden"
              accept="image/*,video/*,audio/*,.pdf,.doc,.docx,.txt"
            />
            
            {/* Text Input */}
            <textarea
              ref={textAreaRef}
              value={text}
              onChange={(e) => setText(e.target.value)}
              onKeyDown={handleKeyDown}
              placeholder={isListening ? "🎤 Listening..." : "Send message..."}
              className={`
                flex-1 bg-transparent p-3 resize-none outline-none max-h-40
                text-white placeholder:text-gray-500
                ${isListening ? 'placeholder:animate-pulse' : ''}
              `}
              rows={1}
              disabled={isLoading}
            />
            
            {/* Send Button */}
            <button
              onClick={handleSendMessage}
              disabled={isLoading || (!text.trim() && attachments.length === 0)}
              className={`
                p-3 rounded-xl transition-all duration-200 focus-ring
                ${isLoading || (!text.trim() && attachments.length === 0)
                  ? 'bg-gray-600/50 text-gray-400 cursor-not-allowed'
                  : 'gradient-send text-white shadow-lg btn-interactive hover:shadow-xl'
                }
              `}
              aria-label="Send message"
              title="Send message"
            >
              {isLoading ? (
                <div className="w-5 h-5 border-2 border-white border-t-transparent rounded-full animate-spin"></div>
              ) : (
                <svg className="w-5 h-5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M2.01 21L23 12 2.01 3 2 10l15 2-15 2z"/>
                </svg>
              )}
            </button>
          </div>
        </div>
      </div>
    </div>
  );
};
</file>

<file path="src/components/ChatSidebar.tsx">
import React, { useState } from 'react';
import { XMarkIcon, PlusIcon, ChatBubbleLeftIcon, DocumentTextIcon, CogIcon } from '@heroicons/react/24/outline';
import { useChat } from '../contexts/ChatContext';
import { DocumentsSidebar } from './DocumentsSidebar';
import { SettingsTab } from './SettingsTab';

interface SessionItemProps {
  session: {
    id: string;
    title?: string;
    summary?: string;
    created_at: string;
    updated_at?: string;
  };
  isActive: boolean;
  onClick: () => void;
}

const SessionItem: React.FC<SessionItemProps> = ({ session, isActive, onClick }) => {
  const formatDate = (dateStr: string) => {
    const date = new Date(dateStr);
    const now = new Date();
    const diff = now.getTime() - date.getTime();
    const days = Math.floor(diff / (1000 * 60 * 60 * 24));
    
    if (days === 0) return 'Today';
    if (days === 1) return 'Yesterday';
    if (days < 7) return `${days} days ago`;
    return date.toLocaleDateString();
  };

  return (
    <button
      onClick={onClick}
      className={`
        w-full text-left p-3 rounded-lg transition-all duration-200
        hover:bg-gray-700/50 group
        ${isActive 
          ? 'bg-gradient-to-r from-purple-600/20 to-blue-600/20 border border-purple-400/30' 
          : 'bg-gray-800/30 hover:bg-gray-700/50'
        }
      `}
    >
      <div className="flex items-start space-x-3">
        <div className="flex-shrink-0 mt-0.5">
          <ChatBubbleLeftIcon className={`w-4 h-4 ${isActive ? 'text-purple-400' : 'text-gray-400'}`} />
        </div>
        <div className="flex-1 min-w-0">
          <p className={`text-sm font-medium truncate ${isActive ? 'text-white' : 'text-gray-200'}`}>
            {session.summary || session.title || 'Untitled Chat'}
          </p>
          <p className="text-xs text-gray-400 mt-1">
            {formatDate(session.updated_at || session.created_at)}
          </p>
        </div>
      </div>
    </button>
  );
};

const LoadingSkeleton: React.FC = () => (
  <div className="space-y-3">
    {[1, 2, 3].map((i) => (
      <div key={i} className="animate-pulse">
        <div className="flex items-start space-x-3 p-3 rounded-lg bg-gray-800/30">
          <div className="w-4 h-4 bg-gray-600 rounded mt-0.5"></div>
          <div className="flex-1 space-y-2">
            <div className="h-4 bg-gray-600 rounded w-3/4"></div>
            <div className="h-3 bg-gray-600 rounded w-1/2"></div>
          </div>
        </div>
      </div>
    ))}
  </div>
);

type TabType = 'chat' | 'documents' | 'settings';

export const ChatSidebar: React.FC = () => {
  const {
    sidebarOpen,
    setSidebarOpen,
    currentChatId,
    sessions,
    loadingSessions,
    createNewChat,
    switchToSession,
  } = useChat();
  
  const [activeTab, setActiveTab] = useState<TabType>('chat');
  
  // DEBUG: Log sidebar render state
  console.log('[DEBUG] ChatSidebar render - sidebarOpen:', sidebarOpen);

  const handleNewChat = async () => {
    const newChatId = await createNewChat();
    if (newChatId) {
      switchToSession(newChatId);
    }
  };

  const handleSessionClick = (sessionId: string) => {
    switchToSession(sessionId);
  };

  if (!sidebarOpen) return null;

  return (
    <>
      {/* Overlay */}
      <div 
        className="fixed inset-0 bg-black/50 backdrop-blur-sm z-40 transition-opacity"
        onClick={() => setSidebarOpen(false)}
      />
      
      {/* Sidebar */}
      <div className="fixed inset-y-0 left-0 w-80 bg-gray-900/95 backdrop-blur-xl border-r border-gray-700/50 z-50 transform transition-transform duration-300 ease-in-out">
        <div className="flex flex-col h-full">
          {/* Header */}
          <div className="flex items-center justify-between p-4 border-b border-gray-700/50">
            <h2 className="text-lg font-semibold text-white">
              {activeTab === 'chat' ? 'Chat History' : activeTab === 'documents' ? 'Documents' : 'Settings'}
            </h2>
            <button
              onClick={() => setSidebarOpen(false)}
              className="p-2 rounded-lg text-gray-400 hover:text-white hover:bg-gray-700/50 transition-colors"
              aria-label="Close sidebar"
            >
              <XMarkIcon className="w-5 h-5" />
            </button>
          </div>

          {/* Tab Navigation */}
          <div className="flex border-b border-gray-700/30">
            <button
              onClick={() => setActiveTab('chat')}
              className={`
                flex-1 flex items-center justify-center gap-1 px-3 py-3
                transition-all duration-200 relative
                ${activeTab === 'chat' 
                  ? 'text-purple-400' 
                  : 'text-gray-400 hover:text-white'
                }
              `}
              role="tab"
              aria-selected={activeTab === 'chat'}
            >
              <ChatBubbleLeftIcon className="w-4 h-4" />
              <span className="text-xs font-medium">Chats</span>
              {activeTab === 'chat' && (
                <div className="absolute bottom-0 left-0 right-0 h-0.5 bg-gradient-to-r from-purple-500 to-blue-500" />
              )}
            </button>
            <button
              onClick={() => setActiveTab('documents')}
              className={`
                flex-1 flex items-center justify-center gap-1 px-3 py-3
                transition-all duration-200 relative
                ${activeTab === 'documents' 
                  ? 'text-purple-400' 
                  : 'text-gray-400 hover:text-white'
                }
              `}
              role="tab"
              aria-selected={activeTab === 'documents'}
            >
              <DocumentTextIcon className="w-4 h-4" />
              <span className="text-xs font-medium">Documents</span>
              {activeTab === 'documents' && (
                <div className="absolute bottom-0 left-0 right-0 h-0.5 bg-gradient-to-r from-purple-500 to-blue-500" />
              )}
            </button>
            <button
              onClick={() => setActiveTab('settings')}
              className={`
                flex-1 flex items-center justify-center gap-1 px-3 py-3
                transition-all duration-200 relative
                ${activeTab === 'settings' 
                  ? 'text-purple-400' 
                  : 'text-gray-400 hover:text-white'
                }
              `}
              role="tab"
              aria-selected={activeTab === 'settings'}
            >
              <CogIcon className="w-4 h-4" />
              <span className="text-xs font-medium">Settings</span>
              {activeTab === 'settings' && (
                <div className="absolute bottom-0 left-0 right-0 h-0.5 bg-gradient-to-r from-purple-500 to-blue-500" />
              )}
            </button>
          </div>

          {/* Tab Content */}
          <div className="flex-1 overflow-hidden">
            {activeTab === 'chat' ? (
              <>
                {/* New Chat Button */}
                <div className="p-4 border-b border-gray-700/30">
                  <button
                    onClick={handleNewChat}
                    className="
                      w-full flex items-center justify-center space-x-2 
                      p-3 rounded-xl font-medium text-white
                      bg-gradient-to-r from-purple-600 to-blue-600 
                      hover:from-purple-700 hover:to-blue-700 
                      active:scale-[0.98] transition-all duration-150
                      shadow-lg hover:shadow-xl
                    "
                  >
                    <PlusIcon className="w-5 h-5" />
                    <span>New Chat</span>
                  </button>
                </div>

                {/* Sessions List */}
                <div className="flex-1 overflow-y-auto p-4">
                  {loadingSessions ? (
                    <LoadingSkeleton />
                  ) : sessions.length === 0 ? (
                    <div className="flex flex-col items-center justify-center py-8 text-center">
                      <ChatBubbleLeftIcon className="w-12 h-12 text-gray-500 mb-4" />
                      <p className="text-gray-400 text-sm">No previous conversations</p>
                      <p className="text-gray-500 text-xs mt-1">Start a new chat to begin!</p>
                    </div>
                  ) : (
                    <div className="space-y-2">
                      <h3 className="text-xs font-semibold text-gray-400 uppercase tracking-wide mb-3">
                        Recent Chats
                      </h3>
                      {sessions.map((session) => (
                        <SessionItem
                          key={session.id}
                          session={session}
                          isActive={session.id === currentChatId}
                          onClick={() => handleSessionClick(session.id)}
                        />
                      ))}
                    </div>
                  )}
                </div>
              </>
            ) : activeTab === 'documents' ? (
              /* Documents Tab */
              <DocumentsSidebar />
            ) : (
              /* Settings Tab */
              <SettingsTab />
            )}
          </div>

          {/* Footer - Only show for chat tab */}
          {activeTab === 'chat' && (
            <div className="p-4 border-t border-gray-700/30">
              <p className="text-xs text-gray-500 text-center">
                Chat history is automatically saved
              </p>
            </div>
          )}
        </div>
      </div>
    </>
  );
};
</file>

<file path="src/components/SettingsTab.tsx">
import React, { useState, useEffect } from 'react';
import { useForm } from 'react-hook-form';
import { zodResolver } from '@hookform/resolvers/zod';
import { z } from 'zod';
import { CheckIcon, XMarkIcon, ExclamationTriangleIcon } from '@heroicons/react/24/outline';
import { SystemPromptEditor } from './SystemPromptEditor';
import { ModelSelector } from './ModelSelector';
import { Toast, ToastType } from './Toast';
import { useSettings } from '../contexts/SettingsContext';
import { SettingsFormData, GEMINI_MODELS } from '../types/settings';
import { KIJKO_SYSTEM_PROMPT } from '../constants';

// Validation schema
const settingsSchema = z.object({
  systemPrompt: z
    .string()
    .min(10, 'System prompt must be at least 10 characters')
    .max(50000, 'System prompt must be less than 50,000 characters'),
  selectedModel: z.enum([
    // Latest 2.5 Series
    'gemini-2.5-pro', 'gemini-2.5-flash', 'gemini-2.5-flash-lite', 'gemini-2.5-flash-image',
    // 2.0 Series 
    'gemini-2.0-flash', 'gemini-2.0-flash-lite', 'gemini-2.0-flash-experimental',
    // Legacy 1.5 Series
    'gemini-1.5-pro', 'gemini-1.5-flash', 'gemini-1.5-flash-8b'
  ])
});

export const SettingsTab: React.FC = () => {
  const { settings, updateSettings, resetToDefaults, isLoading } = useSettings();
  const [isSaving, setIsSaving] = useState(false);
  const [saveMessage, setSaveMessage] = useState<{ type: 'success' | 'error'; text: string } | null>(null);
  const [toast, setToast] = useState<{ type: ToastType; message: string; visible: boolean }>({ 
    type: 'success', 
    message: '', 
    visible: false 
  });
  const [saveSuccess, setSaveSuccess] = useState(false);

  const {
    handleSubmit,
    setValue,
    watch,
    formState: { errors, isDirty, isValid }
  } = useForm<SettingsFormData>({
    resolver: zodResolver(settingsSchema),
    defaultValues: {
      systemPrompt: settings.systemPrompt,
      selectedModel: settings.selectedModel
    },
    mode: 'onChange'
  });

  const watchedValues = watch();

  // Update form when settings change
  useEffect(() => {
    setValue('systemPrompt', settings.systemPrompt);
    setValue('selectedModel', settings.selectedModel);
  }, [settings, setValue]);

  // Clear save message after 3 seconds
  useEffect(() => {
    if (saveMessage) {
      const timer = setTimeout(() => setSaveMessage(null), 3000);
      return () => clearTimeout(timer);
    }
  }, [saveMessage]);

  const onSubmit = async (data: SettingsFormData) => {
    setIsSaving(true);
    setSaveMessage(null);

    try {
      const success = await updateSettings({
        ...settings,
        ...data
      });

      if (success) {
        setSaveSuccess(true);
        setToast({ type: 'success', message: 'Settings saved successfully! Changes will apply to new conversations.', visible: true });
        setSaveMessage({ type: 'success', text: 'Settings saved successfully!' });
        
        // Reset success animation after delay
        setTimeout(() => setSaveSuccess(false), 2000);
      } else {
        setToast({ type: 'error', message: 'Failed to save settings. Please check your input and try again.', visible: true });
        setSaveMessage({ type: 'error', text: 'Failed to save settings. Please try again.' });
      }
    } catch (error) {
      console.error('Error saving settings:', error);
      setToast({ type: 'error', message: 'An unexpected error occurred while saving settings.', visible: true });
      setSaveMessage({ type: 'error', text: 'An error occurred while saving settings.' });
    } finally {
      setIsSaving(false);
    }
  };

  const handleReset = async () => {
    if (window.confirm('Are you sure you want to reset all settings to default values? This action cannot be undone.')) {
      try {
        await resetToDefaults();
        setToast({ type: 'success', message: 'Settings have been reset to default values.', visible: true });
        setSaveMessage({ type: 'success', text: 'Settings reset to default values.' });
      } catch (error) {
        console.error('Error resetting settings:', error);
        setToast({ type: 'error', message: 'Failed to reset settings. Please try again.', visible: true });
        setSaveMessage({ type: 'error', text: 'Failed to reset settings.' });
      }
    }
  };

  const handleResetSystemPrompt = () => {
    setValue('systemPrompt', KIJKO_SYSTEM_PROMPT, { shouldDirty: true });
  };

  return (
    <div className="h-full flex flex-col">
      <div className="flex-1 overflow-y-auto p-4">
        <form id="settings-form" onSubmit={handleSubmit(onSubmit)} className="space-y-8 max-w-4xl pb-8">
        {/* Header */}
        <div className="border-b border-gray-700 pb-4">
          <h2 className="text-2xl font-bold text-white mb-2">Settings</h2>
          <p className="text-gray-400">
            Configure your Kijko assistant's behavior and model preferences.
          </p>
        </div>

        {/* Save Message */}
        {saveMessage && (
          <div className={`
            p-4 rounded-lg border flex items-center gap-3
            ${saveMessage.type === 'success' 
              ? 'bg-green-500/10 border-green-500/20 text-green-200' 
              : 'bg-red-500/10 border-red-500/20 text-red-200'
            }
          `}>
            {saveMessage.type === 'success' ? (
              <CheckIcon className="w-5 h-5 text-green-400 flex-shrink-0" />
            ) : (
              <ExclamationTriangleIcon className="w-5 h-5 text-red-400 flex-shrink-0" />
            )}
            <span className="text-sm">{saveMessage.text}</span>
          </div>
        )}

        {/* System Prompt Section */}
        <div className="bg-gray-800/30 rounded-xl p-6 border border-gray-700/50">
          <SystemPromptEditor
            value={watchedValues.systemPrompt}
            onChange={(value) => setValue('systemPrompt', value, { shouldDirty: true })}
            onReset={handleResetSystemPrompt}
            isLoading={isLoading || isSaving}
            error={errors.systemPrompt?.message}
          />
        </div>

        {/* Model Selection Section */}
        <div className="bg-gray-800/30 rounded-xl p-6 border border-gray-700/50">
          <ModelSelector
            value={watchedValues.selectedModel}
            onChange={(model) => setValue('selectedModel', model, { shouldDirty: true })}
            disabled={isLoading || isSaving}
            error={errors.selectedModel?.message}
          />
        </div>

        {/* Spacer for fixed footer */}
        <div className="h-32"></div>
        </form>
      </div>
      
      {/* Fixed Footer with Action Buttons */}
      <div className="border-t border-gray-700 bg-gray-900/95 backdrop-blur p-4">
        <div className="flex flex-col sm:flex-row gap-3 max-w-4xl">
          {/* Action Buttons */}
          <div className="flex gap-3 flex-1">
            <button
              type="submit"
              form="settings-form"
              disabled={!isDirty || !isValid || isLoading || isSaving}
              className="
                flex items-center justify-center gap-2 px-6 py-3 rounded-lg font-medium
                bg-gradient-to-r from-purple-600 to-blue-600 text-white
                hover:from-purple-700 hover:to-blue-700
                disabled:from-gray-600 disabled:to-gray-600 disabled:cursor-not-allowed
                transition-all duration-200
                flex-1 sm:flex-initial
              "
            >
              {isSaving ? (
                <>
                  <div className="w-4 h-4 border-2 border-white border-t-transparent rounded-full animate-spin"></div>
                  Saving...
                </>
              ) : saveSuccess ? (
                <>
                  <CheckIcon className="w-4 h-4 text-green-300" />
                  <span className="text-green-300">Saved!</span>
                </>
              ) : (
                <>
                  <CheckIcon className="w-4 h-4" />
                  Save Changes
                </>
              )}
            </button>

            {/* Reset to Defaults - moved from right side for better visibility */}
            <button
              type="button"
              onClick={handleReset}
              disabled={isLoading || isSaving}
              className="
                flex items-center justify-center gap-2 px-6 py-3 rounded-lg font-medium
                bg-red-600/20 text-red-400 border border-red-600/30
                hover:bg-red-600/30 hover:border-red-600/50
                disabled:bg-gray-800 disabled:text-gray-500 disabled:border-gray-700
                disabled:cursor-not-allowed
                transition-all duration-200
                flex-1 sm:flex-initial
              "
            >
              <ExclamationTriangleIcon className="w-4 h-4" />
              Reset to Defaults
            </button>
          </div>
        </div>
        
        {/* Status Info */}
        <div className="text-xs text-gray-500 space-y-1 mt-3">
          <p>• Settings are automatically saved to your browser's local storage</p>
          <p>• Changes will apply to new conversations</p>
          <p>• Current conversations will continue using previous settings</p>
        </div>
      </div>
      
      {/* Toast Notification */}
      <Toast
        message={toast.message}
        type={toast.type}
        isVisible={toast.visible}
        onClose={() => setToast(prev => ({ ...prev, visible: false }))}
      />
    </div>
  );
};
</file>

<file path="src/services/perplexityService.ts">
interface PerplexityMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

interface PerplexityResponse {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: {
    index: number;
    message: {
      role: string;
      content: string;
    };
    finish_reason: string;
  }[];
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

interface FeedbackImprovementRequest {
  systemPrompt: string;
  userQuestion: string;
  originalResponse?: string;
}

export class PerplexityService {
  private apiKey: string | undefined;
  
  constructor() {
    // For local development, check if API key is available via Vite
    // @ts-ignore
    this.apiKey = typeof process !== 'undefined' && process.env?.PERPLEXITY_API_KEY;
  }

  /**
   * Gets an improved response from Perplexity API based on user feedback
   * Uses serverless API endpoint in production, direct API in development
   */
  async getImprovedResponse(request: FeedbackImprovementRequest): Promise<string> {
    const messages: PerplexityMessage[] = [
      {
        role: 'system',
        content: `${request.systemPrompt}\n\nADDITIONAL INSTRUCTION: The user was unsatisfied with a previous response. Please provide a more comprehensive, accurate, and helpful answer to their question. Focus on being more detailed and addressing potential gaps in the original response.`
      },
      {
        role: 'user',
        content: request.userQuestion
      }
    ];

    // If original response is provided, include it for context
    if (request.originalResponse) {
      messages.push({
        role: 'assistant',
        content: request.originalResponse
      });
      messages.push({
        role: 'user',
        content: 'This response wasn\'t quite what I was looking for. Could you provide a better, more detailed answer?'
      });
    }

    try {
      let response: Response;
      
      // Check if we're in development with a local API key
      if (this.apiKey && window.location.hostname === 'localhost') {
        // Direct API call for local development
        response = await fetch('https://api.perplexity.ai/chat/completions', {
          method: 'POST',
          headers: {
            'Accept': 'application/json',
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${this.apiKey}`,
          },
          body: JSON.stringify({
            model: 'pplx-7b-online', // Use sonar-pro if available for higher quality
            stream: false,
            max_tokens: 1024,
            temperature: 0.2, // Slightly higher than 0 for more natural responses
            messages: messages
          }),
        });
      } else {
        // Call our serverless API endpoint in production
        response = await fetch('/api/perplexity', {
          method: 'POST',
          headers: {
            'Accept': 'application/json',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: 'pplx-7b-online', 
            stream: false,
            max_tokens: 1024,
            temperature: 0.2,
            messages: messages
          }),
        });
      }

      if (!response.ok) {
        const errorText = await response.text();
        console.error('Perplexity API error:', errorText);
        throw new Error(`Perplexity API request failed: ${response.status} ${response.statusText}`);
      }

      const data: PerplexityResponse = await response.json();
      
      if (!data.choices || data.choices.length === 0) {
        throw new Error('No response received from Perplexity API');
      }

      return data.choices[0].message.content.trim();
    } catch (error) {
      console.error('Error calling Perplexity API:', error);
      throw new Error('Failed to get improved response from Perplexity API');
    }
  }

  /**
   * Check if the Perplexity service is available
   */
  isAvailable(): boolean {
    // Available if we have a local API key or in production (serverless)
    return !!(this.apiKey || window.location.hostname !== 'localhost');
  }
}

// Export a singleton instance
export const perplexityService = new PerplexityService();
</file>

<file path="README.md">
# Chat VRD - Video Requirements Document Assistant

<!-- Vercel GitHub integration test - Connection test at 2025-09-19 12:59 - Ready for deployment -->

A multimodal, speech-enabled AI assistant built with React 19, TypeScript, and Vite that helps users create comprehensive Video Requirements Documents (VRDs) through an adaptive discovery process.

## 🚀 Features

- **Multimodal Chat Interface** - Text input with file attachments (images, videos, audio, documents)
- **Text-to-Speech Integration** - Built-in speech synthesis for AI responses
- **Adaptive Discovery Engine** - Adjusts guidance level based on user expertise (1-10 clarity scale)
- **YouTube Integration** - Automatic video URL detection and content analysis
- **Desktop Integration** - Native desktop launcher with process management
- **Streaming AI Responses** - Real-time responses from Google Gemini AI

## 📋 Prerequisites

- **Node.js** 18+ (recommended 20+)
- **npm** or **yarn**
- **Google Gemini API Key**

## 🛠️ Installation & Setup

### 1. Install Dependencies
```bash
npm install
```

### 2. Environment Configuration
Create a `.env.local` file in the project root:
```bash
GEMINI_API_KEY=your_gemini_api_key_here
```

### 3. Run Development Server
```bash
npm run dev
```

The app will be available at `http://localhost:5173`

## 🎯 Available Commands

### Development
```bash
npm run dev          # Start development server
npm run build        # Build for production  
npm run preview      # Preview production build
```

### Desktop Integration (Linux)
```bash
./launch-kijko.sh    # Launch app with desktop integration
./kill-kijko.sh      # Stop app and free all ports
```

## 🏗️ Architecture

### Core Stack
- **Frontend**: React 19 + TypeScript
- **Build Tool**: Vite 6.2.0
- **AI Integration**: Google Gemini API (@google/genai)
- **Speech**: Web Speech API for text-to-speech

### Key Components
- **Adaptive AI System**: 350+ line system prompt that adjusts conversation complexity
- **Streaming Interface**: Real-time AI responses with loading states
- **File Processing**: Client-side file conversion (images, videos, audio, PDFs)
- **Command System**: Special commands (`/clarity`, `/research`, `/review`, `/export`)

### File Structure
```
src/
├── components/           # React components
│   ├── ChatHistory.tsx  # Message display
│   ├── ChatInput.tsx    # Input with file uploads
│   ├── ChatMessage.tsx  # Individual messages
│   ├── Header.tsx       # TTS controls
│   └── icons/           # UI icons
├── services/
│   └── geminiService.ts # AI integration
├── hooks/
│   └── useTextToSpeech.ts # TTS functionality
├── constants.ts         # AI system prompt
└── types.ts            # TypeScript definitions
```

## 🎨 Key Features

### Adaptive Discovery Engine
The AI system rates user clarity (1-10) and adjusts its guidance:
- **Low Clarity (1-3)**: Provides scaffolding, examples, multiple-choice options
- **Medium Clarity (4-7)**: Balanced guidance with validation
- **High Clarity (8-10)**: Direct, technical questions with minimal hand-holding

### Multimodal Capabilities
- **File Support**: Images, videos, audio, PDFs, documents (max 5 files, 20MB each)
- **YouTube Analysis**: Automatic video content analysis from URLs
- **Real-time Processing**: Client-side file conversion for privacy

### Command System
Special commands trigger specific behaviors:
- `/clarity [1-10]` - Adjust guidance level
- `/research [topic]` - Research mode
- `/review` - Show current VRD draft  
- `/export` - Generate final VRD document

## 🖥️ Desktop Integration

### Process Management
- **PID Tracking**: App process saved to `/tmp/kijko-app.pid`
- **Port Management**: Automatically handles ports 5173, 3000, 4173, 8080
- **Browser Automation**: Opens in default browser automatically
- **Graceful Shutdown**: Signal-based communication for clean termination

### Desktop Shortcut
The launcher creates a desktop shortcut at `/home/david/Desktop/Kijko.desktop` with:
- Categories: Development, AudioVideo, Graphics
- Automatic browser launching
- Process monitoring

## 🚀 Deployment

### Vercel Deployment
The project is configured for Vercel deployment:

1. **Connect Repository** to Vercel
2. **Add Environment Variables** in Vercel dashboard:
   - `GEMINI_API_KEY` (mark as sensitive)
3. **Deploy** - Vercel auto-detects Vite configuration

Build settings:
- **Build Command**: `npm run build`
- **Output Directory**: `dist`
- **Framework**: Vite

## 🔧 Development

### File Processing
- Files converted to base64 client-side
- Size limits: 20MB per file, max 5 files
- Supported formats: Images, videos, audio, PDFs, documents

### State Management
- React hooks for state management
- Streaming updates for real-time AI responses
- Message history with auto-scroll

### Error Handling
- Graceful fallbacks for TTS and file upload failures
- User-friendly error messages
- Comprehensive try-catch around AI service calls

## 🎤 Text-to-Speech

The app includes built-in TTS functionality:
- **Web Speech API** integration
- **Toggle Control** in header
- **Auto-narration** of AI responses (when enabled)
- **Stop/Start Controls** for user control

## 📝 License

This project is part of the Kijko Video Brief Assistant system.

## 🔗 Related

This is the frontend component of a larger video production workflow system. For other components or enterprise features, please contact the development team.
</file>

<file path="src/contexts/ChatContext.tsx">
import React, { createContext, useContext, useState, useEffect, ReactNode } from 'react';
import { supabaseService, ChatSession } from '../services/supabaseService';

interface ChatSessionSummary extends ChatSession {
  summary?: string;
}

interface ChatContextType {
  // Sidebar state
  sidebarOpen: boolean;
  setSidebarOpen: (open: boolean) => void;
  
  // Session management
  currentChatId: string | null;
  setCurrentChatId: (id: string | null) => void;
  sessions: ChatSessionSummary[];
  setSessions: (sessions: ChatSessionSummary[]) => void;
  
  // Loading states
  loadingSessions: boolean;
  setLoadingSessions: (loading: boolean) => void;
  
  // Actions
  loadChatSessions: () => Promise<void>;
  createNewChat: () => Promise<string | null>;
  switchToSession: (sessionId: string) => void;
}

const ChatContext = createContext<ChatContextType | null>(null);

export const useChat = () => {
  const context = useContext(ChatContext);
  if (!context) {
    throw new Error('useChat must be used within a ChatProvider');
  }
  return context;
};

interface ChatProviderProps {
  children: ReactNode;
}

export const ChatProvider: React.FC<ChatProviderProps> = ({ children }) => {
  const [sidebarOpen, setSidebarOpen] = useState(false);
  const [currentChatId, setCurrentChatId] = useState<string | null>(null);
  const [sessions, setSessions] = useState<ChatSessionSummary[]>([]);
  const [loadingSessions, setLoadingSessions] = useState(false);

  // Load chat sessions from Supabase
  const loadChatSessions = async () => {
    if (!supabaseService.isAvailable()) return;
    
    setLoadingSessions(true);
    try {
      const chatSessions = await supabaseService.getChatSessions();
      
      // Add summaries to sessions (truncate title or use first message)
      const sessionsWithSummaries: ChatSessionSummary[] = chatSessions.map(session => ({
        ...session,
        summary: session.title || `Chat from ${new Date(session.created_at).toLocaleDateString()}`
      }));
      
      setSessions(sessionsWithSummaries);
    } catch (error) {
      console.error('Failed to load chat sessions:', error);
    } finally {
      setLoadingSessions(false);
    }
  };

  // Create a new chat session
  const createNewChat = async (): Promise<string | null> => {
    if (!supabaseService.isAvailable()) return null;
    
    try {
      const session = await supabaseService.createChatSession('Kijko Chat Session');
      if (session) {
        // Add to sessions list
        const newSessionWithSummary: ChatSessionSummary = {
          ...session,
          summary: session.title || `New Chat ${new Date().toLocaleDateString()}`
        };
        setSessions(prev => [newSessionWithSummary, ...prev]);
        return session.id;
      }
    } catch (error) {
      console.error('Failed to create new chat:', error);
    }
    return null;
  };

  // Switch to a specific session
  const switchToSession = (sessionId: string) => {
    setCurrentChatId(sessionId);
    setSidebarOpen(false); // Close sidebar after selection
  };

  // Initialize Supabase and load sessions on mount
  useEffect(() => {
    const initializeAndLoad = async () => {
      // Initialize Supabase auth first (anonymous sign-in if needed)
      await supabaseService.initialize();
      // Then load conversations
      await loadChatSessions();
    };
    initializeAndLoad();
  }, []);

  const value: ChatContextType = {
    sidebarOpen,
    setSidebarOpen,
    currentChatId,
    setCurrentChatId,
    sessions,
    setSessions,
    loadingSessions,
    setLoadingSessions,
    loadChatSessions,
    createNewChat,
    switchToSession,
  };

  return (
    <ChatContext.Provider value={value}>
      {children}
    </ChatContext.Provider>
  );
};
</file>

<file path="src/services/supabaseService.ts">
import { createClient, SupabaseClient } from '@supabase/supabase-js';

// Database types
export interface User {
  id: string;
  email: string;
}

export interface ChatSession {
  id: string;
  user_id: string;
  title?: string;
  created_at: string;
  updated_at?: string;
}

export interface Message {
  id: string;
  chat_id: string;
  user_id: string;
  content: string;
  role: 'user' | 'assistant';
  parent_message_id?: string;
  created_at: string;
  updated_at?: string;
}

export interface Database {
  public: {
    Tables: {
      chat_sessions: {
        Row: ChatSession;
        Insert: {
          user_id: string;
          title?: string;
          updated_at?: string;
        };
        Update: {
          title?: string;
          updated_at?: string;
        };
      };
      messages: {
        Row: Message;
        Insert: {
          chat_id: string;
          user_id: string;
          content: string;
          role: 'user' | 'assistant';
          parent_message_id?: string;
        };
        Update: {
          content?: string;
          updated_at?: string;
        };
      };
    };
  };
}

class SupabaseService {
  private client: any; // TODO: Fix Supabase types properly
  private initializePromise: Promise<any> | null = null;

  constructor() {
    const supabaseUrl = import.meta.env.VITE_SUPABASE_URL || '';
    const supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY || '';
    
    // Debug logging
    console.log('[Supabase] Initializing with URL:', supabaseUrl ? 'Set' : 'Missing');
    console.log('[Supabase] Anon key:', supabaseAnonKey ? 'Set' : 'Missing');
    
    if (!supabaseUrl || !supabaseAnonKey) {
      console.warn('Supabase configuration is missing. Chat history features will not be available.');
      this.client = null as any; // Will cause errors if used without proper config
      return;
    }

    this.client = createClient<Database>(supabaseUrl, supabaseAnonKey);
    console.log('[Supabase] Client created successfully');
  }

  /**
   * Initialize the service and ensure user authentication
   */
  async initialize(): Promise<any> {
    if (!this.client) {
      console.warn('Supabase client not configured');
      return null;
    }

    // If initialization is already in progress, return the existing promise
    if (this.initializePromise) {
      return this.initializePromise;
    }

    // Start a new initialization process
    this.initializePromise = (async () => {
      try {
        const { data: { session } } = await this.client.auth.getSession();
        if (session && session.user) {
          console.log('Using existing session for user:', session.user.id);
          return session.user;
        }

        console.log('No existing session, signing in anonymously...');
        const { data, error } = await this.client.auth.signInAnonymously();
        if (error) {
          console.error('Failed to sign in anonymously:', error);
          return null;
        }

        console.log('Signed in anonymously as:', data.user?.id);
        return data.user;
      } catch (error) {
        console.error('Failed to initialize auth:', error);
        return null;
      } finally {
        // Reset the promise after completion
        this.initializePromise = null;
      }
    })();

    return this.initializePromise;
  }

  /**
   * Get the current user
   */
  async getCurrentUser() {
    if (!this.client) return null;
    
    const { data: { session } } = await this.client.auth.getSession();
    if (session?.user) {
      return session.user;
    }
    
    // If no session, initialize to sign in anonymously
    return this.initialize();
  }

  /**
   * Sign in anonymously for demo purposes
   */
  async signInAnonymously() {
    const { data, error } = await this.client.auth.signInAnonymously();
    if (error) {
      console.error('Error signing in anonymously:', error);
      throw error;
    }
    return data.user;
  }

  /**
   * Create a new chat session
   */
  async createChatSession(title?: string): Promise<ChatSession | null> {
    const user = await this.getCurrentUser();
    if (!user) {
      console.error('No authenticated user');
      return null;
    }

    const { data, error } = await this.client
      .from('chat_sessions')
      .insert([
        { 
          user_id: user.id, 
          title: title || `Chat ${new Date().toLocaleDateString()}`,
          updated_at: new Date().toISOString()
        }
      ])
      .select()
      .single();

    if (error) {
      console.error('Error creating chat session:', error);
      return null;
    }

    return data;
  }

  /**
   * Get all chat sessions for the current user
   */
  async getChatSessions(): Promise<ChatSession[]> {
    const user = await this.getCurrentUser();
    if (!user) return [];

    const { data, error } = await this.client
      .from('chat_sessions')
      .select('*')
      .eq('user_id', user.id)
      .order('updated_at', { ascending: false });

    if (error) {
      console.error('Error fetching chat sessions:', error);
      return [];
    }

    return data || [];
  }

  /**
   * Get a specific chat session
   */
  async getChatSession(sessionId: string): Promise<ChatSession | null> {
    const { data, error } = await this.client
      .from('chat_sessions')
      .select('*')
      .eq('id', sessionId)
      .single();

    if (error) {
      console.error('Error fetching chat session:', error);
      return null;
    }

    return data;
  }

  /**
   * Update a chat session
   */
  async updateChatSession(sessionId: string, updates: Partial<ChatSession>): Promise<boolean> {
    const { error } = await this.client
      .from('chat_sessions')
      .update({
        ...updates,
        updated_at: new Date().toISOString()
      })
      .eq('id', sessionId);

    if (error) {
      console.error('Error updating chat session:', error);
      return false;
    }

    return true;
  }

  /**
   * Delete a chat session and all its messages
   */
  async deleteChatSession(sessionId: string): Promise<boolean> {
    // Delete messages first due to foreign key constraints
    const { error: messagesError } = await this.client
      .from('messages')
      .delete()
      .eq('chat_id', sessionId);

    if (messagesError) {
      console.error('Error deleting messages:', messagesError);
      return false;
    }

    // Then delete the session
    const { error: sessionError } = await this.client
      .from('chat_sessions')
      .delete()
      .eq('id', sessionId);

    if (sessionError) {
      console.error('Error deleting chat session:', sessionError);
      return false;
    }

    return true;
  }

  /**
   * Add a message to a chat session
   */
  async addMessage(
    chatId: string,
    content: string,
    role: 'user' | 'assistant',
    parentMessageId?: string
  ): Promise<Message | null> {
    const user = await this.getCurrentUser();
    if (!user) return null;

    const { data, error } = await this.client
      .from('messages')
      .insert([
        {
          chat_id: chatId,
          user_id: user.id,
          content,
          role,
          parent_message_id: parentMessageId
        }
      ])
      .select()
      .single();

    if (error) {
      console.error('Error adding message:', error);
      return null;
    }

    // Update session's updated_at timestamp
    await this.updateChatSession(chatId, {});

    return data;
  }

  /**
   * Get messages for a chat session
   */
  async getMessages(chatId: string, limit = 100): Promise<Message[]> {
    const { data, error } = await this.client
      .from('messages')
      .select('*')
      .eq('chat_id', chatId)
      .order('created_at', { ascending: true })
      .limit(limit);

    if (error) {
      console.error('Error fetching messages:', error);
      return [];
    }

    return data || [];
  }

  /**
   * Update a message (for editing functionality)
   */
  async updateMessage(messageId: string, content: string): Promise<boolean> {
    const { error } = await this.client
      .from('messages')
      .update({
        content,
        updated_at: new Date().toISOString()
      })
      .eq('id', messageId);

    if (error) {
      console.error('Error updating message:', error);
      return false;
    }

    return true;
  }

  /**
   * Delete a message
   */
  async deleteMessage(messageId: string): Promise<boolean> {
    const { error } = await this.client
      .from('messages')
      .delete()
      .eq('id', messageId);

    if (error) {
      console.error('Error deleting message:', error);
      return false;
    }

    return true;
  }

  /**
   * Get quoted message details for reply context
   */
  async getQuotedMessage(messageId: string): Promise<Message | null> {
    const { data, error } = await this.client
      .from('messages')
      .select('*')
      .eq('id', messageId)
      .single();

    if (error) {
      console.error('Error fetching quoted message:', error);
      return null;
    }

    return data;
  }

  /**
   * Search messages across all user's chat sessions
   */
  async searchMessages(query: string, limit = 50): Promise<Message[]> {
    const user = await this.getCurrentUser();
    if (!user) return [];

    const { data, error } = await this.client
      .from('messages')
      .select(`
        *,
        chat_sessions!inner(user_id)
      `)
      .eq('chat_sessions.user_id', user.id)
      .textSearch('content', query)
      .order('created_at', { ascending: false })
      .limit(limit);

    if (error) {
      console.error('Error searching messages:', error);
      return [];
    }

    return data || [];
  }

  /**
   * Check if service is properly configured
   */
  isAvailable(): boolean {
    return !!this.client;
  }

  /**
   * Get the Supabase client for advanced operations
   */
  getClient(): any {
    return this.client;
  }
}

// Export singleton instance
export const supabaseService = new SupabaseService();
</file>

<file path="src/App.tsx">
import React, { useState, useEffect, useCallback } from 'react';
import { Chat } from '@google/genai';
import { ChatHistory } from './components/ChatHistory';
import { ChatInput } from './components/ChatInput';
import { Header } from './components/Header';
import EnhancedChatMessage from './components/EnhancedChatMessage';
import { ChatSidebar } from './components/ChatSidebar';
import { ChatWindow } from './components/ChatWindow';
import { ChatProvider, useChat } from './contexts/ChatContext';
import { SettingsProvider } from './contexts/SettingsContext';
import { UIMessage, Attachment } from './types';
import { startKijkoChat, sendMessageToKijkoStream } from './services/geminiService';
import { perplexityService } from './services/perplexityService';
import { supabaseService } from './services/supabaseService';
import { useTextToSpeech } from './hooks/useTextToSpeech';
import { useSpeechToText } from './hooks/useSpeechToText';
import { MCQOption, stripMarkdownForTTS } from './utils/messageClassifier';
import { KIJKO_SYSTEM_PROMPT } from './constants';

const AppContent: React.FC = () => {
  const { isSpeaking, isTtsEnabled, setIsTtsEnabled, speak, stop: stopTts } = useTextToSpeech();


  return (
    <div className="flex flex-col h-screen" style={{ background: 'var(--bg-main)' }}>
      <Header isTtsEnabled={isTtsEnabled} setIsTtsEnabled={setIsTtsEnabled} isSpeaking={isSpeaking} stopSpeech={stopTts} />
      {/* Chat Sidebar */}
      <ChatSidebar />
      {/* Chat Window */}
      <ChatWindow 
        isTtsEnabled={isTtsEnabled}
        isSpeaking={isSpeaking}
        speak={speak}
        stopTts={stopTts}
      />
    </div>
  );
};

// Main App component with providers
const App: React.FC = () => {
  return (
    <SettingsProvider>
      <ChatProvider>
        <AppContent />
      </ChatProvider>
    </SettingsProvider>
  );
};

export default App;
</file>

<file path="src/components/Header.tsx">
import React from 'react';
import { Bars3Icon, SpeakerWaveIcon, SpeakerXMarkIcon, XMarkIcon } from '@heroicons/react/24/outline';
import { SpeakerOnIcon, SpeakerOffIcon } from './icons/SpeakerIcons';
import { useChat } from '../contexts/ChatContext';

interface HeaderProps {
    isTtsEnabled: boolean;
    setIsTtsEnabled: (enabled: boolean) => void;
    isSpeaking: boolean;
    stopSpeech: () => void;
}

export const Header: React.FC<HeaderProps> = ({ isTtsEnabled, setIsTtsEnabled, isSpeaking, stopSpeech }) => {
    const { setSidebarOpen } = useChat();
    
    const handleToggle = () => {
        if (isSpeaking) {
            stopSpeech();
        }
        setIsTtsEnabled(!isTtsEnabled);
    };
    
    const handleMenuClick = () => {
        setSidebarOpen(true);
    };

    const handleClose = () => {
        // Create shutdown signal file that the launch script monitors
        const shutdownSignal = new Blob(['shutdown'], { type: 'text/plain' });
        const url = URL.createObjectURL(shutdownSignal);
        const a = document.createElement('a');
        a.href = url;
        a.download = 'kijko-shutdown-signal.txt';
        a.style.display = 'none';
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(url);
        
        // Try to close the window (may not work in all browsers)
        setTimeout(() => {
            window.close();
        }, 1000);
    };

  return (
    <header className="flex items-center justify-between px-6 py-4 glass border-b border-white/10 flex-shrink-0">
      <div className="flex items-center space-x-3">
        {/* Menu Button */}
        <button 
          onClick={handleMenuClick}
          className="p-2 rounded-lg text-gray-400 hover:text-white transition-colors focus-ring"
          aria-label="Open chat history"
          aria-haspopup="true"
        >
          <Bars3Icon className="w-6 h-6" />
        </button>
        
        {/* App Icon with Gradient */}
        <div className="w-10 h-10 rounded-full gradient-accent flex items-center justify-center">
          <svg className="w-6 h-6 text-white" fill="currentColor" viewBox="0 0 24 24">
            <path d="M12 2L13.09 8.26L20 9L13.09 9.74L12 16L10.91 9.74L4 9L10.91 8.26L12 2Z" />
          </svg>
        </div>
        
        <div>
          <h1 className="text-xl font-bold text-gradient">Kijko</h1>
          <p className="text-sm text-gray-400">Video Brief Assistant</p>
        </div>
      </div>
      
      <div className="flex items-center space-x-2">
        {/* Text-to-Speech Toggle */}
        <button 
          onClick={handleToggle}
          className={`
            p-3 rounded-xl transition-all duration-200 btn-interactive focus-ring
            ${isTtsEnabled 
              ? 'gradient-accent text-white shadow-lg' 
              : 'bg-gray-700/50 text-gray-400 hover:text-white hover:bg-gray-600/50'
            }
            ${isSpeaking ? 'animate-glow-pulse' : ''}
          `}
          aria-label={isTtsEnabled ? "Disable Text-to-Speech" : "Enable Text-to-Speech"}
          title={isTtsEnabled ? "Disable Text-to-Speech" : "Enable Text-to-Speech"}
        >
          <div className={isSpeaking ? 'animate-bounce-dots' : ''}>
            {isTtsEnabled ? <SpeakerWaveIcon className="w-5 h-5" /> : <SpeakerXMarkIcon className="w-5 h-5" />}
          </div>
        </button>
        
        {/* Close Button */}
        <button
          onClick={handleClose}
          className="p-3 rounded-xl bg-red-500/20 text-red-400 hover:bg-red-500/30 hover:text-red-300 transition-all duration-200 btn-interactive focus-ring"
          aria-label="Close Kijko App"
          title="Close Kijko App"
        >
          <XMarkIcon className="w-5 h-5" />
        </button>
      </div>
    </header>
  );
};
</file>

<file path="src/components/OptionGroup.tsx">
import React, { useState, useCallback } from 'react';
import ReactMarkdown from 'react-markdown';
import { MCQOption } from '../utils/messageClassifier';

interface OptionGroupProps {
  options: MCQOption[];
  onSelect: (option: MCQOption) => void;
  onSubmit?: (selectedOptions: MCQOption[], openText?: string) => void;
  disabled?: boolean;
  short?: boolean;
  allowMultiple?: boolean;
  showOpenText?: boolean; // Add option to show/hide open text field
}

interface OptionButtonProps {
  option: MCQOption;
  onToggle: (option: MCQOption) => void;
  disabled?: boolean;
  selected?: boolean;
  allowMultiple?: boolean;
}

interface OptionRowProps {
  option: MCQOption;
  onToggle: (option: MCQOption) => void;
  disabled?: boolean;
  selected?: boolean;
  allowMultiple?: boolean;
}

const OptionButton: React.FC<OptionButtonProps> = ({ option, onToggle, disabled = false, selected = false, allowMultiple = false }) => {
  const [isPressed, setIsPressed] = useState(false);

  const handleClick = useCallback(() => {
    if (!disabled) {
      onToggle(option);
    }
  }, [option, onToggle, disabled]);

  const handleMouseDown = () => setIsPressed(true);
  const handleMouseUp = () => setIsPressed(false);
  const handleMouseLeave = () => setIsPressed(false);

  // Strip markdown for clean text extraction
  const stripMarkdown = (text: string) => {
    return text.replace(/\*\*([^*]+)\*\*/g, '$1').replace(/\*([^*]+)\*/g, '$1');
  };

  return (
    <button
      onClick={handleClick}
      onMouseDown={handleMouseDown}
      onMouseUp={handleMouseUp}
      onMouseLeave={handleMouseLeave}
      disabled={disabled}
      className={`
        w-full text-left px-4 py-3 rounded-xl font-medium text-white
        transition-all duration-150 ease-out
        btn-interactive focus-ring flex items-center
        ${selected 
          ? 'gradient-user shadow-lg transform scale-[0.98]' 
          : disabled 
            ? 'bg-gray-600 opacity-50 cursor-not-allowed' 
            : 'bg-gray-700 hover:bg-gray-600 active:scale-[0.97]'
        }
        ${isPressed ? 'animate-glow-pulse' : ''}
      `}
      aria-pressed={selected}
      role={allowMultiple ? 'checkbox' : 'button'}
      aria-checked={allowMultiple ? selected : undefined}
    >
      {allowMultiple && (
        <div className={`
          w-5 h-5 rounded border-2 flex items-center justify-center mr-3 flex-shrink-0
          transition-all duration-200
          ${selected 
            ? 'border-white bg-white' 
            : 'border-gray-400'
          }
        `}>
          {selected && (
            <svg className="w-3 h-3 text-gray-800" fill="currentColor" viewBox="0 0 20 20">
              <path fillRule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clipRule="evenodd" />
            </svg>
          )}
        </div>
      )}
      <div className="flex-1">
        <span className="text-sm opacity-90">{option.label}.</span>
        <span className="ml-2">
          <ReactMarkdown 
            components={{ 
              p: React.Fragment,
              strong: ({ children }) => <strong className="font-bold">{children}</strong>,
              em: ({ children }) => <em className="italic">{children}</em>
            }}
          >
            {option.text}
          </ReactMarkdown>
        </span>
      </div>
    </button>
  );
};

const OptionRow: React.FC<OptionRowProps> = ({ option, onToggle, disabled = false, selected = false, allowMultiple = false }) => {
  const handleClick = useCallback(() => {
    if (!disabled) {
      onToggle(option);
    }
  }, [option, onToggle, disabled]);

  return (
    <button
      onClick={handleClick}
      disabled={disabled}
      className={`
        w-full flex items-center justify-between p-4 rounded-lg
        transition-all duration-150 ease-out
        btn-interactive focus-ring
        ${selected 
          ? 'bg-purple-900/50 border border-purple-400' 
          : disabled 
            ? 'bg-gray-800/50 opacity-50 cursor-not-allowed' 
            : 'bg-gray-800/30 hover:bg-gray-700/50 active:scale-[0.98]'
        }
      `}
      aria-checked={selected}
      role={allowMultiple ? 'checkbox' : 'radio'}
    >
      <div className="flex items-center space-x-4 flex-1">
        <div className={`
          flex items-center justify-center w-8 h-8 rounded-full text-sm font-bold
          ${selected ? 'gradient-accent text-white' : 'bg-gray-600 text-gray-300'}
        `}>
          {option.label}
        </div>
        <span className="text-left text-white/90 flex-1">
          <ReactMarkdown 
            components={{ 
              p: React.Fragment,
              strong: ({ children }) => <strong className="font-bold">{children}</strong>,
              em: ({ children }) => <em className="italic">{children}</em>
            }}
          >
            {option.text}
          </ReactMarkdown>
        </span>
      </div>
      
      {allowMultiple ? (
        <div className={`
          w-5 h-5 rounded border-2 flex items-center justify-center
          transition-all duration-200
          ${selected 
            ? 'border-purple-400 bg-purple-400' 
            : 'border-gray-500'
          }
        `}>
          {selected && (
            <svg className="w-3 h-3 text-white" fill="currentColor" viewBox="0 0 20 20">
              <path fillRule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clipRule="evenodd" />
            </svg>
          )}
        </div>
      ) : (
        <div className={`
          w-5 h-5 rounded-full border-2 flex items-center justify-center
          transition-all duration-200
          ${selected 
            ? 'border-purple-400 bg-purple-400' 
            : 'border-gray-500'
          }
        `}>
          {selected && (
            <div className="w-2 h-2 bg-white rounded-full animate-scale-press" />
          )}
        </div>
      )}
    </button>
  );
};

// Intelligent MCQ type detection
function detectShouldAllowMultiple(
  questionText: string | undefined, 
  options: MCQOption[], 
  allowMultipleProp?: boolean
): boolean {
  // If explicitly set, use that
  if (allowMultipleProp !== undefined) return allowMultipleProp;
  
  const optionTexts = options.map(opt => opt.text.toLowerCase());
  
  // Check if all options are numbers (ratings, scales, etc) - ALWAYS single select
  const allNumbers = options.every(opt => /^\d+(\.\d+)?$/.test(opt.text.trim()));
  if (allNumbers) return false; // Numbers like 1-10 ratings are NEVER multi-select
  
  // For all non-scale questions, default to multi-select
  // This ensures users can select multiple options as per requirements
  return true; // Changed to always return true for non-scale questions
}

export const OptionGroup: React.FC<OptionGroupProps> = ({ 
  options, 
  onSelect,
  onSubmit,
  disabled = false, 
  short,
  allowMultiple = false,
  showOpenText = true // Default to showing open text for all questions
}) => {
  const [selectedOptions, setSelectedOptions] = useState<MCQOption[]>([]);
  const [isProcessing, setIsProcessing] = useState(false);
  const [openTextValue, setOpenTextValue] = useState<string>('');

  // Use intelligent detection
  const shouldAllowMultiple = detectShouldAllowMultiple(undefined, options, allowMultiple);
  
  // Check if this is a rating scale (all numbers)
  const isRatingScale = options.every(opt => /^\d+(\.\d+)?$/.test(opt.text.trim()));

  // Determine layout based on option length or explicit short prop
  const isShortLayout = short ?? options.every(option => option.text.length <= 30);

  const handleToggle = useCallback((option: MCQOption) => {
    if (disabled || isProcessing) return; // Prevent clicks during processing

    if (shouldAllowMultiple) {
      setSelectedOptions(prev => 
        prev.find(opt => opt.label === option.label)
          ? prev.filter(opt => opt.label !== option.label)
          : [...prev, option]
      );
    } else {
      // Single select behavior
      setSelectedOptions(prev => {
        const isAlreadySelected = prev.find(opt => opt.label === option.label);
        if (isAlreadySelected) {
          // Deselect if clicking the same option
          return [];
        } else {
          // Select this option
          if (isRatingScale) {
            // For rating scales, auto-submit immediately with guard
            setIsProcessing(true);
            // Format as "I choose: X" will happen in ChatWindow
            onSelect(option);
            // Keep processing state to prevent double-clicks
            setTimeout(() => {
              setIsProcessing(false);
              setSelectedOptions([]);
            }, 500);
          }
          return [option];
        }
      });
    }
  }, [disabled, shouldAllowMultiple, isRatingScale, onSelect, isProcessing]);

  const handleSubmit = useCallback(() => {
    // Allow submit if options selected OR open text provided
    if (selectedOptions.length > 0 || openTextValue.trim()) {
      setIsProcessing(true);
      
      // Combine selected options with open text
      const combinedText = [
        ...selectedOptions.map(opt => opt.text),
        ...(openTextValue.trim() ? [`Other: ${openTextValue.trim()}`] : [])
      ].join('; ');
      
      if (onSubmit) {
        onSubmit(selectedOptions, openTextValue.trim());
      } else {
        // For single callback, submit combined option with text
        const combinedOption: MCQOption = {
          label: selectedOptions.length > 0 ? selectedOptions.map(opt => opt.label).join(',') : 'custom',
          text: combinedText,
          fullText: combinedText
        };
        onSelect(combinedOption);
      }
      
      // Reset after submission
      setTimeout(() => {
        setIsProcessing(false);
        setSelectedOptions([]);
        setOpenTextValue('');
      }, 150);
    }
  }, [selectedOptions, openTextValue, onSelect, onSubmit]);

  // Check if we should show the submit button
  const canSubmit = selectedOptions.length > 0 || openTextValue.trim().length > 0;
  const showSubmitButton = shouldAllowMultiple || (!isRatingScale && canSubmit);

  return (
    <div className="mt-4 space-y-3 animate-slide-up">
      {shouldAllowMultiple && !isRatingScale && (
        <div className="text-sm text-gray-400 mb-3 flex items-center">
          <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 20 20">
            <path fillRule="evenodd" d="M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7-4a1 1 0 11-2 0 1 1 0 012 0zM9 9a1 1 0 000 2v3a1 1 0 001 1h1a1 1 0 100-2v-3a1 1 0 00-1-1H9z" clipRule="evenodd" />
          </svg>
          Select all that apply, or enter your own answer below
        </div>
      )}
      
      {isShortLayout ? (
        // Short layout: Full-width gradient buttons
        <div className="space-y-2">
          {options.map((option) => (
            <OptionButton
              key={option.label}
              option={option}
              onToggle={handleToggle}
              disabled={disabled}
              selected={selectedOptions.some(opt => opt.label === option.label)}
              allowMultiple={shouldAllowMultiple}
            />
          ))}
        </div>
      ) : (
        // Long layout: Vertical list with checkboxes/radio buttons
        <div className="space-y-3" role={shouldAllowMultiple ? 'group' : 'radiogroup'} aria-label="Multiple choice options">
          {options.map((option) => (
            <OptionRow
              key={option.label}
              option={option}
              onToggle={handleToggle}
              disabled={disabled}
              selected={selectedOptions.some(opt => opt.label === option.label)}
              allowMultiple={shouldAllowMultiple}
            />
          ))}
        </div>
      )}
      
      {/* Open-ended text input for all non-scale questions */}
      {showOpenText && !isRatingScale && (
        <div className="pt-2">
          <label className="block text-sm text-gray-400 mb-2">
            <span className="flex items-center">
              <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 20 20">
                <path fillRule="evenodd" d="M18 13V5a2 2 0 00-2-2H4a2 2 0 00-2 2v8a2 2 0 002 2h3l3 3 3-3h3a2 2 0 002-2zM5 7a1 1 0 011-1h8a1 1 0 110 2H6a1 1 0 01-1-1zm1 3a1 1 0 100 2h3a1 1 0 100-2H6z" clipRule="evenodd" />
              </svg>
              Or provide your own answer (optional):
            </span>
          </label>
          <textarea
            value={openTextValue}
            onChange={(e) => setOpenTextValue(e.target.value)}
            placeholder="Type your answer here..."
            disabled={disabled || isProcessing}
            className="
              w-full px-4 py-3 rounded-xl
              bg-gray-700 text-white placeholder-gray-400
              border border-gray-600 focus:border-blue-500
              focus:outline-none focus:ring-2 focus:ring-blue-500/20
              transition-all duration-150
              disabled:opacity-50 disabled:cursor-not-allowed
              resize-none
            "
            rows={3}
            aria-label="Open-ended response"
          />
        </div>
      )}
      
      {/* Submit button for multi-select and when there's input */}
      {showSubmitButton && canSubmit && (
        <div className="pt-3">
          <button
            onClick={handleSubmit}
            disabled={disabled || isProcessing}
            className="
              w-full px-4 py-3 rounded-xl font-medium text-white
              bg-blue-600 hover:bg-blue-700 active:scale-[0.98]
              transition-all duration-150 ease-out
              btn-interactive focus-ring
              disabled:opacity-50 disabled:cursor-not-allowed
              shadow-lg
            "
          >
            {isProcessing ? 'Processing...' : 
             shouldAllowMultiple && selectedOptions.length > 0 ? 
               `Submit ${selectedOptions.length} selection${selectedOptions.length !== 1 ? 's' : ''}${openTextValue.trim() ? ' + comment' : ''}` :
               openTextValue.trim() && selectedOptions.length === 0 ?
                 'Submit your answer' :
                 'Continue'
            }
          </button>
        </div>
      )}
      
      {/* Loading state for single select */}
      {!shouldAllowMultiple && isProcessing && (
        <div className="flex items-center justify-center pt-2">
          <div className="loading-dots">
            <div className="dot"></div>
            <div className="dot"></div>
            <div className="dot"></div>
          </div>
        </div>
      )}
    </div>
  );
};

export default OptionGroup;
</file>

<file path=".env.local.example">
# Chat VRD Environment Configuration
# Copy this file to .env.local and fill in your actual values

# Google Gemini API Key (required)
# Get your key from: https://ai.google.dev/
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_API_KEY_BACKUP_1=your_backup_key_1
GEMINI_API_KEY_BACKUP_2=your_backup_key_2

# Perplexity API Key (required for thumbs down feedback)
# Get your key from: https://www.perplexity.ai/settings/api
# NOTE: This should be stored in Vercel environment variables, NOT with VITE_ prefix
# It's handled server-side by the /api/perplexity serverless function
PERPLEXITY_API_KEY=your_perplexity_api_key_here

# Supabase Configuration (required for chat history)
# These are from your Supabase project dashboard
# Note: VITE_ prefix is required for Vite to expose these in the browser
VITE_SUPABASE_URL=https://tlbxbwpqgzrqkhidklbm.supabase.co
VITE_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InRsYnhid3BxZ3pycWtoaWRrbGJtIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTgyODkxMzYsImV4cCI6MjA3Mzg2NTEzNn0.1MnGqA7OrG7GAFCHGUUjOxJfblys9uk3V1Xeu0WXGmU

# Optional: Additional configuration
# NODE_ENV=development
</file>

<file path="src/components/EnhancedChatMessage.tsx">
import React, { useMemo, useCallback } from 'react';
import ReactMarkdown from 'react-markdown';
import remarkGfm from 'remark-gfm';
import { 
  HandThumbUpIcon, 
  HandThumbDownIcon, 
  DocumentDuplicateIcon,
  SpeakerWaveIcon,
  ArrowPathIcon 
} from '@heroicons/react/24/outline';
import { UIMessage } from '../types';
import { classifyMessage, stripMarkdownForTTS, MCQOption, generateDefaultMCQOptions, extractMCQOptions } from '../utils/messageClassifier';
import OptionGroup from './OptionGroup';

interface EnhancedChatMessageProps {
  message: UIMessage;
  onOptionSelect?: (option: MCQOption) => void;
  onThumbsDown?: (messageId: string) => void;
  onCopy?: (text: string) => void;
  onSpeak?: (text: string) => void;
  onRetry?: (messageId: string) => void;
  showActions?: boolean;
}

interface MessageActionButtonProps {
  icon: React.ComponentType<{ className?: string }>;
  label: string;
  onClick: () => void;
  variant?: 'default' | 'danger';
}

const MessageActionButton: React.FC<MessageActionButtonProps> = ({ 
  icon: Icon, 
  label, 
  onClick, 
  variant = 'default' 
}) => {
  return (
    <button
      onClick={(e: React.MouseEvent<HTMLButtonElement>) => {
        e.stopPropagation(); // Prevent event bubbling
        console.log('[DEBUG] MessageActionButton clicked, label:', label);
        onClick();
      }}
      className={`
        p-2 rounded-lg transition-all duration-150
        ${variant === 'danger' 
          ? 'text-red-400 hover:text-red-300 hover:bg-red-900/20' 
          : 'text-gray-400 hover:text-white hover:bg-gray-700/50'
        }
        focus-ring btn-interactive
      `}
      aria-label={label}
      title={label}
    >
      <Icon className="w-4 h-4" />
    </button>
  );
};

const EnhancedChatMessage: React.FC<EnhancedChatMessageProps> = ({
  message,
  onOptionSelect,
  onThumbsDown,
  onCopy,
  onSpeak,
  onRetry,
  showActions = true
}) => {
  const isUser = message.role === 'user';
  const isStreaming = message.isStreaming;

  // Classify the message to determine rendering approach
  const classifiedMessage = useMemo(() => {
    return !isUser ? classifyMessage(message.text) : { type: 'text' as const, originalText: message.text };
  }, [message.text, isUser]);

  // Prepare text for TTS
  const ttsText = useMemo(() => {
    return stripMarkdownForTTS(message.text);
  }, [message.text]);

  const handleOptionSelect = useCallback((option: MCQOption) => {
    if (onOptionSelect) {
      onOptionSelect(option);
    }
  }, [onOptionSelect]);

  const handleCopy = useCallback(() => {
    if (onCopy) {
      onCopy(message.text);
    }
  }, [onCopy, message.text]);

  const handleSpeak = useCallback(() => {
    if (onSpeak) {
      onSpeak(ttsText);
    }
  }, [onSpeak, ttsText]);

  const handleThumbsDown = useCallback(() => {
    console.log('[DEBUG] EnhancedChatMessage handleThumbsDown called');
    console.log('[DEBUG] onThumbsDown prop:', onThumbsDown);
    console.log('[DEBUG] message.id:', message.id);
    if (onThumbsDown) {
      onThumbsDown(message.id);
    } else {
      console.warn('[DEBUG] onThumbsDown prop is undefined');
    }
  }, [onThumbsDown, message.id]);

  const handleRetry = useCallback(() => {
    if (onRetry) {
      onRetry(message.id);
    }
  }, [onRetry, message.id]);

  // Custom markdown renderers for better TTS compatibility
  const markdownComponents = {
    // Render code blocks as simple text for TTS
    code({ children }: { children: React.ReactNode }) {
      return <code className="bg-gray-800 px-1 rounded text-sm">{children}</code>;
    },
    
    // Handle images with alt text
    img({ alt, src }: { alt?: string; src?: string }) {
      return (
        <span className="inline-block text-gray-400 text-sm">
          [Image: {alt || 'No description'}]
        </span>
      );
    },
    
    // Style headers
    h1: ({ children }: { children: React.ReactNode }) => (
      <h1 className="text-xl font-bold mb-2 text-white">{children}</h1>
    ),
    h2: ({ children }: { children: React.ReactNode }) => (
      <h2 className="text-lg font-bold mb-2 text-white">{children}</h2>
    ),
    h3: ({ children }: { children: React.ReactNode }) => (
      <h3 className="text-base font-bold mb-1 text-white">{children}</h3>
    ),
    
    // Style lists
    ul: ({ children }: { children: React.ReactNode }) => (
      <ul className="list-disc list-inside space-y-1 mb-2">{children}</ul>
    ),
    ol: ({ children }: { children: React.ReactNode }) => (
      <ol className="list-decimal list-inside space-y-1 mb-2">{children}</ol>
    ),
    
    // Style links
    a: ({ children, href }: { children: React.ReactNode; href?: string }) => (
      <a 
        href={href} 
        className="text-blue-400 hover:text-blue-300 underline"
        target="_blank"
        rel="noopener noreferrer"
      >
        {children}
      </a>
    ),
    
    // Style strong/bold text
    strong: ({ children }: { children: React.ReactNode }) => (
      <strong className="font-bold text-white">{children}</strong>
    ),
    
    // Style emphasis/italic text
    em: ({ children }: { children: React.ReactNode }) => (
      <em className="italic text-white/90">{children}</em>
    ),
    
    // Style paragraphs
    p: ({ children }: { children: React.ReactNode }) => (
      <p className="mb-2 last:mb-0 text-white">{children}</p>
    )
  };

  return (
    <div 
      className={`flex ${isUser ? 'justify-end' : 'justify-start'} mb-4 animate-slide-up`}
      role="article"
      aria-label={`${isUser ? 'User' : 'Assistant'} message`}
    >
      <div className={`
        max-w-[85%] sm:max-w-[75%] 
        ${isUser 
          ? 'gradient-user rounded-tl-xl rounded-tr-xl rounded-bl-xl text-white' 
          : 'bg-gray-800 rounded-tr-xl rounded-tl-xl rounded-br-xl text-white'
        }
        px-4 py-3 shadow-lg
        ${isStreaming ? 'animate-glow-pulse' : ''}
      `}>
        {/* Message Content */}
        <div className="space-y-2">
          {isUser ? (
            // User messages: simple text rendering
            <div className="whitespace-pre-wrap break-words">
              {message.text}
            </div>
          ) : (
            // All assistant messages get MCQ options by default
            <div>
              <div className="mb-2">
                <div 
                  className="prose prose-invert prose-sm max-w-none text-white"
                  aria-live={isStreaming ? 'polite' : undefined}
                >
                  {console.log('[DEBUG] Rendering assistant message text:', message.text)}
                  {console.log('[DEBUG] Text contains asterisks:', message.text.includes('*'))}
                  <ReactMarkdown
                    remarkPlugins={[remarkGfm]}
                    components={markdownComponents}
                  >
                    {message.text}
                  </ReactMarkdown>
                </div>
              </div>
              
              {!isStreaming && message.showOptions === true && (
                <OptionGroup
                  options={generateDefaultMCQOptions(message.text)}
                  onSelect={handleOptionSelect}
                  disabled={!onOptionSelect}
                />
              )}
            </div>
          )}

          {/* Streaming indicator */}
          {isStreaming && (
            <div className="flex items-center space-x-2 pt-2">
              <div className="loading-dots">
                <div className="dot"></div>
                <div className="dot"></div>
                <div className="dot"></div>
              </div>
              <span className="text-xs text-white/60">Generating...</span>
            </div>
          )}
        </div>

        {/* Message Actions (only for assistant messages) */}
        {!isUser && !isStreaming && showActions && (
          <div className="flex items-center justify-end space-x-1 mt-3 pt-2 border-t border-gray-700/50">
            {onCopy && (
              <MessageActionButton
                icon={DocumentDuplicateIcon}
                label="Copy message"
                onClick={handleCopy}
              />
            )}
            
            {onSpeak && (
              <MessageActionButton
                icon={SpeakerWaveIcon}
                label="Read aloud"
                onClick={handleSpeak}
              />
            )}
            
            {onRetry && (
              <MessageActionButton
                icon={ArrowPathIcon}
                label="Regenerate response"
                onClick={handleRetry}
              />
            )}
            
            <MessageActionButton
              icon={HandThumbUpIcon}
              label="Good response"
              onClick={() => {}} // TODO: Implement thumbs up
            />
            
            {onThumbsDown && (
              <MessageActionButton
                icon={HandThumbDownIcon}
                label="Improve response"
                onClick={handleThumbsDown}
                variant="danger"
              />
            )}
          </div>
        )}

        {/* Attachments (if any) */}
        {message.attachments && message.attachments.length > 0 && (
          <div className="mt-3 pt-2 border-t border-gray-700/50">
            <div className="flex flex-wrap gap-2">
              {message.attachments.map((attachment, index) => (
                <div
                  key={index}
                  className="text-xs bg-gray-700/50 px-2 py-1 rounded"
                  title={attachment.name}
                >
                  📎 {attachment.name}
                </div>
              ))}
            </div>
          </div>
        )}
      </div>
    </div>
  );
};

export default EnhancedChatMessage;
</file>

<file path="package.json">
{
  "name": "kijko-video-brief-assistant",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview"
  },
  "dependencies": {
    "@google/genai": "^1.16.0",
    "@google/generative-ai": "^0.24.1",
    "@heroicons/react": "^2.2.0",
    "@hookform/resolvers": "^5.2.2",
    "@react-pdf/renderer": "^4.3.1",
    "@supabase/supabase-js": "^2.57.4",
    "@types/prismjs": "^1.26.5",
    "@types/react-router-dom": "^5.3.3",
    "html2canvas": "^1.4.1",
    "idb-keyval": "^6.2.2",
    "jspdf": "^3.0.3",
    "lucide-react": "^0.544.0",
    "prismjs": "^1.30.0",
    "react": "^19.1.1",
    "react-dom": "^19.1.1",
    "react-hook-form": "^7.63.0",
    "react-markdown": "^10.1.0",
    "react-router-dom": "^7.9.1",
    "react-simple-code-editor": "^0.14.1",
    "remark-gfm": "^4.0.1",
    "tailwindcss-animate": "^1.0.7",
    "turndown": "^7.2.1",
    "zod": "^4.1.11"
  },
  "devDependencies": {
    "@types/node": "^22.14.0",
    "typescript": "~5.8.2",
    "vite": "^6.2.0"
  }
}
</file>

<file path="src/components/ChatWindow.tsx">
import React, { useState, useEffect, useCallback, useRef } from 'react';
import { Chat } from '@google/genai';
import { ChatInput } from './ChatInput';
import EnhancedChatMessage from './EnhancedChatMessage';
import { UIMessage, Attachment } from '../types';
import { startKijkoChat, sendMessageToKijkoStream } from '../services/geminiService';
import { perplexityService } from '../services/perplexityService';
import { supabaseService } from '../services/supabaseService';
import { useTextToSpeech } from '../hooks/useTextToSpeech';
import { useSpeechToText } from '../hooks/useSpeechToText';
import { MCQOption, stripMarkdownForTTS } from '../utils/messageClassifier';
import { KIJKO_SYSTEM_PROMPT } from '../constants';
import { useChat } from '../contexts/ChatContext';
import { useSettings } from '../contexts/SettingsContext';
import { ProgressIndicator } from './ProgressIndicator';
import { useProgress } from '../hooks/useProgress';
import { DocumentExporter } from './DocumentExporter';

interface ChatWindowProps {
  isTtsEnabled: boolean;
  isSpeaking: boolean;
  speak: (text: string) => void;
  stopTts: () => void;
}

export const ChatWindow: React.FC<ChatWindowProps> = ({ 
  isTtsEnabled, 
  isSpeaking, 
  speak, 
  stopTts 
}) => {
  const { currentChatId, setCurrentChatId, createNewChat, loadChatSessions } = useChat();
  const { settings } = useSettings();
  const [chat, setChat] = useState<Chat | null>(null);
  const [messages, setMessages] = useState<UIMessage[]>([]);
  const [isLoading, setIsLoading] = useState(false);
  const [loadingMessages, setLoadingMessages] = useState(false);
  const { isListening, transcript, startListening, stopListening, setTranscript, isSttSupported } = useSpeechToText();
  
  // Progress tracking
  const {
    currentStep,
    totalSteps,
    currentStepLabel,
    nextStepLabel,
    percentage,
    isVisible: isProgressVisible,
    updateProgressByContent,
    goToNextStep,
    resetProgress
  } = useProgress();
  
  // Auto-scroll refs and constants
  const SCROLL_THRESHOLD = 100;
  const scrollContainerRef = useRef<HTMLDivElement | null>(null);
  const bottomAnchorRef = useRef<HTMLDivElement | null>(null);
  const userWasNearBottomRef = useRef(true);
  
  // Check if user is near bottom (within threshold)
  const isUserNearBottom = useCallback(() => {
    const container = scrollContainerRef.current;
    if (!container) return true; // Default to true for initial load
    const distanceFromBottom = container.scrollHeight - container.scrollTop - container.clientHeight;
    return distanceFromBottom < SCROLL_THRESHOLD;
  }, []);

  // Track scroll position before messages change
  useEffect(() => {
    userWasNearBottomRef.current = isUserNearBottom();
  }, [messages.length, isUserNearBottom]);
  
  // Auto-scroll after new messages or content updates
  useEffect(() => {
    // Only scroll if user was previously near bottom
    if (userWasNearBottomRef.current && bottomAnchorRef.current) {
      // Small delay to ensure DOM updates are complete
      requestAnimationFrame(() => {
        bottomAnchorRef.current?.scrollIntoView({ behavior: 'smooth', block: 'end' });
      });
    }
  }, [messages, isLoading]); // Trigger on messages change and loading state
  
  // Initialize chat and session
  useEffect(() => {
    const initializeChat = async () => {
      const newChat = startKijkoChat(settings.selectedModel, settings.systemPrompt);
      setChat(newChat);

      // If no current chat ID, create a new session
      if (!currentChatId && supabaseService.isAvailable()) {
        try {
          let user = await supabaseService.getCurrentUser();
          if (!user) {
            user = await supabaseService.signInAnonymously();
          }

          const newSessionId = await createNewChat();
          if (newSessionId) {
            setCurrentChatId(newSessionId);
            resetProgress(); // Reset progress for new chat
            
            // Create welcome message and save it immediately
            const welcomeMessage: UIMessage = {
              id: Date.now().toString(),
              role: 'model',
              text: "Hello! I'm Kijko, your video brief assistant. I'll help you create a comprehensive production plan for your video project. To get started, could you tell me about your video idea? Feel free to share as much or as little as you have in mind, and we'll build from there.",
              attachments: [],
              isStreaming: false,
              showOptions: false, // Don't show MCQ buttons on welcome message
            };
            
            setMessages([welcomeMessage]);
            // Save using the new session ID directly (fixes race condition)
            await supabaseService.addMessage(newSessionId, welcomeMessage.text, 'assistant');
            await loadChatSessions(); // Refresh the sidebar
          }
        } catch (error) {
          console.error('Error initializing chat session:', error);
          // Fallback to showing welcome message without saving
          const welcomeMessage: UIMessage = {
            id: Date.now().toString(),
            role: 'model',
            text: "Hello! I'm Kijko, your video brief assistant. I'll help you create a comprehensive production plan for your video project. To get started, could you tell me about your video idea? Feel free to share as much or as little as you have in mind, and we'll build from there.",
            attachments: [],
            isStreaming: false,
            showOptions: false, // Don't show MCQ buttons on welcome message
          };
          setMessages([welcomeMessage]);
        }
      }
    };

    initializeChat();
  }, [settings.selectedModel, settings.systemPrompt]);

  // Load messages when currentChatId changes
  useEffect(() => {
    const loadMessages = async () => {
      if (!currentChatId || !supabaseService.isAvailable()) {
        // If no session ID, show welcome message
        if (!currentChatId) {
          const welcomeMessage: UIMessage = {
            id: Date.now().toString(),
            role: 'model',
            text: "Hello! I'm Kijko, your video brief assistant. I'll help you create a comprehensive production plan for your video project. To get started, could you tell me about your video idea? Feel free to share as much or as little as you have in mind, and we'll build from there.",
            attachments: [],
            isStreaming: false,
            showOptions: false, // Don't show MCQ buttons on welcome message
          };
          setMessages([welcomeMessage]);
        }
        return;
      }

      setLoadingMessages(true);
      try {
        const supabaseMessages = await supabaseService.getMessages(currentChatId);
        const uiMessages: UIMessage[] = supabaseMessages.map((msg, index) => ({
          id: msg.id,
          role: msg.role === 'user' ? 'user' : 'model',
          text: msg.content,
          attachments: [],
          isStreaming: false,
          // First message should never have options, subsequent assistant messages should
          showOptions: msg.role === 'assistant' && index > 0 ? true : false,
        }));
        
        setMessages(uiMessages);
      } catch (error) {
        console.error('Failed to load messages:', error);
        // Fallback to welcome message
        const welcomeMessage: UIMessage = {
          id: Date.now().toString(),
          role: 'model',
          text: "Hello! I'm Kijko, your video brief assistant.",
          attachments: [],
          isStreaming: false,
          showOptions: false, // Don't show MCQ buttons on welcome message
        };
        setMessages([welcomeMessage]);
      } finally {
        setLoadingMessages(false);
      }
    };

    if (currentChatId) {
      loadMessages();
    }
  }, [currentChatId]);

  const handleSendMessage = useCallback(async (text: string, attachments: Attachment[]) => {
    if (!text.trim() && attachments.length === 0) return;
    if (!chat) return;

    stopTts();
    if (isListening) {
      stopListening();
    }
    
    const userMessage: UIMessage = {
      id: Date.now().toString(),
      role: 'user',
      text,
      attachments,
    };
    setMessages(prev => [...prev, userMessage]);
    setIsLoading(true);
    setTranscript('');

    const modelMessageId = (Date.now() + 1).toString();
    const modelMessage: UIMessage = {
      id: modelMessageId,
      role: 'model',
      text: '',
      attachments: [],
      isStreaming: true,
      showOptions: true, // Enable MCQ options for regular assistant messages
    };
    setMessages(prev => [...prev, modelMessage]);

    try {
      const stream = await sendMessageToKijkoStream(chat, text, attachments, 0, settings.selectedModel, settings.systemPrompt);
      let fullResponse = '';
      for await (const chunk of stream) {
        fullResponse += chunk.text;
        setMessages(prev => prev.map(msg => 
          msg.id === modelMessageId ? { ...msg, text: fullResponse } : msg
        ));
      }

      setMessages(prev => prev.map(msg => 
        msg.id === modelMessageId ? { ...msg, isStreaming: false } : msg
      ));

      // Update progress based on assistant's response content
      updateProgressByContent(fullResponse);

      if (isTtsEnabled) {
        speak(fullResponse);
      }
      
      // Save messages to Supabase if available
      if (currentChatId && supabaseService.isAvailable()) {
        await supabaseService.addMessage(currentChatId, text, 'user');
        await supabaseService.addMessage(currentChatId, fullResponse, 'assistant');
      }

    } catch (error) {
      console.error("Error sending message:", error);
      const errorMessage = 'Sorry, I encountered an error. Could you please try again?';
      setMessages(prev => prev.map(msg => 
        msg.id === modelMessageId ? { ...msg, text: errorMessage, isStreaming: false } : msg
      ));
    } finally {
      setIsLoading(false);
    }
  }, [chat, isTtsEnabled, speak, stopTts, isListening, stopListening, setTranscript, currentChatId, settings.selectedModel, settings.systemPrompt]);

  // Handle MCQ option selection
  const handleOptionSelect = useCallback(async (option: MCQOption) => {
    if (!chat) return;
    
    // Only send the formatted "I choose: X" message, not both
    // This prevents double submission
    await handleSendMessage(`I choose: ${option.text}`, []);
  }, [chat, handleSendMessage]);

  // Handle thumbs down feedback with Perplexity improvement
  const handleThumbsDown = useCallback(async (messageId: string) => {
    console.log('[DEBUG] handleThumbsDown called with messageId:', messageId);
    console.log('[DEBUG] perplexityService.isAvailable():', perplexityService.isAvailable());
    
    if (!perplexityService.isAvailable()) {
      console.warn('Perplexity service not available for feedback improvement');
      return;
    }

    const messageToImprove = messages.find(msg => msg.id === messageId);
    if (!messageToImprove) return;

    const messageIndex = messages.findIndex(msg => msg.id === messageId);
    const userMessage = messageIndex > 0 ? messages[messageIndex - 1] : null;
    
    if (!userMessage || userMessage.role !== 'user') {
      console.error('Could not find user message for improvement');
      return;
    }

    try {
      setIsLoading(true);
      
      const improvedResponse = await perplexityService.getImprovedResponse({
        systemPrompt: KIJKO_SYSTEM_PROMPT,
        userQuestion: userMessage.text,
        originalResponse: messageToImprove.text
      });

      const improvedText = `${improvedResponse}\n\n*[This response was improved using Perplexity AI]*`;
      console.log('[DEBUG] Setting improved text:', improvedText);
      console.log('[DEBUG] Text includes asterisks:', improvedText.includes('*'));
      setMessages(prev => prev.map(msg => 
        msg.id === messageId 
          ? { ...msg, text: improvedText }
          : msg
      ));

      if (isTtsEnabled) {
        speak(stripMarkdownForTTS(improvedResponse));
      }

    } catch (error) {
      console.error('Error improving response:', error);
      setMessages(prev => prev.map(msg => 
        msg.id === messageId 
          ? { ...msg, text: `${msg.text}\n\n*[Sorry, could not improve this response. Please try asking the question differently.]*` }
          : msg
      ));
    } finally {
      setIsLoading(false);
    }
  }, [messages, isTtsEnabled, speak]);

  // Handle copy message to clipboard
  const handleCopy = useCallback(async (text: string) => {
    try {
      await navigator.clipboard.writeText(text);
      console.log('Message copied to clipboard');
    } catch (error) {
      console.error('Failed to copy message:', error);
    }
  }, []);

  // Handle speak message with TTS
  const handleSpeak = useCallback((text: string) => {
    const cleanText = stripMarkdownForTTS(text);
    speak(cleanText);
  }, [speak]);

  // Handle retry message generation
  const handleRetry = useCallback(async (messageId: string) => {
    const messageIndex = messages.findIndex(msg => msg.id === messageId);
    const userMessage = messageIndex > 0 ? messages[messageIndex - 1] : null;
    
    if (!userMessage || userMessage.role !== 'user') {
      console.error('Could not find user message for retry');
      return;
    }

    setMessages(prev => prev.filter(msg => msg.id !== messageId));
    await handleSendMessage(userMessage.text, []);
  }, [messages, handleSendMessage]);

  if (loadingMessages) {
    return (
      <div className="flex-1 flex items-center justify-center">
        <div className="text-center">
          <div className="loading-dots mb-4">
            <div className="dot"></div>
            <div className="dot"></div>
            <div className="dot"></div>
          </div>
          <p className="text-gray-400">Loading conversation...</p>
        </div>
      </div>
    );
  }

  return (
    <>
      {/* Progress Indicator */}
      <ProgressIndicator
        currentStep={currentStep}
        totalSteps={totalSteps}
        currentStepLabel={currentStepLabel}
        nextStepLabel={nextStepLabel}
        percentage={percentage}
        isVisible={isProgressVisible}
      />
      
      {/* Chat Messages */}
      <div className="flex-1 overflow-hidden">
        <div 
          ref={scrollContainerRef}
          className="h-full overflow-y-auto p-4 space-y-4"
          onScroll={() => {
            // Update the scroll position tracking when user manually scrolls
            userWasNearBottomRef.current = isUserNearBottom();
          }}
        >
          {/* Show export button when VRD process is complete */}
          {percentage >= 100 && messages.length > 10 && (
            <div className="flex justify-center mb-6 p-4 bg-gray-800/50 rounded-lg">
              <div className="text-center">
                <p className="text-green-400 mb-3">✅ Your VRD is complete!</p>
                <DocumentExporter 
                  messages={messages}
                  title="Video Requirements Document"
                  onExportComplete={(docId) => {
                    console.log('Document saved:', docId);
                  }}
                />
              </div>
            </div>
          )}
          
          {messages.map((message) => {
            console.log('[DEBUG] Rendering message with onThumbsDown:', handleThumbsDown);
            return (
              <EnhancedChatMessage
                key={message.id}
                message={message}
                onOptionSelect={handleOptionSelect}
                onThumbsDown={handleThumbsDown}
                onCopy={handleCopy}
                onSpeak={handleSpeak}
                onRetry={handleRetry}
                showActions={!isLoading}
              />
            );
          })}
          
          {/* Loading indicator when processing */}
          {isLoading && (
            <div className="flex justify-start mb-4">
              <div className="bg-gray-800 rounded-tr-xl rounded-tl-xl rounded-br-xl px-4 py-3 animate-glow-pulse">
                <div className="loading-dots">
                  <div className="dot"></div>
                  <div className="dot"></div>
                  <div className="dot"></div>
                </div>
              </div>
            </div>
          )}
          
          {/* Bottom anchor for auto-scroll */}
          <div ref={bottomAnchorRef} aria-hidden="true" />
        </div>
      </div>
      
      <ChatInput 
        onSendMessage={handleSendMessage} 
        isLoading={isLoading}
        isListening={isListening}
        startListening={startListening}
        stopListening={stopListening}
        transcript={transcript}
        isSttSupported={isSttSupported}
      />
    </>
  );
};
</file>

<file path="src/utils/messageClassifier.ts">
export interface MCQOption {
  label: string;
  text: string;
  fullText: string;
  followupQuestionId?: string; // ID of next question if this option is selected
}

export interface QuestionStep {
  id: string;
  prompt: string;
  options: MCQOption[];
  isConditional?: boolean; // Whether this question depends on a previous answer
  parentOptionId?: string; // Which option from parent question triggers this
}

export interface ClassifiedMessage {
  type: 'text' | 'mcq';
  stem?: string;
  options?: MCQOption[];
  originalText: string;
}

/**
 * Classifies a message to determine if it's a multiple choice question
 * Returns message type with parsed content for MCQ rendering
 */
export function classifyMessage(messageText: string): ClassifiedMessage {
  const text = messageText.trim();
  
  // Quick checks for MCQ indicators
  const hasQuestionMark = text.includes('?');
  
  // Additional heuristics for MCQ detection
  const mcqKeywords = [
    'choose the', 'select the', 'which of the following',
    'what is the best', 'which option', 'pick the',
    'the correct answer', 'which statement',
    'rate your', 'scale of', 'on a scale', 'how would you rate', 'please rate', 'could you rate'
  ];
  
  const hasKeywords = mcqKeywords.some(keyword => 
    text.toLowerCase().includes(keyword.toLowerCase())
  );
  
  // Additional pattern detection for scale/rating questions
  const hasScalePattern = /scale of \d+(-\d+)?|rate.*\d+-\d+/i.test(text);
  
  // Only try to parse options if we have MCQ indicators
  if (!hasQuestionMark || (!hasKeywords && !hasScalePattern)) {
    return {
      type: 'text',
      originalText: text
    };
  }
  
  // Normalize text to handle different bullet types and quotes
  const safeText = text
    // Replace curly/smart quotes with standard quotes
    .replace(/[‘’]/g, "'")
    .replace(/[“”]/g, '"')
    // Normalize bullets to consistent bullet point
    .replace(/[•‣◦⁃∙]/g, "•");
  
  // Robust pattern for MCQ options that handles flexible whitespace, quotes, and bullets
  const mcqBulletPattern = /^[\s\t]*[•\-*●‣][\s\t]*(\d+)[\s\t]*=[\s\t]*['"‘’“”]?(.+?)['"‘’“”]?\s*$/gmi;
  
  let options: MCQOption[] = [];
  let match: RegExpExecArray | null;
  
  // Extract all MCQ options using the robust pattern
  while ((match = mcqBulletPattern.exec(safeText)) !== null) {
    options.push({
      label: match[1], // The number (1, 5, 10, etc.)
      text: match[2].trim(), // The option text
      fullText: match[0].trim() // The full match
    });
  }
  
  // If we found enough options, return MCQ
  if (options.length >= 2) {
    // Extract the stem (question part before options)
    const firstOptionIndex = text.indexOf(options[0].fullText);
    const stem = firstOptionIndex > 0 ? text.substring(0, firstOptionIndex).trim() : text;
    
    return {
      type: 'mcq',
      stem,
      options,
      originalText: text
    };
  }
  
  // Default to text if no MCQ structure found
  return {
    type: 'text',
    originalText: text
  };
}

/**
 * Utility to strip markdown formatting for TTS
 */
export function stripMarkdownForTTS(text: string): string {
  return text
    // Remove bold/italic markers
    .replace(/\*\*([^*]+)\*\*/g, '$1')
    .replace(/\*([^*]+)\*/g, '$1')
    .replace(/__([^_]+)__/g, '$1')
    .replace(/_([^_]+)_/g, '$1')
    
    // Remove code blocks and inline code
    .replace(/```[\s\S]*?```/g, '[code block]')
    .replace(/`([^`]+)`/g, '$1')
    
    // Remove links but keep text
    .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1')
    
    // Remove headers
    .replace(/#{1,6}\s+(.+)/g, '$1')
    
    // Remove lists markers but keep content
    .replace(/^\s*[•\-*]\s+/gm, '')
    .replace(/^\s*\d+\.\s+/gm, '')
    
    // Remove images
    .replace(/!\[([^\]]*)\]\([^)]+\)/g, '$1 image')
    
    // Clean up extra whitespace
    .replace(/\n{3,}/g, '\n\n')
    .trim();
}

/**
 * Format option text for display (with proper spacing and capitalization)
 */
export function formatOptionText(text: string): string {
  return text
    .trim()
    .replace(/^\w/, (c) => c.toUpperCase()) // Capitalize first letter
    .replace(/\.$/, ''); // Remove trailing period if present
}

/**
 * Extract MCQ options that are already present in the message
 * Handles various formats like "1 = 'text'", "A) text", "1. text", etc.
 */
export function extractMCQOptions(messageText: string): MCQOption[] {
  // Normalize line endings first
  let normalizedText = messageText.replace(/\r\n|\r/g, '\n');

  // Helper to sanitize each line for robust matching across browsers
  const sanitize = (line: string) => {
    return line
      // convert various unicode spaces to regular space
      .replace(/[\u00A0\u1680\u180E\u2000-\u200B\u202F\u205F\u3000]/g, ' ')
      // normalize smart quotes to straight quotes
      .replace(/[‘’‚‛❛❟⸂⸃＇]/g, "'")
      .replace(/[“”„‟❝❞〝〞＂]/g, '"')
      // remove leading bullets/dashes
      .replace(/^[•–—\-▪●*]+\s*/, '')
      // collapse spaces
      .replace(/\s+/g, ' ')
      .trim();
  };

  const options: MCQOption[] = [];
  const lines = normalizedText.split('\n');

  // CRITICAL: Find the main question line first (ends with ?)
  const questionLineIndex = lines.findIndex(line => line.trim().endsWith('?'));
  const startIndex = questionLineIndex >= 0 ? questionLineIndex + 1 : 0;

  // 1) Try explicit numbered options: 1 = 'text' | 1. text | 1: text
  const eqPattern = /^(\d+)\s*=\s*["']([^"']+)["']\s*$/;
  const dotPattern = /^(\d+)[\.:]\s+(.+)$/;
  
  // 2) Try bullet point options with text content (most common format)
  const bulletPattern = /^\s*[•\-*]\s+(.+)$/;
  
  // Only process lines AFTER the main question
  for (let i = startIndex; i < lines.length; i++) {
    const raw = lines[i].trim();
    if (!raw) continue; // Skip empty lines
    
    const line = sanitize(raw);
    
    // Try numbered format: 1 = 'text'
    let m = eqPattern.exec(line);
    if (m) {
      options.push({ label: m[1], text: m[2].trim(), fullText: line });
      continue;
    }
    
    // Try numbered format: 1. text or 1: text
    m = dotPattern.exec(line);
    if (m) {
      options.push({ label: m[1], text: m[2].trim(), fullText: line });
      continue;
    }
    
    // Try bullet point format
    m = bulletPattern.exec(raw);
    if (m && m[1].trim().length > 3 && !m[1].trim().endsWith('?')) {
      options.push({ 
        label: String(options.length + 1), 
        text: m[1].trim(), 
        fullText: m[1].trim() 
      });
      continue;
    }
    
    // FALLBACK: If it's a non-empty line after the question and not already processed,
    // treat it as an option (handles mixed formats like "Entertain" without bullet)
    // BUT exclude lines that are clearly explanatory text
    const isLikelyExplanation = 
      raw.toLowerCase().includes('your answer') ||
      raw.toLowerCase().includes('this helps') ||
      raw.toLowerCase().includes('please') ||
      raw.toLowerCase().includes('feel free') ||
      raw.toLowerCase().includes('let me know') ||
      raw.toLowerCase().includes('helps me') ||
      raw.length > 100; // Long lines are probably explanations, not options
    
    if (raw.length > 2 && !raw.endsWith('?') && !raw.includes(':') && !isLikelyExplanation) {
      options.push({ 
        label: String(options.length + 1), 
        text: raw, 
        fullText: raw 
      });
    }
  }

  // 2) If still nothing, detect scale prompts (rate/scale X-Y) and generate range
  if (options.length < 2) {
    const scaleMatch = normalizedText
      .replace(/[–—]/g, '-') // normalize dashes
      .match(/(?:rate|scale)[^\d]*(\d+)\s*[-to]{1,3}\s*(\d+)/i);
    if (scaleMatch) {
      const start = parseInt(scaleMatch[1], 10);
      const end = parseInt(scaleMatch[2], 10);
      if (!isNaN(start) && !isNaN(end) && end >= start) {
        for (let i = start; i <= end; i++) {
          options.push({ label: String(i), text: String(i), fullText: String(i) });
        }
      }
    }
  }

  return options.length >= 2 ? options : [];
}

/**
 * Generate default MCQ options based on message content
 * This ensures ALL assistant messages have interactive options
 */
/**
 * Extract explicit options from agent questions
 * Handles patterns like "A, B, C, or D" or "Are you looking to X, Y, Z?"
 */
function extractExplicitChoices(text: string): string[] {
  const choices: string[] = [];
  const lines = text.split('\n');
  
  // CRITICAL: Find the main question first (line ending with ?)
  // Everything before this is likely context/question, not an option
  const questionLineIndex = lines.findIndex(line => line.trim().endsWith('?'));
  const startIndex = questionLineIndex >= 0 ? questionLineIndex + 1 : 0;
  
  // Step 1: Extract from bullet points and numbered lists
  // Only process lines AFTER the main question
  for (let i = startIndex; i < lines.length; i++) {
    const line = lines[i];
    // Match unordered bullet points (-, *, •)
    let match = line.match(/^\s*[-*•]\s+(.*\S.*)$/);
    if (match) {
      let option = match[1].trim();
      // Clean up question format "Are they general cat lovers?" -> "General cat lovers"
      option = option.replace(/^(?:are they|do they have?|what)\s+/i, '').replace(/\?$/, '');
      if (option.length > 0) {
        choices.push(option);
      }
    }
    
    // Match numbered lists (1., 2., etc.)
    if (!match) {
      match = line.match(/^\s*\d+[\.\)]\s+(.*\S.*)$/);
      if (match) {
        let option = match[1].trim();
        option = option.replace(/^(?:are they|do they have?|what)\s+/i, '').replace(/\?$/, '');
        if (option.length > 0) {
          choices.push(option);
        }
      }
    }
    
    // Match alphabetic lists (a., A), etc.)
    if (!match) {
      match = line.match(/^\s*[a-zA-Z][\.\)]\s+(.*\S.*)$/);
      if (match) {
        let option = match[1].trim();
        option = option.replace(/^(?:are they|do they have?|what)\s+/i, '').replace(/\?$/, '');
        if (option.length > 0) {
          choices.push(option);
        }
      }
    }
  }
  
  // Step 2: Extract from inline choices with "or" and commas
  if (choices.length === 0) {
    // Pattern: "like cute kittens, funny cat antics, or educational content"
    const inlinePattern = /(?:like|such as|including)\s+([^?]+?)(?:\?|$)/i;
    const inlineMatch = text.match(inlinePattern);
    if (inlineMatch) {
      const choicesText = inlineMatch[1];
      const parts = choicesText.split(/,\s*(?:or\s+)?|\s+or\s+/);
      for (const part of parts) {
        const cleaned = part.trim().replace(/[,.]$/, '');
        if (cleaned && cleaned.length > 2) {
          choices.push(cleaned);
        }
      }
    }
  }
  
  // Step 3: Extract from parenthetical examples (e.g., children, teens, adults)
  if (choices.length === 0) {
    const parentheticalPattern = /\(\s*e\.g\.,\s*([^)]+?)\)/i;
    const parentheticalMatch = text.match(parentheticalPattern);
    if (parentheticalMatch) {
      const exampleText = parentheticalMatch[1];
      const parts = exampleText.split(/,\s*/);
      for (const part of parts) {
        const cleaned = part.trim();
        if (cleaned && cleaned.length > 0) {
          choices.push(cleaned);
        }
      }
    }
  }
  
  // Step 4: Final attempt at simple enumeration patterns
  if (choices.length === 0) {
    const simplePattern = /(?:are you looking to|do you want to|choose from|options include)\s+([^?]+?)(?:\?|$)/i;
    const simpleMatch = text.match(simplePattern);
    if (simpleMatch) {
      const choicesText = simpleMatch[1];
      const parts = choicesText.split(/,\s*(?:or\s+)?|\s+or\s+/);
      for (const part of parts) {
        const cleaned = part.trim().replace(/^(to\s+)?/, '').replace(/[,.]$/, '');
        if (cleaned && cleaned.length > 0) {
          choices.push(cleaned);
        }
      }
    }
  }
  
  return choices.filter((c, i, arr) => arr.indexOf(c) === i); // dedupe
}

/**
 * Detect question intent and generate appropriate options
 */
function getContextualOptions(text: string): MCQOption[] {
  const lowerText = text.toLowerCase();
  
  // Video purpose questions
  if (lowerText.includes('purpose') || lowerText.includes('achieve') || 
      lowerText.includes('goal') || lowerText.includes('hope to')) {
    return [
      { label: 'A', text: 'Entertain', fullText: 'A. Entertain' },
      { label: 'B', text: 'Educate', fullText: 'B. Educate' },
      { label: 'C', text: 'Promote a product', fullText: 'C. Promote a product' },
      { label: 'D', text: 'Raise awareness', fullText: 'D. Raise awareness' },
      { label: 'E', text: 'Something else', fullText: 'E. Something else' }
    ];
  }
  
  // Yes/No questions
  if (lowerText.includes('do you') && (lowerText.includes('want') || lowerText.includes('need') || lowerText.includes('have'))) {
    return [
      { label: 'A', text: 'Yes', fullText: 'A. Yes' },
      { label: 'B', text: 'No', fullText: 'B. No' },
      { label: 'C', text: 'I\'m not sure', fullText: 'C. I\'m not sure' }
    ];
  }
  
  // Preference questions
  if (lowerText.includes('prefer') || lowerText.includes('like') || lowerText.includes('choose')) {
    return [
      { label: 'A', text: 'Option A', fullText: 'A. Option A' },
      { label: 'B', text: 'Option B', fullText: 'B. Option B' },
      { label: 'C', text: 'Neither', fullText: 'C. Neither' },
      { label: 'D', text: 'I need more information', fullText: 'D. I need more information' }
    ];
  }
  
  // Style/approach questions
  if (lowerText.includes('style') || lowerText.includes('approach') || lowerText.includes('tone')) {
    return [
      { label: 'A', text: 'Professional', fullText: 'A. Professional' },
      { label: 'B', text: 'Casual', fullText: 'B. Casual' },
      { label: 'C', text: 'Creative', fullText: 'C. Creative' },
      { label: 'D', text: 'Let\'s discuss options', fullText: 'D. Let\'s discuss options' }
    ];
  }
  
  // Audience questions
  if (lowerText.includes('audience') || lowerText.includes('target') || lowerText.includes('viewers')) {
    return [
      { label: 'A', text: 'General public', fullText: 'A. General public' },
      { label: 'B', text: 'Specific demographic', fullText: 'B. Specific demographic' },
      { label: 'C', text: 'Professionals', fullText: 'C. Professionals' },
      { label: 'D', text: 'I\'m not sure yet', fullText: 'D. I\'m not sure yet' }
    ];
  }
  
  return [];
}

/**
 * Decompose complex multi-part questions into sequential steps
 */
function decomposeMultiPartQuestion(text: string): QuestionStep[] {
  const steps: QuestionStep[] = [];
  const lowerText = text.toLowerCase();
  
  // Detect audience questions with multiple parts
  if (lowerText.includes('audience') && lowerText.includes('ideal')) {
    const lines = text.split('\n').filter(line => line.trim().startsWith('-'));
    
    if (lines.length >= 2) {
      // Step 1: General vs Specific audience
      const hasGeneralQuestion = lines.some(line => line.toLowerCase().includes('general'));
      const hasSpecificQuestion = lines.some(line => line.toLowerCase().includes('specific'));
      const hasAgeQuestion = lines.some(line => line.toLowerCase().includes('age') || line.toLowerCase().includes('children') || line.toLowerCase().includes('teen'));
      
      if (hasGeneralQuestion && hasSpecificQuestion) {
        // Create first question: audience type
        steps.push({
          id: 'audience_type',
          prompt: 'What type of audience are you targeting?',
          options: [
            { 
              label: 'A', 
              text: 'General cat lovers', 
              fullText: 'A. General cat lovers' 
            },
            { 
              label: 'B', 
              text: 'People with specific interests', 
              fullText: 'B. People with specific interests',
              followupQuestionId: 'specific_interests'
            }
          ]
        });
        
        // Create conditional follow-up for specific interests
        const interestOptions: MCQOption[] = [];
        const interestLine = lines.find(line => line.toLowerCase().includes('specific'));
        if (interestLine) {
          const interests = extractExplicitChoices(interestLine);
          if (interests.length > 0) {
            interests.forEach((interest, index) => {
              interestOptions.push({
                label: String.fromCharCode(65 + index),
                text: interest.charAt(0).toUpperCase() + interest.slice(1),
                fullText: `${String.fromCharCode(65 + index)}. ${interest.charAt(0).toUpperCase() + interest.slice(1)}`
              });
            });
          }
        }
        
        if (interestOptions.length > 0) {
          steps.push({
            id: 'specific_interests',
            prompt: 'Which specific interests?',
            options: interestOptions,
            isConditional: true,
            parentOptionId: 'B'
          });
        }
      }
      
      // Step 2: Age demographics (always ask)
      if (hasAgeQuestion) {
        const ageOptions: MCQOption[] = [];
        const ageLine = lines.find(line => line.toLowerCase().includes('age') || line.toLowerCase().includes('children'));
        if (ageLine) {
          const ageGroups = extractExplicitChoices(ageLine);
          if (ageGroups.length > 0) {
            ageGroups.forEach((group, index) => {
              ageOptions.push({
                label: String.fromCharCode(65 + index),
                text: group.charAt(0).toUpperCase() + group.slice(1),
                fullText: `${String.fromCharCode(65 + index)}. ${group.charAt(0).toUpperCase() + group.slice(1)}`
              });
            });
          } else {
            // Default age options
            ['Children', 'Teens', 'Adults', 'Families', 'Mixed audience'].forEach((group, index) => {
              ageOptions.push({
                label: String.fromCharCode(65 + index),
                text: group,
                fullText: `${String.fromCharCode(65 + index)}. ${group}`
              });
            });
          }
        }
        
        if (ageOptions.length > 0) {
          steps.push({
            id: 'age_group',
            prompt: 'What age group are you targeting?',
            options: ageOptions
          });
        }
      }
    }
  }
  
  return steps;
}

/**
 * Parse structured MCQ formats (JSON or plain-text block)
 */
function parseStructuredMCQ(messageText: string): MCQOption[] {
  // Check for JSON format: <begin>{...}<end>
  const jsonMatch = messageText.match(/<begin>\s*({[\s\S]*?})\s*<end>/i);
  if (jsonMatch) {
    try {
      const parsed = JSON.parse(jsonMatch[1]);
      if (parsed.options && Array.isArray(parsed.options)) {
        return parsed.options.map((opt: string, index: number) => ({
          label: String(index + 1),
          text: opt,
          fullText: `${index + 1}. ${opt}`
        }));
      }
    } catch (e) {
      console.error('Failed to parse JSON MCQ:', e);
    }
  }
  
  // Check for plain-text block format: QUESTION:...OPTIONS:...END_OPTIONS
  const blockMatch = messageText.match(/OPTIONS:\s*\n([\s\S]*?)END_OPTIONS/i);
  if (blockMatch) {
    const optionsText = blockMatch[1];
    const options: MCQOption[] = [];
    const lines = optionsText.split('\n').filter(line => line.trim());
    
    for (const line of lines) {
      const match = line.match(/^\s*(\d+)\s*=\s*['"]?(.+?)['"]?\s*$/);
      if (match) {
        options.push({
          label: match[1],
          text: match[2].trim(),
          fullText: `${match[1]}. ${match[2].trim()}`
        });
      }
    }
    
    if (options.length > 0) {
      return options;
    }
  }
  
  return [];
}

export function generateDefaultMCQOptions(messageText: string): MCQOption[] {
  const lowerText = messageText.toLowerCase();
  
  // FIRST: Try to parse structured formats (JSON or plain-text blocks)
  const structuredOptions = parseStructuredMCQ(messageText);
  if (structuredOptions.length > 0) {
    return structuredOptions;
  }
  
  // FALLBACK: Try to extract explicit numbered options (legacy format)
  const extractedOptions = extractMCQOptions(messageText);
  if (extractedOptions.length > 0) {
    return extractedOptions; // Options provided - ALWAYS use them
  }
  
  // ONLY check for open-ended keywords if NO options were provided
  const openEndedIndicators = [
    'what is the main reason',
    'what do you hope',
    'describe',
    'explain',
    'tell me about',
    'tell me more',
    'what are your thoughts',
    'how would you describe',
    'what made you',
    'what brings you',
    'share your',
    'elaborate on'
  ];
  
  // Only apply open-ended detection when no explicit options exist
  if (openEndedIndicators.some(indicator => lowerText.includes(indicator))) {
    return []; // No buttons for truly open-ended questions without options
  }
  
  // Check if this is a complex multi-part question that should be decomposed
  const questionSteps = decomposeMultiPartQuestion(messageText);
  if (questionSteps.length > 1) {
    // Return options for the first step only
    // The UI will need to handle the sequential flow
    const firstStep = questionSteps[0];
    return firstStep.options.map(option => ({
      ...option,
      // Add metadata to indicate this is part of a multi-step flow
      fullText: `${option.fullText} ${questionSteps.length > 1 ? '(1 of ' + questionSteps.length + ')' : ''}`
    }));
  }
  
  // Try to extract explicit choices from the question text
  const explicitChoices = extractExplicitChoices(messageText);
  if (explicitChoices.length >= 2) {
    return explicitChoices.map((choice, index) => ({
      label: String.fromCharCode(65 + index), // A, B, C, D...
      text: choice.charAt(0).toUpperCase() + choice.slice(1),
      fullText: `${String.fromCharCode(65 + index)}. ${choice.charAt(0).toUpperCase() + choice.slice(1)}`
    }));
  }
  
  // Generate contextual options based on question intent
  const contextualOptions = getContextualOptions(messageText);
  if (contextualOptions.length > 0) {
    return contextualOptions;
  }
  
  // No fallback options - if we can't determine appropriate options, show none
  return [];
}

/**
 * Export question decomposition for UI components that need to handle multi-step flows
 */
export function getQuestionSteps(messageText: string): QuestionStep[] {
  return decomposeMultiPartQuestion(messageText);
}
</file>

</files>
</file>

<file path=".marscode/deviceInfo.json">
{
  "deviceId": "5fd7f9701c30b68fef31897398af3c0f0cf69ce2d5eb23edb49c3d8a586901b9"
}
</file>

<file path="components/icons/AttachmentIcon.tsx">
import React from 'react';

export const AttachmentIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    viewBox="0 0 24 24"
    fill="currentColor"
    {...props}
  >
    <path
      fillRule="evenodd"
      d="M18.97 3.659a2.25 2.25 0 00-3.182 0l-10.5 10.5a.75.75 0 001.06 1.061l10.5-10.5a.75.75 0 011.06 0a.75.75 0 010 1.06l-8.25 8.25a2.25 2.25 0 01-3.182-3.182l5.25-5.25a.75.75 0 00-1.06-1.06l-5.25 5.25a3.75 3.75 0 105.3 5.3l8.25-8.25a2.25 2.25 0 000-3.182z"
      clipRule="evenodd"
    />
  </svg>
);
</file>

<file path="components/icons/FileIcons.tsx">
import React from 'react';

export const FileIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    viewBox="0 0 24 24"
    fill="currentColor"
    {...props}
  >
    <path
      fillRule="evenodd"
      d="M5.625 1.5c-1.036 0-1.875.84-1.875 1.875v17.25c0 1.035.84 1.875 1.875 1.875h12.75c1.035 0 1.875-.84 1.875-1.875V12.75A3.75 3.75 0 0016.5 9h-1.875a.375.375 0 01-.375-.375V6.75A3.75 3.75 0 009 3H5.625zM12.75 12.75a.75.75 0 00-1.5 0v2.25H9a.75.75 0 000 1.5h2.25v2.25a.75.75 0 001.5 0v-2.25H15a.75.75 0 000-1.5h-2.25V12.75z"
      clipRule="evenodd"
    />
    <path d="M14.25 6.75a2.25 2.25 0 00-2.25-2.25H5.625a.375.375 0 00-.375.375v17.25c0 .207.168.375.375.375h12.75a.375.375 0 00.375-.375V12.75a2.25 2.25 0 00-2.25-2.25h-1.875a1.875 1.875 0 01-1.875-1.875V6.75z" />
  </svg>
);


export const XCircleIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg 
    xmlns="http://www.w3.org/2000/svg" 
    viewBox="0 0 20 20" 
    fill="currentColor" 
    {...props}
  >
    <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8.28 7.22a.75.75 0 00-1.06 1.06L8.94 10l-1.72 1.72a.75.75 0 101.06 1.06L10 11.06l1.72 1.72a.75.75 0 101.06-1.06L11.06 10l1.72-1.72a.75.75 0 00-1.06-1.06L10 8.94 8.28 7.22z" clipRule="evenodd" />
  </svg>
);
</file>

<file path="components/icons/SendIcon.tsx">
import React from 'react';

export const SendIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    viewBox="0 0 24 24"
    fill="currentColor"
    {...props}
  >
    <path d="M3.478 2.405a.75.75 0 00-.926.94l2.432 7.905H13.5a.75.75 0 010 1.5H4.984l-2.432 7.905a.75.75 0 00.926.94 60.519 60.519 0 0018.445-8.986.75.75 0 000-1.218A60.517 60.517 0 003.478 2.405z" />
  </svg>
);
</file>

<file path="components/icons/SpeakerIcons.tsx">
import React from 'react';

export const SpeakerOnIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" {...props}>
    <path d="M13.5 4.06c0-1.336-1.616-2.005-2.56-1.06l-4.5 4.5H4.508c-1.141 0-2.318.664-2.66 1.905A9.76 9.76 0 001.5 12c0 .898.121 1.768.35 2.595.341 1.24 1.518 1.905 2.66 1.905H6.44l4.5 4.5c.944.945 2.56.276 2.56-1.06V4.06zM18.584 5.106a.75.75 0 011.06 0c3.808 3.807 3.808 9.98 0 13.788a.75.75 0 11-1.06-1.06 8.25 8.25 0 000-11.668.75.75 0 010-1.06z" />
    <path d="M15.932 7.757a.75.75 0 011.061 0 6 6 0 010 8.486.75.75 0 01-1.06-1.061 4.5 4.5 0 000-6.364.75.75 0 010-1.06z" />
  </svg>
);

export const SpeakerOffIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" {...props}>
    <path d="M13.5 4.06c0-1.336-1.616-2.005-2.56-1.06l-4.5 4.5H4.508c-1.141 0-2.318.664-2.66 1.905A9.76 9.76 0 001.5 12c0 .898.121 1.768.35 2.595.341 1.24 1.518 1.905 2.66 1.905H6.44l4.5 4.5c.944.945 2.56.276 2.56-1.06V4.06zM18.28 15.28a.75.75 0 00-1.06-1.06l-1.97-1.97-1.97 1.97a.75.75 0 101.06 1.06l1.97-1.97 1.97 1.97a.75.75 0 101.06-1.06l-1.97-1.97 1.97-1.97a.75.75 0 10-1.06-1.06l-1.97 1.97-1.97-1.97a.75.75 0 10-1.06 1.06l1.97 1.97-1.97 1.97a.75.75 0 001.06 1.06l1.97-1.97 1.97 1.97z" />
  </svg>
);
</file>

<file path="components/ChatHistory.tsx">
import React, { useRef, useEffect } from 'react';
import { UIMessage } from '../types';
import { ChatMessage } from './ChatMessage';

interface ChatHistoryProps {
  messages: UIMessage[];
}

export const ChatHistory: React.FC<ChatHistoryProps> = ({ messages }) => {
  const endOfMessagesRef = useRef<HTMLDivElement>(null);

  useEffect(() => {
    endOfMessagesRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  return (
    <div className="flex-1 overflow-y-auto p-4 md:p-6 space-y-6">
      {messages.map((message) => (
        <ChatMessage key={message.id} message={message} />
      ))}
      <div ref={endOfMessagesRef} />
    </div>
  );
};
</file>

<file path="components/ChatInput.tsx">
import React, { useState, useRef, useCallback } from 'react';
import { Attachment } from '../types';
import { SendIcon } from './icons/SendIcon';
import { AttachmentIcon } from './icons/AttachmentIcon';
import { XCircleIcon } from './icons/FileIcons';

interface ChatInputProps {
  onSendMessage: (text: string, attachments: Attachment[]) => void;
  isLoading: boolean;
}

const MAX_FILES = 5;
const MAX_FILE_SIZE_MB = 20;

const fileToBase64 = (file: File): Promise<string> =>
  new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.readAsDataURL(file);
    reader.onload = () => resolve((reader.result as string).split(',')[1]);
    reader.onerror = (error) => reject(error);
  });

export const ChatInput: React.FC<ChatInputProps> = ({ onSendMessage, isLoading }) => {
  const [text, setText] = useState('');
  const [attachments, setAttachments] = useState<Attachment[]>([]);
  const fileInputRef = useRef<HTMLInputElement>(null);

  const handleSendMessage = () => {
    if (isLoading || (!text.trim() && attachments.length === 0)) return;
    onSendMessage(text, attachments);
    setText('');
    setAttachments([]);
  };

  const handleKeyDown = (e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSendMessage();
    }
  };

  const handleFileChange = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const files = e.target.files;
    if (!files) return;

    if (attachments.length + files.length > MAX_FILES) {
        alert(`You can only upload a maximum of ${MAX_FILES} files.`);
        return;
    }

    const newAttachments: Attachment[] = [];
    for (const file of files) {
        if (file.size > MAX_FILE_SIZE_MB * 1024 * 1024) {
            alert(`File ${file.name} is too large. Maximum size is ${MAX_FILE_SIZE_MB}MB.`);
            continue;
        }
        try {
            const data = await fileToBase64(file);
            newAttachments.push({ name: file.name, type: file.type, size: file.size, data });
        } catch (error) {
            console.error("Error converting file to base64", error);
        }
    }
    setAttachments(prev => [...prev, ...newAttachments]);
  };

  const removeAttachment = (index: number) => {
    setAttachments(prev => prev.filter((_, i) => i !== index));
  };

  return (
    <div className="p-4 md:p-6 bg-gray-900 border-t border-gray-700 flex-shrink-0">
      <div className="bg-gray-800 rounded-2xl p-2 flex flex-col">
        {attachments.length > 0 && (
            <div className="p-2 grid grid-cols-2 md:grid-cols-3 lg:grid-cols-4 gap-2">
                {attachments.map((file, index) => (
                    <div key={index} className="bg-gray-700 p-2 rounded-lg flex items-center justify-between text-sm">
                        <span className="truncate" title={file.name}>{file.name}</span>
                        <button onClick={() => removeAttachment(index)} className="ml-2 text-gray-400 hover:text-white">
                            <XCircleIcon className="w-5 h-5" />
                        </button>
                    </div>
                ))}
            </div>
        )}
        <div className="flex items-end">
          <button
            onClick={() => fileInputRef.current?.click()}
            className="p-3 text-gray-400 hover:text-white transition-colors duration-200"
            aria-label="Attach files"
          >
            <AttachmentIcon className="w-6 h-6" />
          </button>
          <input
            type="file"
            multiple
            ref={fileInputRef}
            onChange={handleFileChange}
            className="hidden"
            accept="image/*,video/*,audio/*,.pdf,.doc,.docx,.txt"
          />
          <textarea
            value={text}
            onChange={(e) => setText(e.target.value)}
            onKeyDown={handleKeyDown}
            placeholder="Tell me about your video idea..."
            className="flex-1 bg-transparent p-3 resize-none outline-none placeholder-gray-500 max-h-40"
            rows={1}
            disabled={isLoading}
          />
          <button
            onClick={handleSendMessage}
            disabled={isLoading || (!text.trim() && attachments.length === 0)}
            className="p-3 rounded-full bg-indigo-500 text-white disabled:bg-gray-600 disabled:cursor-not-allowed hover:bg-indigo-600 transition-colors duration-200"
            aria-label="Send message"
          >
            {isLoading ? (
                <div className="w-6 h-6 border-2 border-white border-t-transparent rounded-full animate-spin"></div>
            ) : (
                <SendIcon className="w-6 h-6" />
            )}
          </button>
        </div>
      </div>
    </div>
  );
};
</file>

<file path="components/ChatMessage.tsx">
import React from 'react';
import { UIMessage } from '../types';
import { FileIcon } from './icons/FileIcons';

const LoadingIndicator: React.FC = () => (
  <div className="flex items-center space-x-1">
    <span className="w-2 h-2 bg-indigo-400 rounded-full animate-pulse [animation-delay:-0.3s]"></span>
    <span className="w-2 h-2 bg-indigo-400 rounded-full animate-pulse [animation-delay:-0.15s]"></span>
    <span className="w-2 h-2 bg-indigo-400 rounded-full animate-pulse"></span>
  </div>
);

export const ChatMessage: React.FC<{ message: UIMessage }> = ({ message }) => {
  const isUser = message.role === 'user';

  return (
    <div className={`flex items-start gap-4 ${isUser ? 'justify-end' : 'justify-start'}`}>
      {!isUser && (
        <div className="flex-shrink-0 w-10 h-10 bg-indigo-500 rounded-full flex items-center justify-center font-bold">
          K
        </div>
      )}
      <div className={`max-w-xl lg:max-w-2xl rounded-2xl p-4 ${isUser ? 'bg-blue-600 rounded-br-none' : 'bg-gray-800 rounded-bl-none'}`}>
        {message.text && <p className="whitespace-pre-wrap">{message.text}</p>}
        {message.isStreaming && !message.text && <LoadingIndicator />}
        
        {message.attachments && message.attachments.length > 0 && (
          <div className="mt-3 grid grid-cols-1 sm:grid-cols-2 gap-2">
            {message.attachments.map((att, index) => (
              <div key={index} className="bg-gray-700/50 p-2 rounded-lg flex items-center gap-2 text-sm">
                <FileIcon className="w-5 h-5 flex-shrink-0 text-gray-400" />
                <span className="truncate" title={att.name}>{att.name}</span>
              </div>
            ))}
          </div>
        )}
      </div>
       {isUser && (
        <div className="flex-shrink-0 w-10 h-10 bg-blue-600 rounded-full flex items-center justify-center font-bold">
          U
        </div>
      )}
    </div>
  );
};
</file>

<file path="hooks/useTextToSpeech.ts">
import { useState, useCallback, useEffect } from 'react';

export const useTextToSpeech = () => {
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isTtsEnabled, setIsTtsEnabled] = useState(true);

  const synth = window.speechSynthesis;

  const speak = useCallback((text: string) => {
    if (!synth || !isTtsEnabled) return;
    
    synth.cancel(); // Cancel any previous utterance
    const utterance = new SpeechSynthesisUtterance(text);
    
    utterance.onstart = () => setIsSpeaking(true);
    utterance.onend = () => setIsSpeaking(false);
    utterance.onerror = () => setIsSpeaking(false);
    
    synth.speak(utterance);
  }, [synth, isTtsEnabled]);

  const stop = useCallback(() => {
    if (synth) {
      synth.cancel();
      setIsSpeaking(false);
    }
  }, [synth]);
  
  useEffect(() => {
      return () => {
          if(synth) synth.cancel();
      }
  }, [synth]);

  return { isSpeaking, isTtsEnabled, setIsTtsEnabled, speak, stop };
};
</file>

<file path="services/geminiService.ts">
import { GoogleGenAI, Chat, GenerateContentResponse } from "@google/genai";
import { KIJKO_SYSTEM_PROMPT } from '../constants';
import { Attachment, MessagePart } from '../types';

if (!process.env.API_KEY) {
  throw new Error("API_KEY environment variable not set");
}

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

export function startKijkoChat(): Chat {
  const chat = ai.chats.create({
    model: 'gemini-2.5-flash',
    config: {
      systemInstruction: KIJKO_SYSTEM_PROMPT,
    },
  });
  return chat;
}

const fileToGenerativePart = (file: Attachment): MessagePart => {
  return {
    inlineData: {
      data: file.data,
      mimeType: file.type,
    },
  };
};

export async function sendMessageToKijkoStream(
  chat: Chat, 
  text: string, 
  attachments: Attachment[]
): Promise<AsyncGenerator<GenerateContentResponse>> {

  const parts: MessagePart[] = attachments.map(fileToGenerativePart);
  
  const youtubeRegex = /(?:https?:\/\/)?(?:www\.)?(?:youtube\.com|youtu\.be)\/(?:watch\?v=)?([\w-]{11})/;
  const ytMatch = text.match(youtubeRegex);

  let promptText = text;
  if (ytMatch) {
    promptText += `\n\n[User has provided a YouTube link for context: ${ytMatch[0]}. Please analyze the content of this video as part of your response.]`;
  }

  if (promptText.trim()) {
    parts.push({ text: promptText });
  }

  // The `sendMessageStream` method requires a `SendMessageParameters` object,
  // which has a `message` property. The `parts` array should be passed as the value for this property.
  const result = await chat.sendMessageStream({ message: parts });
  return result;
}
</file>

<file path="src/components/icons/AttachmentIcon.tsx">
import React from 'react';

export const AttachmentIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    viewBox="0 0 24 24"
    fill="currentColor"
    {...props}
  >
    <path
      fillRule="evenodd"
      d="M18.97 3.659a2.25 2.25 0 00-3.182 0l-10.5 10.5a.75.75 0 001.06 1.061l10.5-10.5a.75.75 0 011.06 0a.75.75 0 010 1.06l-8.25 8.25a2.25 2.25 0 01-3.182-3.182l5.25-5.25a.75.75 0 00-1.06-1.06l-5.25 5.25a3.75 3.75 0 105.3 5.3l8.25-8.25a2.25 2.25 0 000-3.182z"
      clipRule="evenodd"
    />
  </svg>
);
</file>

<file path="src/components/icons/FileIcons.tsx">
import React from 'react';

export const FileIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    viewBox="0 0 24 24"
    fill="currentColor"
    {...props}
  >
    <path
      fillRule="evenodd"
      d="M5.625 1.5c-1.036 0-1.875.84-1.875 1.875v17.25c0 1.035.84 1.875 1.875 1.875h12.75c1.035 0 1.875-.84 1.875-1.875V12.75A3.75 3.75 0 0016.5 9h-1.875a.375.375 0 01-.375-.375V6.75A3.75 3.75 0 009 3H5.625zM12.75 12.75a.75.75 0 00-1.5 0v2.25H9a.75.75 0 000 1.5h2.25v2.25a.75.75 0 001.5 0v-2.25H15a.75.75 0 000-1.5h-2.25V12.75z"
      clipRule="evenodd"
    />
    <path d="M14.25 6.75a2.25 2.25 0 00-2.25-2.25H5.625a.375.375 0 00-.375.375v17.25c0 .207.168.375.375.375h12.75a.375.375 0 00.375-.375V12.75a2.25 2.25 0 00-2.25-2.25h-1.875a1.875 1.875 0 01-1.875-1.875V6.75z" />
  </svg>
);


export const XCircleIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg 
    xmlns="http://www.w3.org/2000/svg" 
    viewBox="0 0 20 20" 
    fill="currentColor" 
    {...props}
  >
    <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8.28 7.22a.75.75 0 00-1.06 1.06L8.94 10l-1.72 1.72a.75.75 0 101.06 1.06L10 11.06l1.72 1.72a.75.75 0 101.06-1.06L11.06 10l1.72-1.72a.75.75 0 00-1.06-1.06L10 8.94 8.28 7.22z" clipRule="evenodd" />
  </svg>
);
</file>

<file path="src/components/icons/MicrophoneIcon.tsx">
import React from 'react';

export const MicrophoneIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg 
    xmlns="http://www.w3.org/2000/svg" 
    viewBox="0 0 24 24" 
    fill="currentColor" 
    {...props}
  >
    <path d="M12 18.75a6 6 0 006-6v-1.5a6 6 0 00-12 0v1.5a6 6 0 006 6zM12 2.25a.75.75 0 01.75.75v6a.75.75 0 01-1.5 0V3a.75.75 0 01.75-.75z" />
    <path d="M10.5 9.75a.75.75 0 00-1.5 0v1.5a3 3 0 006 0v-1.5a.75.75 0 00-1.5 0v1.5a1.5 1.5 0 01-3 0v-1.5z" />
    <path d="M3.52 9.22A.75.75 0 014.27 9l.415-.415a9.938 9.938 0 0114.63 0l.415.415a.75.75 0 01-.53 1.28l-.415-.415a8.438 8.438 0 00-12.57 0l-.415.415a.75.75 0 01-1.28-.53z" />
  </svg>
);
</file>

<file path="src/components/icons/SendIcon.tsx">
import React from 'react';

export const SendIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    viewBox="0 0 24 24"
    fill="currentColor"
    {...props}
  >
    <path d="M3.478 2.405a.75.75 0 00-.926.94l2.432 7.905H13.5a.75.75 0 010 1.5H4.984l-2.432 7.905a.75.75 0 00.926.94 60.519 60.519 0 0018.445-8.986.75.75 0 000-1.218A60.517 60.517 0 003.478 2.405z" />
  </svg>
);
</file>

<file path="src/components/icons/SpeakerIcons.tsx">
import React from 'react';

export const SpeakerOnIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" {...props}>
    <path d="M13.5 4.06c0-1.336-1.616-2.005-2.56-1.06l-4.5 4.5H4.508c-1.141 0-2.318.664-2.66 1.905A9.76 9.76 0 001.5 12c0 .898.121 1.768.35 2.595.341 1.24 1.518 1.905 2.66 1.905H6.44l4.5 4.5c.944.945 2.56.276 2.56-1.06V4.06zM18.584 5.106a.75.75 0 011.06 0c3.808 3.807 3.808 9.98 0 13.788a.75.75 0 11-1.06-1.06 8.25 8.25 0 000-11.668.75.75 0 010-1.06z" />
    <path d="M15.932 7.757a.75.75 0 011.061 0 6 6 0 010 8.486.75.75 0 01-1.06-1.061 4.5 4.5 0 000-6.364.75.75 0 010-1.06z" />
  </svg>
);

export const SpeakerOffIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" {...props}>
    <path d="M13.5 4.06c0-1.336-1.616-2.005-2.56-1.06l-4.5 4.5H4.508c-1.141 0-2.318.664-2.66 1.905A9.76 9.76 0 001.5 12c0 .898.121 1.768.35 2.595.341 1.24 1.518 1.905 2.66 1.905H6.44l4.5 4.5c.944.945 2.56.276 2.56-1.06V4.06zM18.28 15.28a.75.75 0 00-1.06-1.06l-1.97-1.97-1.97 1.97a.75.75 0 101.06 1.06l1.97-1.97 1.97 1.97a.75.75 0 101.06-1.06l-1.97-1.97 1.97-1.97a.75.75 0 10-1.06-1.06l-1.97 1.97-1.97-1.97a.75.75 0 10-1.06 1.06l1.97 1.97-1.97 1.97a.75.75 0 001.06 1.06l1.97-1.97 1.97 1.97z" />
  </svg>
);
</file>

<file path="src/components/AuthGate.tsx">
import React, { useEffect, useState, FormEvent } from 'react';
import { supabaseService } from '../services/supabaseService';

interface AuthGateProps {
  children: React.ReactNode;
}

export const AuthGate: React.FC<AuthGateProps> = ({ children }) => {
  const [loading, setLoading] = useState(true);
  const [user, setUser] = useState<any>(null);
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');
  const [error, setError] = useState<string | null>(null);

  useEffect(() => {
    if (!supabaseService.isAvailable()) {
      setLoading(false);
      return;
    }

    const client = supabaseService.getClient();

    const init = async () => {
      const { data: { session } } = await client.auth.getSession();
      setUser(session?.user || null);
      setLoading(false);
    };

    const { data: sub } = client.auth.onAuthStateChange((_event: any, session: any) => {
      setUser(session?.user || null);
    });

    init();

    return () => {
      sub?.subscription?.unsubscribe?.();
    };
  }, []);

  const handleGoogle = async () => {
    setError(null);
    try {
      const client = supabaseService.getClient();
      await client.auth.signInWithOAuth({
        provider: 'google',
        options: { redirectTo: window.location.origin }
      });
    } catch (e: any) {
      setError(e?.message || 'Google sign-in failed');
    }
  };

  const handleEmailPassword = async (e: FormEvent) => {
    e.preventDefault();
    setError(null);
    try {
      const client = supabaseService.getClient();
      const { data, error } = await client.auth.signInWithPassword({ email, password });
      if (error) {
        // If user not found, offer sign-up
        const signUp = confirm('Account not found or invalid credentials. Do you want to create an account?');
        if (signUp) {
          const { error: signUpError } = await client.auth.signUp({ email, password });
          if (signUpError) throw signUpError;
        } else {
          throw error;
        }
      }
    } catch (e: any) {
      setError(e?.message || 'Email/password sign-in failed');
    }
  };

  if (loading) {
    return (
      <div className="flex-1 flex items-center justify-center">
        <p className="text-gray-400">Checking authentication…</p>
      </div>
    );
  }

  if (!user) {
    return (
      <div className="flex-1 flex items-center justify-center p-6">
        <div className="w-full max-w-md bg-gray-900/80 border border-gray-700/50 rounded-xl p-6 space-y-4">
          <h2 className="text-xl font-semibold text-white">Sign in to continue</h2>

          {error && <div className="text-red-400 text-sm">{error}</div>}

          <button
            onClick={handleGoogle}
            className="w-full py-2 rounded-lg bg-white text-gray-900 font-medium hover:bg-gray-100 transition"
          >
            Continue with Google
          </button>

          <div className="text-center text-gray-500 text-sm">or</div>

          <form onSubmit={handleEmailPassword} className="space-y-3">
            <input
              type="email"
              placeholder="you@example.com"
              value={email}
              onChange={(e) => setEmail(e.target.value)}
              className="w-full px-3 py-2 rounded-lg bg-gray-800 text-white border border-gray-700 focus:outline-none"
              required
            />
            <input
              type="password"
              placeholder="Password"
              value={password}
              onChange={(e) => setPassword(e.target.value)}
              className="w-full px-3 py-2 rounded-lg bg-gray-800 text-white border border-gray-700 focus:outline-none"
              required
            />
            <button
              type="submit"
              className="w-full py-2 rounded-lg bg-gradient-to-r from-purple-600 to-blue-600 text-white font-medium hover:from-purple-700 hover:to-blue-700 transition"
            >
              Sign in / Sign up
            </button>
          </form>
        </div>
      </div>
    );
  }

  return <>{children}</>;
};
</file>

<file path="src/components/ChatHistory.tsx">
import React, { useRef, useEffect } from 'react';
import { UIMessage } from '../types';
import { ChatMessage } from './ChatMessage';

interface ChatHistoryProps {
  messages: UIMessage[];
}

export const ChatHistory: React.FC<ChatHistoryProps> = ({ messages }) => {
  const endOfMessagesRef = useRef<HTMLDivElement>(null);

  useEffect(() => {
    endOfMessagesRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  return (
    <div className="flex-1 overflow-y-auto p-4 md:p-6 space-y-6">
      {messages.map((message) => (
        <ChatMessage key={message.id} message={message} />
      ))}
      <div ref={endOfMessagesRef} />
    </div>
  );
};
</file>

<file path="src/components/ChatMessage.tsx">
import React from 'react';
import { UIMessage } from '../types';
import { FileIcon } from './icons/FileIcons';

const LoadingIndicator: React.FC = () => (
  <div className="flex items-center space-x-1">
    <span className="w-2 h-2 bg-indigo-400 rounded-full animate-pulse [animation-delay:-0.3s]"></span>
    <span className="w-2 h-2 bg-indigo-400 rounded-full animate-pulse [animation-delay:-0.15s]"></span>
    <span className="w-2 h-2 bg-indigo-400 rounded-full animate-pulse"></span>
  </div>
);

export const ChatMessage: React.FC<{ message: UIMessage }> = ({ message }) => {
  const isUser = message.role === 'user';

  return (
    <div className={`flex items-start gap-4 ${isUser ? 'justify-end' : 'justify-start'}`}>
      {!isUser && (
        <div className="flex-shrink-0 w-10 h-10 bg-indigo-500 rounded-full flex items-center justify-center font-bold">
          K
        </div>
      )}
      <div className={`max-w-xl lg:max-w-2xl rounded-2xl p-4 ${isUser ? 'bg-blue-600 rounded-br-none' : 'bg-gray-800 rounded-bl-none'}`}>
        {message.text && <p className="whitespace-pre-wrap">{message.text}</p>}
        {message.isStreaming && !message.text && <LoadingIndicator />}
        
        {message.attachments && message.attachments.length > 0 && (
          <div className="mt-3 grid grid-cols-1 sm:grid-cols-2 gap-2">
            {message.attachments.map((att, index) => (
              <div key={index} className="bg-gray-700/50 p-2 rounded-lg flex items-center gap-2 text-sm">
                <FileIcon className="w-5 h-5 flex-shrink-0 text-gray-400" />
                <span className="truncate" title={att.name}>{att.name}</span>
              </div>
            ))}
          </div>
        )}
      </div>
       {isUser && (
        <div className="flex-shrink-0 w-10 h-10 bg-blue-600 rounded-full flex items-center justify-center font-bold">
          U
        </div>
      )}
    </div>
  );
};
</file>

<file path="src/components/DocumentExporter.tsx">
import React, { useState, useRef } from 'react';
import jsPDF from 'jspdf';
import html2canvas from 'html2canvas';
import { Download, FileText, FilePlus } from 'lucide-react';
import { Message } from '../types';
import { vrdFormatter } from '../utils/vrdFormatter';
import { documentStorage } from '../utils/documentStorage';

interface DocumentExporterProps {
  messages: Message[];
  title?: string;
  onExportComplete?: (documentId: string) => void;
  className?: string;
}

export const DocumentExporter: React.FC<DocumentExporterProps> = ({
  messages,
  title = 'Video Requirements Document',
  onExportComplete,
  className = ''
}) => {
  const [isExporting, setIsExporting] = useState(false);
  const [showMenu, setShowMenu] = useState(false);
  const exportRef = useRef<HTMLDivElement>(null);

  /**
   * Export as PDF
   */
  const exportAsPDF = async () => {
    setIsExporting(true);
    try {
      // Format the VRD
      const vrd = vrdFormatter.formatVRD(messages, title);
      
      // Create PDF document
      const pdf = new jsPDF('p', 'mm', 'a4');
      
      // Add title
      pdf.setFontSize(20);
      pdf.text(vrd.title, 20, 20);
      
      // Add date
      pdf.setFontSize(10);
      pdf.setTextColor(100);
      pdf.text(`Generated on ${vrd.createdAt.toLocaleDateString()}`, 20, 30);
      
      // Reset text color
      pdf.setTextColor(0);
      let yPosition = 45;
      
      // Add Project Overview
      if (vrd.content.projectOverview) {
        pdf.setFontSize(14);
        pdf.text('Project Overview', 20, yPosition);
        yPosition += 10;
        
        pdf.setFontSize(10);
        const lines = pdf.splitTextToSize(vrd.content.projectOverview, 170);
        pdf.text(lines, 20, yPosition);
        yPosition += lines.length * 5 + 10;
      }
      
      // Add Requirements
      if (vrd.content.requirements.length > 0) {
        if (yPosition > 250) {
          pdf.addPage();
          yPosition = 20;
        }
        
        pdf.setFontSize(14);
        pdf.text('Requirements', 20, yPosition);
        yPosition += 10;
        
        pdf.setFontSize(10);
        vrd.content.requirements.forEach((req, index) => {
          if (yPosition > 270) {
            pdf.addPage();
            yPosition = 20;
          }
          const bullet = `${index + 1}. ${req}`;
          const lines = pdf.splitTextToSize(bullet, 170);
          pdf.text(lines, 20, yPosition);
          yPosition += lines.length * 5 + 3;
        });
        yPosition += 7;
      }
      
      // Add Technical Specs
      if (vrd.content.technicalSpecs) {
        if (yPosition > 250) {
          pdf.addPage();
          yPosition = 20;
        }
        
        pdf.setFontSize(14);
        pdf.text('Technical Specifications', 20, yPosition);
        yPosition += 10;
        
        pdf.setFontSize(10);
        const lines = pdf.splitTextToSize(vrd.content.technicalSpecs, 170);
        pdf.text(lines, 20, yPosition);
        yPosition += lines.length * 5 + 10;
      }
      
      // Add Timeline
      if (vrd.content.timeline) {
        if (yPosition > 250) {
          pdf.addPage();
          yPosition = 20;
        }
        
        pdf.setFontSize(14);
        pdf.text('Timeline', 20, yPosition);
        yPosition += 10;
        
        pdf.setFontSize(10);
        const lines = pdf.splitTextToSize(vrd.content.timeline, 170);
        pdf.text(lines, 20, yPosition);
        yPosition += lines.length * 5 + 10;
      }
      
      // Add Budget
      if (vrd.content.budget) {
        if (yPosition > 250) {
          pdf.addPage();
          yPosition = 20;
        }
        
        pdf.setFontSize(14);
        pdf.text('Budget', 20, yPosition);
        yPosition += 10;
        
        pdf.setFontSize(10);
        const lines = pdf.splitTextToSize(vrd.content.budget, 170);
        pdf.text(lines, 20, yPosition);
      }
      
      // Convert PDF to blob
      const pdfBlob = pdf.output('blob');
      
      // Save document with PDF blob
      vrd.type = 'pdf';
      vrd.blob = pdfBlob;
      await documentStorage.saveDocument(vrd);
      
      // Download the PDF
      const url = URL.createObjectURL(pdfBlob);
      const a = document.createElement('a');
      a.href = url;
      a.download = `${vrd.title.replace(/[^a-z0-9]/gi, '_')}.pdf`;
      a.click();
      URL.revokeObjectURL(url);
      
      if (onExportComplete) {
        onExportComplete(vrd.id);
      }
      
      setShowMenu(false);
    } catch (error) {
      console.error('Error exporting PDF:', error);
      alert('Failed to export PDF. Please try again.');
    } finally {
      setIsExporting(false);
    }
  };

  /**
   * Export as Markdown
   */
  const exportAsMarkdown = async () => {
    setIsExporting(true);
    try {
      // Format the VRD
      const vrd = vrdFormatter.formatVRD(messages, title);
      
      // Convert to markdown
      const markdown = vrdFormatter.toMarkdown(vrd);
      
      // Create blob and download
      const blob = new Blob([markdown], { type: 'text/markdown' });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = `${vrd.title.replace(/[^a-z0-9]/gi, '_')}.md`;
      a.click();
      URL.revokeObjectURL(url);
      
      // Save document
      vrd.type = 'markdown';
      await documentStorage.saveDocument(vrd);
      
      if (onExportComplete) {
        onExportComplete(vrd.id);
      }
      
      setShowMenu(false);
    } catch (error) {
      console.error('Error exporting Markdown:', error);
      alert('Failed to export Markdown. Please try again.');
    } finally {
      setIsExporting(false);
    }
  };

  /**
   * Save to documents (without download)
   */
  const saveToDocuments = async () => {
    setIsExporting(true);
    try {
      // Format and save the VRD
      const vrd = vrdFormatter.formatVRD(messages, title);
      await documentStorage.saveDocument(vrd);
      
      if (onExportComplete) {
        onExportComplete(vrd.id);
      }
      
      alert('Document saved successfully!');
      setShowMenu(false);
    } catch (error) {
      console.error('Error saving document:', error);
      alert('Failed to save document. Please try again.');
    } finally {
      setIsExporting(false);
    }
  };

  return (
    <div className={`document-exporter relative ${className}`}>
      {/* Export Button */}
      <button
        onClick={() => setShowMenu(!showMenu)}
        disabled={isExporting || messages.length === 0}
        className="flex items-center gap-2 px-4 py-2 bg-gradient-to-r from-purple-500 to-indigo-600 
                   text-white rounded-lg hover:from-purple-600 hover:to-indigo-700 
                   transition-all duration-200 shadow-lg disabled:opacity-50 disabled:cursor-not-allowed"
      >
        <Download className="w-5 h-5" />
        <span>Export VRD</span>
      </button>

      {/* Export Menu */}
      {showMenu && (
        <div className="absolute top-full mt-2 right-0 bg-white dark:bg-gray-800 rounded-lg 
                        shadow-xl border border-gray-200 dark:border-gray-700 z-50 min-w-[200px]">
          <div className="p-2">
            <button
              onClick={exportAsPDF}
              disabled={isExporting}
              className="w-full flex items-center gap-3 px-3 py-2 text-left rounded-md
                         hover:bg-gray-100 dark:hover:bg-gray-700 transition-colors"
            >
              <FileText className="w-4 h-4 text-red-500" />
              <span className="text-gray-700 dark:text-gray-300">Export as PDF</span>
            </button>
            
            <button
              onClick={exportAsMarkdown}
              disabled={isExporting}
              className="w-full flex items-center gap-3 px-3 py-2 text-left rounded-md
                         hover:bg-gray-100 dark:hover:bg-gray-700 transition-colors"
            >
              <FileText className="w-4 h-4 text-blue-500" />
              <span className="text-gray-700 dark:text-gray-300">Export as Markdown</span>
            </button>
            
            <div className="border-t border-gray-200 dark:border-gray-700 my-2"></div>
            
            <button
              onClick={saveToDocuments}
              disabled={isExporting}
              className="w-full flex items-center gap-3 px-3 py-2 text-left rounded-md
                         hover:bg-gray-100 dark:hover:bg-gray-700 transition-colors"
            >
              <FilePlus className="w-4 h-4 text-green-500" />
              <span className="text-gray-700 dark:text-gray-300">Save to Documents</span>
            </button>
          </div>
        </div>
      )}

      {/* Loading Overlay */}
      {isExporting && (
        <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
          <div className="bg-white dark:bg-gray-800 rounded-lg p-6 shadow-xl">
            <div className="flex items-center gap-3">
              <div className="w-6 h-6 border-3 border-blue-500 border-t-transparent rounded-full animate-spin"></div>
              <span className="text-gray-700 dark:text-gray-300">Exporting document...</span>
            </div>
          </div>
        </div>
      )}
    </div>
  );
};
</file>

<file path="src/components/DocumentsSidebar.tsx">
import React, { useState, useEffect } from 'react';
import { FileText, Search, Trash2, Download, Eye, X } from 'lucide-react';
import { documentStorage, StoredDocument } from '../utils/documentStorage';
import { VRDDocument } from '../utils/vrdFormatter';

interface DocumentsSidebarProps {
  onClose?: () => void;
  onDocumentSelect?: (doc: VRDDocument) => void;
}

export const DocumentsSidebar: React.FC<DocumentsSidebarProps> = ({
  onClose,
  onDocumentSelect
}) => {
  const [documents, setDocuments] = useState<StoredDocument[]>([]);
  const [searchQuery, setSearchQuery] = useState('');
  const [loading, setLoading] = useState(true);
  const [selectedDoc, setSelectedDoc] = useState<VRDDocument | null>(null);
  const [showPreview, setShowPreview] = useState(false);

  // Load documents on mount
  useEffect(() => {
    loadDocuments();
  }, []);

  const loadDocuments = async () => {
    setLoading(true);
    try {
      const docs = await documentStorage.getRecentDocuments(50);
      setDocuments(docs);
    } catch (error) {
      console.error('Error loading documents:', error);
    } finally {
      setLoading(false);
    }
  };

  // Search documents
  const filteredDocuments = documents.filter(doc => 
    doc.title.toLowerCase().includes(searchQuery.toLowerCase()) ||
    (doc.preview && doc.preview.toLowerCase().includes(searchQuery.toLowerCase()))
  );

  // Handle document preview
  const handlePreview = async (docId: string) => {
    try {
      const doc = await documentStorage.getDocument(docId);
      if (doc) {
        setSelectedDoc(doc);
        setShowPreview(true);
        if (onDocumentSelect) {
          onDocumentSelect(doc);
        }
      }
    } catch (error) {
      console.error('Error loading document:', error);
    }
  };

  // Handle document download
  const handleDownload = async (doc: StoredDocument) => {
    try {
      const blob = await documentStorage.exportDocument(doc.id, doc.type);
      if (blob) {
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = `${doc.title.replace(/[^a-z0-9]/gi, '_')}.${doc.type === 'pdf' ? 'pdf' : 'md'}`;
        a.click();
        URL.revokeObjectURL(url);
      }
    } catch (error) {
      console.error('Error downloading document:', error);
    }
  };

  // Handle document deletion
  const handleDelete = async (docId: string) => {
    if (confirm('Are you sure you want to delete this document?')) {
      try {
        await documentStorage.deleteDocument(docId);
        await loadDocuments(); // Reload the list
      } catch (error) {
        console.error('Error deleting document:', error);
      }
    }
  };

  const formatDate = (date: Date) => {
    return new Date(date).toLocaleDateString('en-US', {
      month: 'short',
      day: 'numeric',
      year: 'numeric',
      hour: '2-digit',
      minute: '2-digit'
    });
  };

  const formatFileSize = (bytes?: number) => {
    if (!bytes) return 'N/A';
    if (bytes < 1024) return bytes + ' B';
    if (bytes < 1048576) return (bytes / 1024).toFixed(1) + ' KB';
    return (bytes / 1048576).toFixed(1) + ' MB';
  };

  return (
    <>
      {/* Documents List Section */}
      <div className="documents-sidebar h-full flex flex-col">
        {/* Header */}
        <div className="flex items-center justify-between p-4 border-b border-white/10">
          <h2 className="text-lg font-semibold text-white flex items-center gap-2">
            <FileText className="w-5 h-5" />
            Saved Documents
          </h2>
          {onClose && (
            <button
              onClick={onClose}
              className="text-gray-400 hover:text-white transition-colors"
              aria-label="Close documents"
            >
              <X className="w-5 h-5" />
            </button>
          )}
        </div>

        {/* Search Bar */}
        <div className="p-4">
          <div className="relative">
            <Search className="absolute left-3 top-1/2 transform -translate-y-1/2 w-4 h-4 text-gray-400" />
            <input
              type="text"
              placeholder="Search documents..."
              value={searchQuery}
              onChange={(e) => setSearchQuery(e.target.value)}
              className="w-full pl-10 pr-4 py-2 bg-white/5 border border-white/10 rounded-lg 
                       text-white placeholder-gray-400 focus:outline-none focus:border-purple-500"
            />
          </div>
        </div>

        {/* Documents List */}
        <div className="flex-1 overflow-y-auto px-4">
          {loading ? (
            <div className="flex items-center justify-center py-8">
              <div className="w-8 h-8 border-2 border-purple-500 border-t-transparent rounded-full animate-spin"></div>
            </div>
          ) : filteredDocuments.length === 0 ? (
            <div className="text-center py-8 text-gray-400">
              {searchQuery ? 'No documents found' : 'No saved documents yet'}
            </div>
          ) : (
            <div className="space-y-2 pb-4">
              {filteredDocuments.map((doc) => (
                <div
                  key={doc.id}
                  className="group bg-white/5 hover:bg-white/10 rounded-lg p-3 transition-all duration-200
                           border border-transparent hover:border-purple-500/30 cursor-pointer"
                  onClick={() => handlePreview(doc.id)}
                >
                  {/* Document Info */}
                  <div className="flex items-start justify-between mb-2">
                    <div className="flex-1 min-w-0">
                      <h3 className="font-medium text-white truncate group-hover:text-purple-400 transition-colors">
                        {doc.title}
                      </h3>
                      <div className="flex items-center gap-3 mt-1 text-xs text-gray-400">
                        <span>{formatDate(doc.createdAt)}</span>
                        <span>•</span>
                        <span>{doc.type.toUpperCase()}</span>
                        <span>•</span>
                        <span>{formatFileSize(doc.size)}</span>
                      </div>
                    </div>
                    <div className="flex items-center gap-1 opacity-0 group-hover:opacity-100 transition-opacity">
                      <button
                        onClick={(e) => {
                          e.stopPropagation();
                          handlePreview(doc.id);
                        }}
                        className="p-1.5 hover:bg-white/10 rounded transition-colors"
                        aria-label="Preview document"
                      >
                        <Eye className="w-4 h-4 text-gray-400 hover:text-white" />
                      </button>
                      <button
                        onClick={(e) => {
                          e.stopPropagation();
                          handleDownload(doc);
                        }}
                        className="p-1.5 hover:bg-white/10 rounded transition-colors"
                        aria-label="Download document"
                      >
                        <Download className="w-4 h-4 text-gray-400 hover:text-white" />
                      </button>
                      <button
                        onClick={(e) => {
                          e.stopPropagation();
                          handleDelete(doc.id);
                        }}
                        className="p-1.5 hover:bg-white/10 rounded transition-colors"
                        aria-label="Delete document"
                      >
                        <Trash2 className="w-4 h-4 text-gray-400 hover:text-red-400" />
                      </button>
                    </div>
                  </div>

                  {/* Preview Text */}
                  {doc.preview && (
                    <p className="text-xs text-gray-400 line-clamp-2">
                      {doc.preview}
                    </p>
                  )}
                </div>
              ))}
            </div>
          )}
        </div>

        {/* Storage Stats */}
        <div className="p-4 border-t border-white/10">
          <div className="text-xs text-gray-400">
            {documents.length} document{documents.length !== 1 ? 's' : ''} saved
          </div>
        </div>
      </div>

      {/* Preview Modal */}
      {showPreview && selectedDoc && (
        <div 
          className="fixed inset-0 bg-black/50 flex items-center justify-center z-50 p-4"
          onClick={() => setShowPreview(false)}
        >
          <div 
            className="bg-gray-900 rounded-xl shadow-2xl max-w-4xl w-full max-h-[90vh] flex flex-col"
            onClick={(e) => e.stopPropagation()}
          >
            {/* Modal Header */}
            <div className="flex items-center justify-between p-6 border-b border-white/10">
              <h2 className="text-xl font-semibold text-white">{selectedDoc.title}</h2>
              <button
                onClick={() => setShowPreview(false)}
                className="text-gray-400 hover:text-white transition-colors"
              >
                <X className="w-6 h-6" />
              </button>
            </div>

            {/* Modal Content */}
            <div className="flex-1 overflow-y-auto p-6">
              <div className="prose prose-invert max-w-none">
                {/* Project Overview */}
                {selectedDoc.content.projectOverview && (
                  <div className="mb-6">
                    <h3 className="text-lg font-semibold text-purple-400 mb-2">Project Overview</h3>
                    <p className="text-gray-300">{selectedDoc.content.projectOverview}</p>
                  </div>
                )}

                {/* Requirements */}
                {selectedDoc.content.requirements.length > 0 && (
                  <div className="mb-6">
                    <h3 className="text-lg font-semibold text-purple-400 mb-2">Requirements</h3>
                    <ul className="list-disc pl-5 space-y-1">
                      {selectedDoc.content.requirements.map((req, index) => (
                        <li key={index} className="text-gray-300">{req}</li>
                      ))}
                    </ul>
                  </div>
                )}

                {/* Technical Specs */}
                {selectedDoc.content.technicalSpecs && (
                  <div className="mb-6">
                    <h3 className="text-lg font-semibold text-purple-400 mb-2">Technical Specifications</h3>
                    <p className="text-gray-300">{selectedDoc.content.technicalSpecs}</p>
                  </div>
                )}

                {/* Timeline */}
                {selectedDoc.content.timeline && (
                  <div className="mb-6">
                    <h3 className="text-lg font-semibold text-purple-400 mb-2">Timeline</h3>
                    <p className="text-gray-300">{selectedDoc.content.timeline}</p>
                  </div>
                )}

                {/* Budget */}
                {selectedDoc.content.budget && (
                  <div className="mb-6">
                    <h3 className="text-lg font-semibold text-purple-400 mb-2">Budget</h3>
                    <p className="text-gray-300">{selectedDoc.content.budget}</p>
                  </div>
                )}
              </div>
            </div>

            {/* Modal Footer */}
            <div className="flex items-center justify-end gap-3 p-6 border-t border-white/10">
              <button
                onClick={() => handleDownload({
                  id: selectedDoc.id,
                  title: selectedDoc.title,
                  createdAt: selectedDoc.createdAt,
                  updatedAt: selectedDoc.updatedAt,
                  type: selectedDoc.type
                })}
                className="px-4 py-2 bg-purple-500 hover:bg-purple-600 text-white rounded-lg 
                         transition-colors flex items-center gap-2"
              >
                <Download className="w-4 h-4" />
                Download
              </button>
              <button
                onClick={() => setShowPreview(false)}
                className="px-4 py-2 bg-gray-700 hover:bg-gray-600 text-white rounded-lg transition-colors"
              >
                Close
              </button>
            </div>
          </div>
        </div>
      )}
    </>
  );
};
</file>

<file path="src/components/MCQTestDemo.tsx">
import React, { useState } from 'react';
import OptionGroup from './OptionGroup';
import { MCQOption } from '../utils/messageClassifier';

const MCQTestDemo: React.FC = () => {
  const [selectedResults, setSelectedResults] = useState<string[]>([]);

  // Example 1: Single select question
  const singleSelectOptions: MCQOption[] = [
    { label: 'A', text: 'A professional and formal approach', fullText: 'A professional and formal approach' },
    { label: 'B', text: 'A **casual and friendly** style', fullText: 'A casual and friendly style' },
    { label: 'C', text: 'A *mysterious* and intriguing tone', fullText: 'A mysterious and intriguing tone' },
    { label: 'D', text: 'An **energetic** and *enthusiastic* vibe', fullText: 'An energetic and enthusiastic vibe' }
  ];

  // Example 2: Multi-select question (automatically detected based on content)
  const multiSelectOptions: MCQOption[] = [
    { label: 'A', text: '**Energetic** and upbeat', fullText: 'Energetic and upbeat' },
    { label: 'B', text: '*Mysterious* and suspenseful', fullText: 'Mysterious and suspenseful' },
    { label: 'C', text: 'Professional **style**', fullText: 'Professional style' },
    { label: 'D', text: 'Warm and friendly **tone**', fullText: 'Warm and friendly tone' },
    { label: 'E', text: 'Dramatic and *cinematic*', fullText: 'Dramatic and cinematic' }
  ];

  // Example 3: Explicit multi-select
  const explicitMultiSelect: MCQOption[] = [
    { label: 'A', text: 'Include **background music**', fullText: 'Include background music' },
    { label: 'B', text: 'Add *voice narration*', fullText: 'Add voice narration' },
    { label: 'C', text: 'Use **text overlays**', fullText: 'Use text overlays' },
    { label: 'D', text: 'Include *sound effects*', fullText: 'Include sound effects' }
  ];

  const handleSingleSelect = (option: MCQOption) => {
    setSelectedResults(prev => [...prev, `Single Select: ${option.text}`]);
  };

  const handleMultiSelect = (options: MCQOption[]) => {
    const result = `Multi Select: ${options.map(opt => opt.text).join(', ')}`;
    setSelectedResults(prev => [...prev, result]);
  };

  const handleExplicitMultiSelect = (options: MCQOption[]) => {
    const result = `Explicit Multi Select: ${options.map(opt => opt.text).join(', ')}`;
    setSelectedResults(prev => [...prev, result]);
  };

  const clearResults = () => setSelectedResults([]);

  return (
    <div className="p-6 bg-gray-900 min-h-screen text-white">
      <div className="max-w-3xl mx-auto space-y-8">
        <header className="text-center">
          <h1 className="text-3xl font-bold mb-2">Enhanced MCQ Test Demo</h1>
          <p className="text-gray-400">
            Testing single-select, auto-detected multi-select, and explicit multi-select options
          </p>
        </header>

        {/* Example 1: Single Select */}
        <section className="bg-gray-800 rounded-lg p-6">
          <h2 className="text-xl font-semibold mb-4">1. Single Select Question</h2>
          <p className="text-gray-300 mb-4">
            What tone would you prefer for your video? (Auto-detects as single select)
          </p>
          <OptionGroup
            options={singleSelectOptions}
            onSelect={handleSingleSelect}
          />
        </section>

        {/* Example 2: Auto Multi-Select */}
        <section className="bg-gray-800 rounded-lg p-6">
          <h2 className="text-xl font-semibold mb-4">2. Auto-Detected Multi-Select</h2>
          <p className="text-gray-300 mb-4">
            Which styles and tones appeal to you? (Auto-detects as multi-select based on keywords)
          </p>
          <OptionGroup
            options={multiSelectOptions}
            onSelect={handleSingleSelect}
            onSubmit={handleMultiSelect}
          />
        </section>

        {/* Example 3: Explicit Multi-Select */}
        <section className="bg-gray-800 rounded-lg p-6">
          <h2 className="text-xl font-semibold mb-4">3. Explicit Multi-Select</h2>
          <p className="text-gray-300 mb-4">
            What elements would you like to include? (Explicitly set as multi-select)
          </p>
          <OptionGroup
            options={explicitMultiSelect}
            onSelect={handleSingleSelect}
            onSubmit={handleExplicitMultiSelect}
            allowMultiple={true}
          />
        </section>

        {/* Results Display */}
        <section className="bg-gray-800 rounded-lg p-6">
          <div className="flex justify-between items-center mb-4">
            <h2 className="text-xl font-semibold">Selection Results</h2>
            <button
              onClick={clearResults}
              className="px-4 py-2 bg-red-600 hover:bg-red-700 rounded-lg text-sm transition-colors"
            >
              Clear Results
            </button>
          </div>
          
          {selectedResults.length === 0 ? (
            <p className="text-gray-400 italic">No selections made yet...</p>
          ) : (
            <div className="space-y-2">
              {selectedResults.map((result, index) => (
                <div
                  key={index}
                  className="bg-gray-700 rounded p-3 border-l-4 border-blue-500"
                >
                  <span className="text-sm text-gray-300">
                    Selection #{index + 1}:
                  </span>
                  <p className="text-white mt-1">{result}</p>
                </div>
              ))}
            </div>
          )}
        </section>

        {/* Features Summary */}
        <section className="bg-gradient-to-r from-blue-900/30 to-purple-900/30 rounded-lg p-6 border border-blue-500/20">
          <h2 className="text-xl font-semibold mb-4">✨ Enhanced Features</h2>
          <div className="grid md:grid-cols-2 gap-4 text-sm">
            <div>
              <h3 className="font-medium text-blue-300 mb-2">🎨 Visual Enhancements</h3>
              <ul className="text-gray-300 space-y-1">
                <li>• **Bold** and *italic* markdown rendering</li>
                <li>• Checkbox indicators for multi-select</li>
                <li>• Responsive layouts (short vs long)</li>
                <li>• Smooth animations and transitions</li>
              </ul>
            </div>
            <div>
              <h3 className="font-medium text-purple-300 mb-2">⚡ Interaction Features</h3>
              <ul className="text-gray-300 space-y-1">
                <li>• Auto-detection of multi-select scenarios</li>
                <li>• Contextual hint text and tooltips</li>
                <li>• Submit button for multi-select confirmation</li>
                <li>• Accessible ARIA roles and labels</li>
              </ul>
            </div>
          </div>
        </section>
      </div>
    </div>
  );
};

export default MCQTestDemo;
</file>

<file path="src/components/SystemPromptEditor.tsx">
import React, { useCallback } from 'react';
import Editor from 'react-simple-code-editor';
import { highlight, languages } from 'prismjs';
import 'prismjs/components/prism-markdown';
import 'prismjs/themes/prism-dark.css';
import { ArrowUturnLeftIcon, CheckIcon } from '@heroicons/react/24/outline';

interface SystemPromptEditorProps {
  value: string;
  onChange: (value: string) => void;
  onReset: () => void;
  isLoading?: boolean;
  error?: string;
}

export const SystemPromptEditor: React.FC<SystemPromptEditorProps> = ({
  value,
  onChange,
  onReset,
  isLoading = false,
  error
}) => {
  const highlightCode = useCallback((code: string) => {
    return highlight(code, languages.markdown, 'markdown');
  }, []);

  const handleEditorChange = useCallback((code: string) => {
    onChange(code);
  }, [onChange]);

  return (
    <div className="space-y-4">
      {/* Header */}
      <div className="flex items-center justify-between">
        <div>
          <h3 className="text-lg font-semibold text-white">System Prompt</h3>
          <p className="text-sm text-gray-400">
            Configure how Kijko responds and behaves in conversations
          </p>
        </div>
        <button
          onClick={onReset}
          disabled={isLoading}
          className="
            flex items-center gap-2 px-3 py-2 text-sm
            text-gray-400 hover:text-white
            bg-gray-800 hover:bg-gray-700
            border border-gray-600 hover:border-gray-500
            rounded-lg transition-colors
            disabled:opacity-50 disabled:cursor-not-allowed
          "
          title="Reset to default system prompt"
        >
          <ArrowUturnLeftIcon className="w-4 h-4" />
          Reset
        </button>
      </div>

      {/* Error Message */}
      {error && (
        <div className="p-3 bg-red-500/10 border border-red-500/20 rounded-lg">
          <p className="text-sm text-red-400">{error}</p>
        </div>
      )}

      {/* Editor Container */}
      <div className="relative">
        <div className="
          bg-gray-900 border border-gray-700 rounded-lg overflow-hidden
          focus-within:border-purple-500/50 focus-within:ring-1 focus-within:ring-purple-500/20
          transition-colors
        ">
          <div className="p-4">
            <Editor
              value={value}
              onValueChange={handleEditorChange}
              highlight={highlightCode}
              padding={0}
              disabled={isLoading}
              className="
                min-h-[300px] max-h-[500px] overflow-y-auto
                text-sm font-mono text-gray-200
                focus:outline-none
                disabled:opacity-50
              "
              style={{
                fontFamily: '"Fira Code", "Monaco", "Cascadia Code", "Ubuntu Mono", monospace',
                fontSize: 14,
                lineHeight: 1.5,
                tabSize: 2,
              }}
              textareaClassName="
                focus:outline-none resize-none
                placeholder:text-gray-500
              "
              placeholder="Enter your system prompt here..."
            />
          </div>

          {/* Character Count */}
          <div className="flex items-center justify-between px-4 py-2 bg-gray-800/50 border-t border-gray-700">
            <div className="flex items-center gap-4 text-xs text-gray-400">
              <span>{value.length.toLocaleString()} characters</span>
              <span>{value.split('\n').length} lines</span>
            </div>
            
            {isLoading && (
              <div className="flex items-center gap-2 text-xs text-gray-400">
                <div className="w-3 h-3 border border-gray-400 border-t-transparent rounded-full animate-spin"></div>
                Saving...
              </div>
            )}
          </div>
        </div>

        {/* Syntax Highlighting Info */}
        <div className="mt-2 text-xs text-gray-500">
          Markdown syntax highlighting enabled • Use Ctrl+A to select all • Tab for indentation
        </div>
      </div>

      {/* Tips */}
      <div className="p-3 bg-blue-500/10 border border-blue-500/20 rounded-lg">
        <div className="flex items-start gap-2">
          <CheckIcon className="w-4 h-4 text-blue-400 mt-0.5 flex-shrink-0" />
          <div className="text-xs text-blue-200 space-y-1">
            <p><strong>Tips for effective system prompts:</strong></p>
            <ul className="list-disc list-inside space-y-1 ml-2">
              <li>Be specific about the assistant's role and capabilities</li>
              <li>Include examples of desired behavior when possible</li>
              <li>Define the expected response format and tone</li>
              <li>Set clear boundaries and limitations</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  );
};
</file>

<file path="src/components/Toast.tsx">
import React, { useEffect } from 'react';
import { CheckCircleIcon, XCircleIcon, ExclamationCircleIcon } from '@heroicons/react/24/solid';

export type ToastType = 'success' | 'error' | 'warning';

interface ToastProps {
  message: string;
  type: ToastType;
  isVisible: boolean;
  onClose: () => void;
  duration?: number;
}

export const Toast: React.FC<ToastProps> = ({
  message,
  type,
  isVisible,
  onClose,
  duration = 3000
}) => {
  useEffect(() => {
    if (isVisible && duration > 0) {
      const timer = setTimeout(() => {
        onClose();
      }, duration);
      
      return () => clearTimeout(timer);
    }
  }, [isVisible, duration, onClose]);

  const getIcon = () => {
    switch (type) {
      case 'success':
        return <CheckCircleIcon className="w-5 h-5 text-green-400" />;
      case 'error':
        return <XCircleIcon className="w-5 h-5 text-red-400" />;
      case 'warning':
        return <ExclamationCircleIcon className="w-5 h-5 text-yellow-400" />;
    }
  };

  const getStyles = () => {
    switch (type) {
      case 'success':
        return 'bg-green-500/10 border-green-500/20 text-green-200';
      case 'error':
        return 'bg-red-500/10 border-red-500/20 text-red-200';
      case 'warning':
        return 'bg-yellow-500/10 border-yellow-500/20 text-yellow-200';
    }
  };

  if (!isVisible) return null;

  return (
    <div
      className={`
        fixed top-4 right-4 z-[60] min-w-80 max-w-md p-4 rounded-lg border backdrop-blur-sm
        transform transition-all duration-300 ease-in-out
        ${getStyles()}
        ${isVisible ? 'translate-x-0 opacity-100' : 'translate-x-full opacity-0'}
      `}
    >
      <div className="flex items-center gap-3">
        {getIcon()}
        <div className="flex-1">
          <p className="text-sm font-medium">{message}</p>
        </div>
        <button
          onClick={onClose}
          className="text-gray-400 hover:text-white transition-colors p-1 rounded hover:bg-gray-700/50"
          aria-label="Close notification"
        >
          <svg className="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
          </svg>
        </button>
      </div>
      
      {/* Progress bar */}
      {duration > 0 && (
        <div className="mt-2 w-full bg-gray-700/30 rounded-full h-1">
          <div 
            className={`h-1 rounded-full transition-all ease-linear
              ${type === 'success' ? 'bg-green-400' : 
                type === 'error' ? 'bg-red-400' : 'bg-yellow-400'}
            `}
            style={{
              animation: `shrink ${duration}ms linear forwards`
            }}
          />
        </div>
      )}
    </div>
  );
};

// CSS animation for progress bar
const style = document.createElement('style');
style.textContent = `
  @keyframes shrink {
    from { width: 100%; }
    to { width: 0%; }
  }
`;
document.head.appendChild(style);
</file>

<file path="src/hooks/useProgress.ts">
import { useState, useCallback, useEffect } from 'react';

export interface ProgressStep {
  id: string;
  label: string;
  percentage: number;
}

// Define the conversation progress steps
export const PROGRESS_STEPS: ProgressStep[] = [
  { id: 'welcome', label: 'Welcome', percentage: 0 },
  { id: 'initial_rating', label: 'Initial Rating', percentage: 10 },
  { id: 'project_overview', label: 'Project Overview', percentage: 20 },
  { id: 'primary_goal', label: 'Primary Goal', percentage: 30 },
  { id: 'target_audience', label: 'Target Audience', percentage: 40 },
  { id: 'video_style', label: 'Video Style & Tone', percentage: 50 },
  { id: 'narrative_approach', label: 'Narrative Approach', percentage: 60 },
  { id: 'visual_elements', label: 'Visual Elements', percentage: 70 },
  { id: 'technical_specs', label: 'Technical Specs', percentage: 80 },
  { id: 'production_constraints', label: 'Production Details', percentage: 90 },
  { id: 'review', label: 'Review & Finalize', percentage: 100 }
];

export const useProgress = () => {
  const [currentStepIndex, setCurrentStepIndex] = useState(0);
  const [isVisible, setIsVisible] = useState(true);

  const currentStep = PROGRESS_STEPS[currentStepIndex];
  const nextStep = PROGRESS_STEPS[currentStepIndex + 1] || null;
  const totalSteps = PROGRESS_STEPS.length - 1; // Exclude welcome step from count

  // Calculate display values
  const displayStep = Math.max(currentStepIndex, 1); // Don't show step 0
  const percentage = currentStep.percentage;

  // Update progress based on message content
  const updateProgressByContent = useCallback((messageContent: string) => {
    const lowerContent = messageContent.toLowerCase();
    
    // Map keywords to progress steps
    if (lowerContent.includes('rate your') || lowerContent.includes('scale of')) {
      setCurrentStepIndex(1); // Initial Rating
    } else if (lowerContent.includes('project overview') || lowerContent.includes('tell me about your video')) {
      setCurrentStepIndex(2); // Project Overview
    } else if (lowerContent.includes('primary goal') || lowerContent.includes('main objective')) {
      setCurrentStepIndex(3); // Primary Goal
    } else if (lowerContent.includes('target audience') || lowerContent.includes('who is this for')) {
      setCurrentStepIndex(4); // Target Audience
    } else if (lowerContent.includes('video style') || lowerContent.includes('tone')) {
      setCurrentStepIndex(5); // Video Style
    } else if (lowerContent.includes('narrative') || lowerContent.includes('storytelling')) {
      setCurrentStepIndex(6); // Narrative Approach
    } else if (lowerContent.includes('visual') && lowerContent.includes('element')) {
      setCurrentStepIndex(7); // Visual Elements
    } else if (lowerContent.includes('technical') || lowerContent.includes('specification')) {
      setCurrentStepIndex(8); // Technical Specs
    } else if (lowerContent.includes('production') || lowerContent.includes('constraint')) {
      setCurrentStepIndex(9); // Production Constraints
    } else if (lowerContent.includes('review') || lowerContent.includes('finalize')) {
      setCurrentStepIndex(10); // Review
    }
  }, []);

  // Manual progress control
  const goToNextStep = useCallback(() => {
    if (currentStepIndex < PROGRESS_STEPS.length - 1) {
      setCurrentStepIndex(prev => prev + 1);
    }
  }, [currentStepIndex]);

  const goToPreviousStep = useCallback(() => {
    if (currentStepIndex > 0) {
      setCurrentStepIndex(prev => prev - 1);
    }
  }, [currentStepIndex]);

  const resetProgress = useCallback(() => {
    setCurrentStepIndex(0);
    setIsVisible(true);
  }, []);

  const hideProgress = useCallback(() => {
    setIsVisible(false);
  }, []);

  const showProgress = useCallback(() => {
    setIsVisible(true);
  }, []);

  // Auto-hide when complete
  useEffect(() => {
    if (percentage === 100) {
      const timer = setTimeout(() => {
        setIsVisible(false);
      }, 3000); // Hide after 3 seconds at 100%
      return () => clearTimeout(timer);
    }
  }, [percentage]);

  return {
    currentStep: displayStep,
    totalSteps,
    currentStepLabel: currentStep.label,
    nextStepLabel: nextStep?.label,
    percentage,
    isVisible,
    updateProgressByContent,
    goToNextStep,
    goToPreviousStep,
    resetProgress,
    hideProgress,
    showProgress
  };
};
</file>

<file path="src/hooks/useSpeechToText.ts">
import { useState, useEffect, useRef, useCallback } from 'react';

// Manually define types for the Web Speech API to address TypeScript errors,
// as these are not standard in all TypeScript DOM library versions.
interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  maxAlternatives: number;
  onaudiostart: ((this: SpeechRecognition, ev: Event) => any) | null;
  onaudioend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => any) | null;
  onnomatch: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null;
  onsoundstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  onsoundend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onspeechstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  onspeechend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  abort(): void;
  start(): void;
  stop(): void;
}

interface SpeechRecognitionEvent extends Event {
  readonly resultIndex: number;
  readonly results: SpeechRecognitionResultList;
}

interface SpeechRecognitionResultList {
  readonly length: number;
  item(index: number): SpeechRecognitionResult;
  [index: number]: SpeechRecognitionResult;
}

interface SpeechRecognitionResult {
  readonly isFinal: boolean;
  readonly length: number;
  item(index: number): SpeechRecognitionAlternative;
  [index: number]: SpeechRecognitionAlternative;
}

interface SpeechRecognitionAlternative {
  readonly transcript: string;
  readonly confidence: number;
}

interface SpeechRecognitionErrorEvent extends Event {
  readonly error: string;
  readonly message: string;
}

const getSpeechRecognition = () => {
  if (typeof window !== 'undefined') {
    // Cast `window` to `any` to access non-standard SpeechRecognition APIs
    // without causing TypeScript compilation errors.
    return (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
  }
  return undefined;
};

export const useSpeechToText = () => {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  // Use the defined `SpeechRecognition` interface as the type for the ref.
  const recognitionRef = useRef<SpeechRecognition | null>(null);

  // Rename the `SpeechRecognition` constant to `SpeechRecognitionAPI` to avoid a naming
  // conflict with the `SpeechRecognition` interface type.
  const SpeechRecognitionAPI = getSpeechRecognition();

  const stopListening = useCallback(() => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }
  }, []);

  const startListening = useCallback(() => {
    if (isListening || !SpeechRecognitionAPI) {
      return;
    }

    const recognition = new SpeechRecognitionAPI();
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'en-US';

    recognition.onstart = () => {
      setIsListening(true);
      setTranscript('');
    };

    recognition.onend = () => {
      setIsListening(false);
      recognitionRef.current = null;
    };

    recognition.onerror = (event) => {
      console.error('Speech recognition error', event.error);
      stopListening();
    };

    recognition.onresult = (event) => {
      const fullTranscript = Array.from(event.results)
        .map((result) => result[0].transcript)
        .join('');
      setTranscript(fullTranscript);
    };
    
    recognitionRef.current = recognition;
    recognition.start();
  }, [SpeechRecognitionAPI, isListening, stopListening]);

  useEffect(() => {
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.abort();
      }
    };
  }, []);

  return {
    isListening,
    transcript,
    startListening,
    stopListening,
    isSttSupported: !!SpeechRecognitionAPI,
    setTranscript,
  };
};
</file>

<file path="src/hooks/useTextToSpeech.ts">
import { useState, useCallback, useEffect } from 'react';

export const useTextToSpeech = () => {
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isTtsEnabled, setIsTtsEnabled] = useState(true);

  const synth = window.speechSynthesis;

  const speak = useCallback((text: string) => {
    if (!synth || !isTtsEnabled) return;
    
    synth.cancel(); // Cancel any previous utterance
    const utterance = new SpeechSynthesisUtterance(text);
    
    utterance.onstart = () => setIsSpeaking(true);
    utterance.onend = () => setIsSpeaking(false);
    utterance.onerror = () => setIsSpeaking(false);
    
    synth.speak(utterance);
  }, [synth, isTtsEnabled]);

  const stop = useCallback(() => {
    if (synth) {
      synth.cancel();
      setIsSpeaking(false);
    }
  }, [synth]);
  
  useEffect(() => {
      return () => {
          if(synth) synth.cancel();
      }
  }, [synth]);

  return { isSpeaking, isTtsEnabled, setIsTtsEnabled, speak, stop };
};
</file>

<file path="src/types/speech.d.ts">
// TypeScript declarations for Web Speech API
declare global {
  interface Window {
    SpeechRecognition: typeof SpeechRecognition;
    webkitSpeechRecognition: typeof SpeechRecognition;
  }
}

export {};
</file>

<file path="src/utils/documentStorage.ts">
import { get, set, del, entries, clear } from 'idb-keyval';
import { VRDDocument } from './vrdFormatter';

const DOCUMENTS_KEY = 'vrd_documents';
const DOCUMENT_PREFIX = 'vrd_doc_';

export interface StoredDocument {
  id: string;
  title: string;
  createdAt: Date;
  updatedAt: Date;
  type: 'pdf' | 'markdown';
  size?: number;
  preview?: string; // First few lines for preview
}

class DocumentStorage {
  /**
   * Save a VRD document
   */
  async saveDocument(doc: VRDDocument): Promise<void> {
    try {
      // Save the full document
      await set(`${DOCUMENT_PREFIX}${doc.id}`, doc);

      // Update the documents index
      const index = await this.getDocumentsIndex();
      const storedDoc: StoredDocument = {
        id: doc.id,
        title: doc.title,
        createdAt: doc.createdAt,
        updatedAt: doc.updatedAt,
        type: doc.type,
        size: doc.blob ? doc.blob.size : 0,
        preview: this.generatePreview(doc)
      };

      const existingIndex = index.findIndex(d => d.id === doc.id);
      if (existingIndex !== -1) {
        index[existingIndex] = storedDoc;
      } else {
        index.push(storedDoc);
      }

      await set(DOCUMENTS_KEY, index);
    } catch (error) {
      console.error('Error saving document:', error);
      throw error;
    }
  }

  /**
   * Get a document by ID
   */
  async getDocument(id: string): Promise<VRDDocument | null> {
    try {
      const doc = await get(`${DOCUMENT_PREFIX}${id}`);
      if (doc) {
        // Convert dates back from strings
        doc.createdAt = new Date(doc.createdAt);
        doc.updatedAt = new Date(doc.updatedAt);
      }
      return doc || null;
    } catch (error) {
      console.error('Error getting document:', error);
      return null;
    }
  }

  /**
   * Get all documents index
   */
  async getDocumentsIndex(): Promise<StoredDocument[]> {
    try {
      const index = await get(DOCUMENTS_KEY);
      if (index) {
        // Convert dates back from strings
        return index.map((doc: any) => ({
          ...doc,
          createdAt: new Date(doc.createdAt),
          updatedAt: new Date(doc.updatedAt)
        }));
      }
      return [];
    } catch (error) {
      console.error('Error getting documents index:', error);
      return [];
    }
  }

  /**
   * Delete a document
   */
  async deleteDocument(id: string): Promise<void> {
    try {
      // Delete the document
      await del(`${DOCUMENT_PREFIX}${id}`);

      // Update the index
      const index = await this.getDocumentsIndex();
      const updatedIndex = index.filter(d => d.id !== id);
      await set(DOCUMENTS_KEY, updatedIndex);
    } catch (error) {
      console.error('Error deleting document:', error);
      throw error;
    }
  }

  /**
   * Delete all documents
   */
  async clearAllDocuments(): Promise<void> {
    try {
      // Get all entries to find document keys
      const allEntries = await entries();
      
      // Delete all document entries
      for (const [key] of allEntries) {
        if (typeof key === 'string' && key.startsWith(DOCUMENT_PREFIX)) {
          await del(key);
        }
      }

      // Clear the index
      await set(DOCUMENTS_KEY, []);
    } catch (error) {
      console.error('Error clearing all documents:', error);
      throw error;
    }
  }

  /**
   * Search documents by title
   */
  async searchDocuments(query: string): Promise<StoredDocument[]> {
    try {
      const index = await this.getDocumentsIndex();
      const searchTerm = query.toLowerCase();
      return index.filter(doc => 
        doc.title.toLowerCase().includes(searchTerm) ||
        (doc.preview && doc.preview.toLowerCase().includes(searchTerm))
      );
    } catch (error) {
      console.error('Error searching documents:', error);
      return [];
    }
  }

  /**
   * Get recent documents
   */
  async getRecentDocuments(limit: number = 10): Promise<StoredDocument[]> {
    try {
      const index = await this.getDocumentsIndex();
      return index
        .sort((a, b) => b.updatedAt.getTime() - a.updatedAt.getTime())
        .slice(0, limit);
    } catch (error) {
      console.error('Error getting recent documents:', error);
      return [];
    }
  }

  /**
   * Export a document as a file
   */
  async exportDocument(id: string, format: 'pdf' | 'markdown'): Promise<Blob | null> {
    try {
      const doc = await this.getDocument(id);
      if (!doc) return null;

      if (format === 'pdf' && doc.blob) {
        return doc.blob;
      }

      if (format === 'markdown') {
        // Convert to markdown if needed
        const { vrdFormatter } = await import('./vrdFormatter');
        const markdown = vrdFormatter.toMarkdown(doc);
        return new Blob([markdown], { type: 'text/markdown' });
      }

      return null;
    } catch (error) {
      console.error('Error exporting document:', error);
      return null;
    }
  }

  /**
   * Generate preview text for a document
   */
  private generatePreview(doc: VRDDocument): string {
    const preview = [];
    
    if (doc.content.projectOverview) {
      preview.push(doc.content.projectOverview.substring(0, 100));
    }
    
    if (doc.content.requirements.length > 0) {
      preview.push(doc.content.requirements[0]);
    }

    return preview.join(' ').substring(0, 200) + '...';
  }

  /**
   * Get storage usage stats
   */
  async getStorageStats(): Promise<{
    documentCount: number;
    totalSize: number;
  }> {
    try {
      const index = await this.getDocumentsIndex();
      const totalSize = index.reduce((acc, doc) => acc + (doc.size || 0), 0);
      
      return {
        documentCount: index.length,
        totalSize
      };
    } catch (error) {
      console.error('Error getting storage stats:', error);
      return { documentCount: 0, totalSize: 0 };
    }
  }
}

export const documentStorage = new DocumentStorage();
</file>

<file path="src/utils/settingsStorage.ts">
import { AppSettings, DEFAULT_SETTINGS } from '../types/settings';
import { KIJKO_SYSTEM_PROMPT } from '../constants';

const SETTINGS_KEY = 'kijko_app_settings';

// Initialize default settings with actual system prompt
const getDefaultSettings = (): AppSettings => ({
  ...DEFAULT_SETTINGS,
  systemPrompt: KIJKO_SYSTEM_PROMPT
});

/**
 * Load settings from localStorage with type safety and error handling
 */
export const loadSettings = (): AppSettings => {
  try {
    const stored = localStorage.getItem(SETTINGS_KEY);
    
    if (!stored) {
      return getDefaultSettings();
    }

    const parsed = JSON.parse(stored) as AppSettings;
    
    // Validate that all required properties exist
    if (
      typeof parsed.systemPrompt !== 'string' ||
      typeof parsed.selectedModel !== 'string' ||
      !parsed.systemPrompt.trim()
    ) {
      console.warn('Invalid settings found in localStorage, using defaults');
      return getDefaultSettings();
    }

    return {
      ...getDefaultSettings(),
      ...parsed
    };
  } catch (error) {
    console.error('Failed to load settings from localStorage:', error);
    return getDefaultSettings();
  }
};

/**
 * Save settings to localStorage with error handling
 */
export const saveSettings = (settings: AppSettings): boolean => {
  try {
    const serialized = JSON.stringify(settings);
    localStorage.setItem(SETTINGS_KEY, serialized);
    console.log('Settings saved successfully');
    return true;
  } catch (error) {
    console.error('Failed to save settings to localStorage:', error);
    return false;
  }
};

/**
 * Reset settings to default values
 */
export const resetSettings = (): AppSettings => {
  try {
    localStorage.removeItem(SETTINGS_KEY);
    console.log('Settings reset to defaults');
    return getDefaultSettings();
  } catch (error) {
    console.error('Failed to reset settings:', error);
    return getDefaultSettings();
  }
};

/**
 * Check if settings exist in localStorage
 */
export const hasStoredSettings = (): boolean => {
  try {
    return localStorage.getItem(SETTINGS_KEY) !== null;
  } catch (error) {
    return false;
  }
};

/**
 * Validate settings object structure
 */
export const validateSettings = (settings: unknown): settings is AppSettings => {
  if (!settings || typeof settings !== 'object') {
    return false;
  }

  const s = settings as Record<string, unknown>;
  
  return (
    typeof s.systemPrompt === 'string' &&
    typeof s.selectedModel === 'string' &&
    s.systemPrompt.trim().length > 0
  );
};
</file>

<file path="src/utils/vrdFormatter.ts">
import { Message } from '../types';
import TurndownService from 'turndown';

export interface VRDContent {
  projectOverview: string;
  requirements: string[];
  technicalSpecs: string;
  timeline: string;
  budget: string;
  additionalNotes?: string;
}

export interface VRDDocument {
  id: string;
  title: string;
  createdAt: Date;
  updatedAt: Date;
  content: VRDContent;
  conversationHistory: Message[];
  type: 'pdf' | 'markdown';
  blob?: Blob;
}

class VrdFormatter {
  private turndown: TurndownService;

  constructor() {
    this.turndown = new TurndownService({
      headingStyle: 'atx',
      hr: '---',
      bulletListMarker: '-',
      codeBlockStyle: 'fenced'
    });

    // Customize Turndown for better Markdown output
    this.turndown.addRule('emphasis', {
      filter: ['em', 'i'],
      replacement: function (content) {
        return '*' + content + '*';
      }
    });
  }

  /**
   * Formats chat messages into a structured VRD document
   */
  public formatVRD(messages: Message[], title: string): VRDDocument {
    const vrd: VRDDocument = {
      id: crypto.randomUUID(),
      title,
      createdAt: new Date(),
      updatedAt: new Date(),
      content: this.extractContent(messages),
      conversationHistory: messages,
      type: 'markdown'
    };

    return vrd;
  }

  /**
   * Extracts structured content from chat messages
   */
  private extractContent(messages: Message[]): VRDContent {
    // Initialize content sections
    const content: VRDContent = {
      projectOverview: '',
      requirements: [],
      technicalSpecs: '',
      timeline: '',
      budget: '',
      additionalNotes: ''
    };

    // Find relevant messages for each section
    messages.forEach(msg => {
      if (msg.role === 'assistant') {
        // Project Overview - usually at the start
        if (msg.text.toLowerCase().includes('project overview') || 
            msg.text.toLowerCase().includes('project description')) {
          content.projectOverview = this.extractSection(msg.text, 'project overview');
        }

        // Requirements - look for bullet points and numbered lists
        if (msg.text.toLowerCase().includes('requirements') ||
            msg.text.toLowerCase().includes('features needed')) {
          content.requirements = this.extractRequirements(msg.text);
        }

        // Technical Specs
        if (msg.text.toLowerCase().includes('technical') || 
            msg.text.toLowerCase().includes('specifications')) {
          content.technicalSpecs = this.extractSection(msg.text, 'technical specifications');
        }

        // Timeline
        if (msg.text.toLowerCase().includes('timeline') || 
            msg.text.toLowerCase().includes('schedule')) {
          content.timeline = this.extractSection(msg.text, 'timeline');
        }

        // Budget
        if (msg.text.toLowerCase().includes('budget') || 
            msg.text.toLowerCase().includes('cost')) {
          content.budget = this.extractSection(msg.text, 'budget');
        }
      }
    });

    return content;
  }

  /**
   * Extracts a specific section from text
   */
  private extractSection(text: string, sectionName: string): string {
    const sections = text.split(/(?=##?\s+[A-Z])/);
    const section = sections.find(s => 
      s.toLowerCase().includes(sectionName.toLowerCase())
    );
    return section ? this.cleanText(section) : '';
  }

  /**
   * Extracts requirements from text
   */
  private extractRequirements(text: string): string[] {
    const requirements: string[] = [];
    const lines = text.split('\n');

    let inRequirementsList = false;
    lines.forEach(line => {
      // Check if this is a requirement (starts with bullet or number)
      if (line.match(/^[-*•]|\d+\./)) {
        inRequirementsList = true;
        requirements.push(this.cleanText(line));
      } else if (inRequirementsList && line.trim() === '') {
        inRequirementsList = false;
      }
    });

    return requirements;
  }

  /**
   * Cleans and formats text
   */
  private cleanText(text: string): string {
    return text
      .replace(/^[-*•]\s+/, '') // Remove bullet points
      .replace(/^\d+\.\s+/, '') // Remove numbering
      .trim();
  }

  /**
   * Converts VRD to Markdown format
   */
  public toMarkdown(vrd: VRDDocument): string {
    let md = `# ${vrd.title}\n\n`;
    md += `_Generated on ${vrd.createdAt.toLocaleDateString()}_\n\n`;

    // Project Overview
    if (vrd.content.projectOverview) {
      md += `## Project Overview\n\n${vrd.content.projectOverview}\n\n`;
    }

    // Requirements
    if (vrd.content.requirements.length > 0) {
      md += '## Requirements\n\n';
      vrd.content.requirements.forEach(req => {
        md += `- ${req}\n`;
      });
      md += '\n';
    }

    // Technical Specifications
    if (vrd.content.technicalSpecs) {
      md += `## Technical Specifications\n\n${vrd.content.technicalSpecs}\n\n`;
    }

    // Timeline
    if (vrd.content.timeline) {
      md += `## Timeline\n\n${vrd.content.timeline}\n\n`;
    }

    // Budget
    if (vrd.content.budget) {
      md += `## Budget\n\n${vrd.content.budget}\n\n`;
    }

    // Additional Notes
    if (vrd.content.additionalNotes) {
      md += `## Additional Notes\n\n${vrd.content.additionalNotes}\n\n`;
    }

    return md;
  }

  /**
   * Converts HTML content to Markdown
   */
  public htmlToMarkdown(html: string): string {
    return this.turndown.turndown(html);
  }
}

export const vrdFormatter = new VrdFormatter();
</file>

<file path="constants.ts">
export const KIJKO_SYSTEM_PROMPT = `
You are Kijko, a multimodal, speech-enabled Video Brief Assistant that expertly guides users through creating comprehensive Video Requirements Documents (VRDs) and managing the entire video production process. You adapt your guidance level based on each user's clarity and experience, ensuring everyone—from complete beginners to seasoned professionals—can articulate and realize their video vision.

Your primary capabilities are:
1.  **Adaptive Discovery Engine**:
    *   **Vision Assessment**: Early in the conversation (within the first 3 exchanges), gauge the user's clarity level on a 1-10 scale. The prompt is: "To help me tailor our session perfectly for you, could you rate your current vision clarity on a scale of 1-10? 1 = 'I just know I need a video to achieve a business goal', 5 = 'I have a general concept and some specific ideas', 10 = 'I have detailed requirements including script, style, and technical specs'. Your answer helps me adjust my guidance level to match your needs."
    *   **Dynamic Adjustment**: Modify questioning depth and guidance based on the assessed level.
    *   **Intelligent Extraction**: Pull relevant information from vague ideas or detailed specifications.
    *   **Context Building**: Accumulate understanding through natural conversation flow.

2.  **Multi-Modal Processing**:
    *   **Language Detection**: Automatically detect and respond in the user's spoken/written language.
    *   **File Analysis**: Process images, videos, documents, and audio for context and reference. You will receive these as base64 encoded data. When a user provides a YouTube URL, analyze its content as a video reference.
    *   **Visual Understanding**: Extract style, mood, and composition from uploaded references.
    *   **Document Parsing**: Extract requirements from existing briefs, scripts, or guidelines.

3.  **VRD Generation Pipeline**:
    *   **Structured Documentation**: Create professional VRDs matching industry standards.
    *   **Component Assembly**: Build all required sections from gathered information.
    *   **Format Flexibility**: Adjust the detail level based on user needs and project scope.
    *   **Export Ready**: Generate publication-ready documents for stakeholder review when requested via the /export command.

**Conversation Framework & Questioning Strategy:**

*   **Phase 1: Initial Assessment (First 2-3 exchanges)**: Start with the opening engagement: "Hello! I'm Kijko, your video brief assistant. I'll help you create a comprehensive production plan for your video project. To get started, could you tell me about your video idea? Feel free to share as much or as little as you have in mind, and we'll build from there." Then, perform the Vision Clarity Assessment.
*   **Phase 2: Adaptive Discovery (Based on Clarity Score)**:
    *   **Low Clarity (1-3)**: Start with fundamental business questions, provide multiple-choice options, offer industry examples, use analogies, and provide heavy scaffolding with pre-filled suggestions.
    *   **Medium Clarity (4-7)**: Mix open and guided questions, probe for specifics, suggest options for uncertain areas, validate assumptions explicitly, and provide moderate guidance.
    *   **High Clarity (8-10)**: Ask direct, specific questions, focus on technical requirements, validate completeness with minimal hand-holding, and use expert-level terminology.
*   **Phase 3: Information Gathering (Core Discovery Questions adapted to clarity level)**: Cover Purpose & Goals, Audience, Message, Style & Tone, and Practical Constraints.
*   **Phase 4: Intelligent Assistance**: When the user is unclear, offer help: "I notice you might need some help with [specific aspect]. Would you like me to: A) Generate suggestions based on our conversation so far, B) Show you similar examples from other projects, C) Research best practices for your industry, D) Move on and revisit this later. Just pick a letter or describe what would help most."

**Interaction Commands (User Commands you must recognize and act upon):**
*   \`/clarity\` [1-10]: User adjusts guidance level mid-session.
*   \`/research\` [topic]: User invokes a research agent. You should perform a targeted search on the topic and provide a summary.
*   \`/example\` [type]: User requests relevant examples.
*   \`/template\` [industry]: User wants to load an industry template.
*   \`/review\`: User wants to see the current VRD draft. Summarize the collected information in the standard VRD sections.
*   \`/missing\`: User wants to know what's missing. Show incomplete sections.
*   \`/suggest\`: User wants suggestions for the current section.
*   \`/export\`: User wants the final VRD document. Present the complete VRD in a well-formatted, clean way, ready for copying.

**System Behaviors:**
*   **Progress Indicator**: Periodically, show the completion percentage of the VRD.
*   **Smart Prompts**: Offer pre-written options when detecting hesitation.
*   **Validation Loops**: Confirm your understanding of critical points.
*   **Information Display**: Use bullet points for clarity, provide inline examples, summarize periodically, and confirm before moving to new sections.

**Tone Adaptation:**
*   **Low clarity users**: Be encouraging, educational, and patient.
*   **Medium clarity users**: Be collaborative, validating, and guiding.
*   **High clarity users**: Be efficient, professional, and technical.

Your ultimate goal is to extract a professional, comprehensive VRD from any user, regardless of their initial clarity or experience level. Be adaptive, intelligent, and supportive while maintaining efficiency and professionalism.
`;
</file>

<file path="DEPLOY_GUIDE.md">
# Vercel Deployment Checklist

## Steps for React/Next.js MVP Deployment to Vercel via GitHub

• **Create GitHub Repository**: Initialize repo with main/master branch, add .gitignore for node_modules, .env.local, .vercel
• **Project Structure**: Ensure package.json in root with build/dev scripts, Next.js pages/app directory structure
• **Local Environment Setup**: Create .env.local for development variables, add to .gitignore 
• **Build Command**: Set "build": "next build" in package.json scripts
• **Output Directory**: Next.js outputs to .next/ (auto-detected by Vercel)
• **Connect to Vercel**: Import GitHub repo via Vercel dashboard, auto-detects Next.js framework
• **Environment Variables**: Add via Vercel dashboard Settings > Environment Variables
• **Sensitive Variables**: Toggle "Sensitive" switch for API keys (production/preview only)
• **Deploy Trigger**: Push to main branch triggers automatic production deployment
• **Preview Deployments**: Every PR/branch push creates preview URL automatically

## Common Pitfalls to Avoid

• **Missing .env Variables**: Add all required env vars in Vercel dashboard before deployment
• **Build Size Limits**: Keep bundle under 250MB, optimize images and dependencies  
• **Static Assets**: Place in public/ directory, not in pages or components
• **API Routes**: Use pages/api/ or app/api/ structure for serverless functions
• **Build Errors**: Test "npm run build" locally before pushing to GitHub
• **Wrong Branch**: Ensure main/master is default branch in GitHub settings

```yaml
# Vercel Deployment Checklist
vercel_deployment_checklist:
  pre_deployment:
    - task: "Create GitHub repo with main branch"
      status: "completed"
    - task: "Add .gitignore (node_modules, .env.local, .vercel)"  
      status: "completed"
    - task: "Verify package.json build script"
      status: "pending"
    - task: "Test local build with npm run build"
      status: "pending"
      
  vercel_setup:
    - task: "Import GitHub repo to Vercel dashboard"
      status: "pending"
    - task: "Add environment variables in Settings"
      status: "pending" 
    - task: "Mark sensitive vars (API keys) as Sensitive"
      status: "pending"
    - task: "Verify framework detection (Next.js)"
      status: "pending"
      
  post_deployment:
    - task: "Test production deployment URL"
      status: "pending"
    - task: "Verify environment variables loaded"  
      status: "pending"
    - task: "Check build logs for errors"
      status: "pending"
    - task: "Test preview deployment on PR"
      status: "pending"
```
</file>

<file path="DESKTOP_USAGE.md">
# Kijko Desktop Integration

This setup provides desktop shortcut functionality and app closing capabilities for the Kijko Video Brief Assistant.

## Files Created

1. **`launch-kijko.sh`** - Starts the Kijko app
2. **`kill-kijko.sh`** - Stops the app and frees all ports  
3. **`/home/david/Desktop/Kijko.desktop`** - Desktop shortcut (updated)

## How to Use

### Starting Kijko
- **Double-click** the "Kijko" desktop icon
- Or run: `./launch-kijko.sh` from terminal in this directory
- The app will start on `http://localhost:5173` and open automatically in your browser

### Closing Kijko

#### Method 1: Close Button (Recommended)
- Click the red **×** button in the top-right corner of the app
- Confirm when prompted
- The app will display a shutdown message and the browser will close
- The launcher script automatically detects the shutdown signal and kills all processes

#### Method 2: Terminal Command
- Run: `./kill-kijko.sh` from terminal in this directory
- This forcefully kills all app processes and frees ports

#### Method 3: Manual Cleanup
- If the app gets stuck, you can always run the kill script directly

## Features

### Desktop Shortcut
- **Name**: Kijko Video Brief Assistant
- **Location**: `/home/david/Desktop/Kijko.desktop`
- **Function**: Launches the app and opens browser automatically
- **Categories**: Development, AudioVideo, Graphics

### Process Management
- **PID Tracking**: App process ID saved to `/tmp/kijko-app.pid`
- **Port Management**: Automatically frees ports 5173, 3000, 4173, 8080
- **Process Cleanup**: Kills all related Vite/Node processes

### Shutdown Monitoring
- The launcher script monitors for shutdown signals
- Creates shutdown signal file in Downloads folder
- Automatically triggers cleanup when signal detected

## Troubleshooting

### App Won't Start
```bash
# Check if ports are in use
lsof -i :5173

# Kill any existing processes
./kill-kijko.sh

# Try starting again
./launch-kijko.sh
```

### App Won't Close
```bash
# Force kill all processes
./kill-kijko.sh

# Check if ports are free
lsof -i :5173
```

### Desktop Shortcut Not Working
```bash
# Make sure the desktop file is executable
chmod +x /home/david/Desktop/Kijko.desktop

# Test the launcher script directly
./launch-kijko.sh
```

## Technical Details

- **Framework**: React + Vite + TypeScript
- **Default Port**: 5173 (Vite dev server)
- **Process Monitoring**: PID file + signal file approach
- **Browser Integration**: Automatic opening via `xdg-open`
- **Cleanup**: Comprehensive process and port cleanup
</file>

<file path="ENHANCED_MCQ_README.md">
# Enhanced MCQ System Implementation

## Overview

The Multiple Choice Question (MCQ) system has been significantly enhanced to address the issues with irrelevant button options and improve user experience. The new implementation includes:

1. **Markdown Rendering**: Raw markdown asterisks are now properly rendered as **bold** and *italic* text
2. **Multi-Select Capability**: Support for checkbox-style multi-select options
3. **Auto-Detection**: Intelligent detection of multi-select scenarios based on content keywords
4. **Visual Enhancements**: Improved UI with proper indicators and animations
5. **Accessibility**: Better ARIA labels and semantic HTML structure

## Key Features

### 🎨 Visual Enhancements

- **Markdown Support**: Uses `react-markdown` to render option text with proper formatting
- **Checkbox Indicators**: Visual checkboxes for multi-select options
- **Radio Buttons**: Traditional radio buttons for single-select scenarios  
- **Responsive Layouts**: Adaptive short vs long option layouts
- **Smooth Animations**: Subtle transitions and hover effects
- **Loading States**: Visual feedback during processing

### ⚡ Interaction Features

- **Auto-Detection**: Automatically detects multi-select scenarios based on keywords:
  - `energetic`, `mysterious`, `style`, `tone` trigger multi-select mode
- **Contextual Hints**: "Select all that apply" tooltip for multi-select questions
- **Submit Button**: Confirmation button for multi-select with selection count
- **Immediate Response**: Single-select options trigger immediately
- **Multiple Selection Support**: Array-based state management for multiple choices

### 🔧 Technical Implementation

#### Component Structure

```typescript
interface OptionGroupProps {
  options: MCQOption[];
  onSelect: (option: MCQOption) => void;
  onSubmit?: (selectedOptions: MCQOption[]) => void; // For multi-select
  disabled?: boolean;
  short?: boolean; // Force short layout
  allowMultiple?: boolean; // Explicit multi-select override
}
```

#### Auto-Detection Logic

```typescript
const shouldAllowMultiple = allowMultiple || options.some(opt => 
  opt.text.toLowerCase().includes('energetic') || 
  opt.text.toLowerCase().includes('mysterious') ||
  opt.text.toLowerCase().includes('style') ||
  opt.text.toLowerCase().includes('tone')
);
```

#### Markdown Rendering

```typescript
<ReactMarkdown 
  components={{ 
    p: React.Fragment,
    strong: ({ children }) => <strong className="font-bold">{children}</strong>,
    em: ({ children }) => <em className="italic">{children}</em>
  }}
>
  {option.text}
</ReactMarkdown>
```

## Usage Examples

### Single Select (Default)
```jsx
<OptionGroup
  options={singleSelectOptions}
  onSelect={handleSingleSelect}
/>
```

### Auto-Detected Multi-Select
```jsx
<OptionGroup
  options={multiSelectOptions} // Contains keywords like "style", "tone"
  onSelect={handleSingleSelect} // Fallback for single selections
  onSubmit={handleMultiSelect} // For multi-select submissions
/>
```

### Explicit Multi-Select
```jsx
<OptionGroup
  options={explicitMultiSelect}
  onSelect={handleSingleSelect}
  onSubmit={handleExplicitMultiSelect}
  allowMultiple={true} // Force multi-select mode
/>
```

## Testing

A comprehensive test demo is available at `/mcq-test` route which demonstrates:

1. **Single Select Questions**: Traditional radio button behavior
2. **Auto-Detected Multi-Select**: Keywords trigger multi-select mode
3. **Explicit Multi-Select**: Manually enabled multi-select
4. **Markdown Rendering**: Bold and italic text formatting
5. **Selection Results**: Real-time feedback of user choices

## Files Modified

- `src/components/OptionGroup.tsx`: Core MCQ component with multi-select logic
- `src/components/MCQTestDemo.tsx`: Test demo component (new)
- `src/index.tsx`: Added router for test routes
- `package.json`: Added react-router-dom dependencies

## Benefits

### User Experience
- **Cleaner Interface**: No more raw markdown asterisks in button text
- **Intuitive Selection**: Clear visual indicators for single vs multi-select
- **Contextual Guidance**: Helpful hints and tooltips
- **Confirmation Flow**: Submit button prevents accidental submissions

### Developer Experience
- **Flexible API**: Supports both single and multi-select modes
- **Auto-Detection**: Reduces need for manual configuration
- **Type Safety**: Full TypeScript support with proper interfaces
- **Maintainable Code**: Clean separation of concerns

### Accessibility
- **Proper ARIA Roles**: `checkbox`, `radio`, `group`, `radiogroup`
- **Keyboard Navigation**: Full keyboard accessibility
- **Screen Reader Support**: Descriptive labels and states
- **Focus Management**: Clear focus indicators

## Future Enhancements

- **Conditional Logic**: Sequential question flows based on responses
- **Custom Input Fields**: Text input options alongside MCQ choices
- **Advanced Auto-Detection**: Machine learning-based detection
- **Analytics**: Track user interaction patterns
- **Themes**: Customizable visual themes for different contexts

## Demo Access

Visit `http://localhost:5174/mcq-test` to see the enhanced MCQ system in action with various test scenarios demonstrating all the new features.
</file>

<file path="index.html">
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Kijko Video Brief Assistant</title>
    <script src="https://cdn.tailwindcss.com"></script>
  <script type="importmap">
{
  "imports": {
    "react": "https://aistudiocdn.com/react@^19.1.1",
    "react/": "https://aistudiocdn.com/react@^19.1.1/",
    "react-dom/": "https://aistudiocdn.com/react-dom@^19.1.1/",
    "@google/genai": "https://aistudiocdn.com/@google/genai@^1.16.0"
  }
}
</script>
</head>
  <body class="bg-gray-900 text-white">
    <div id="root"></div>
    <script type="module" src="/src/index.tsx"></script>
  </body>
</html>
</file>

<file path="kijko-control.sh">
#!/bin/bash

# Kijko Control Script
# Provides easy commands to start/stop Kijko from anywhere

APP_DIR="/home/david/Projects/Kijko/MVP/MVP_Kijko"

case "$1" in
    start|launch|run)
        echo "Starting Kijko..."
        bash "$APP_DIR/launch-kijko.sh"
        ;;
    stop|kill|close)
        echo "Stopping Kijko..."
        bash "$APP_DIR/kill-kijko.sh"
        ;;
    restart)
        echo "Restarting Kijko..."
        bash "$APP_DIR/kill-kijko.sh"
        sleep 2
        bash "$APP_DIR/launch-kijko.sh"
        ;;
    status)
        PID_FILE="/tmp/kijko-app.pid"
        if [ -f "$PID_FILE" ] && ps -p "$(cat $PID_FILE)" > /dev/null 2>&1; then
            echo "Kijko is running (PID: $(cat $PID_FILE))"
            echo "App should be available at: http://localhost:5173"
        else
            echo "Kijko is not running"
        fi
        ;;
    *)
        echo "Kijko Control Script"
        echo ""
        echo "Usage: $0 {start|stop|restart|status}"
        echo ""
        echo "Commands:"
        echo "  start    - Launch Kijko app"
        echo "  stop     - Stop Kijko app and free all ports"
        echo "  restart  - Stop and start Kijko app"
        echo "  status   - Check if Kijko is running"
        echo ""
        echo "Desktop shortcut: Double-click Kijko icon on desktop"
        exit 1
        ;;
esac
</file>

<file path="kill-kijko.sh">
#!/bin/bash

# Kijko App Killer Script
# This script stops the Kijko application and frees up all ports

PID_FILE="/tmp/kijko-app.pid"
APP_NAME="kijko"

echo "Stopping Kijko app..."

# Kill process by PID file if it exists
if [ -f "$PID_FILE" ]; then
    PID=$(cat "$PID_FILE")
    if ps -p "$PID" > /dev/null 2>&1; then
        echo "Killing main process (PID: $PID)..."
        kill -TERM "$PID" 2>/dev/null || kill -KILL "$PID" 2>/dev/null
        sleep 1
    fi
    rm "$PID_FILE"
    echo "PID file removed"
fi

# Kill any remaining vite/node processes related to the app
echo "Killing any remaining Vite/Node processes..."
pkill -f "vite.*kijko" 2>/dev/null || true
pkill -f "node.*vite" 2>/dev/null || true
pkill -f "npm.*dev" 2>/dev/null || true

# Free up common development ports (5173 is Vite's default)
echo "Freeing up ports..."
for port in 5173 3000 4173 8080; do
    PID_ON_PORT=$(lsof -ti:$port 2>/dev/null)
    if [ -n "$PID_ON_PORT" ]; then
        echo "Killing process on port $port (PID: $PID_ON_PORT)"
        kill -TERM "$PID_ON_PORT" 2>/dev/null || kill -KILL "$PID_ON_PORT" 2>/dev/null
    fi
done

# Wait a moment for cleanup
sleep 1

# Verify ports are free
echo "Checking if ports are free..."
for port in 5173 3000 4173 8080; do
    if lsof -ti:$port > /dev/null 2>&1; then
        echo "Warning: Port $port is still in use"
    else
        echo "Port $port is free"
    fi
done

echo "Kijko app has been stopped and all ports freed!"
</file>

<file path="launch-kijko-absolute.sh">
#!/bin/bash

# Kijko App Launcher Script (Absolute Paths Version)
# This version uses absolute paths to avoid PATH issues

APP_DIR="/home/david/Projects/Kijko/MVP/MVP_Kijko"
PID_FILE="/tmp/kijko-app.pid"
NODE_BIN="/home/david/.nvm/versions/node/v24.4.1/bin"
NPM="$NODE_BIN/npm"
NODE="$NODE_BIN/node"

# Change to app directory
cd "$APP_DIR"

echo "=== Kijko Launcher (Absolute Paths) ==="
echo "App Directory: $APP_DIR"
echo "Node Binary: $NODE"
echo "NPM Binary: $NPM"

# Check if binaries exist
if [ ! -f "$NODE" ]; then
    echo "Error: Node.js not found at $NODE"
    echo "Please check your Node.js installation"
    exit 1
fi

if [ ! -f "$NPM" ]; then
    echo "Error: NPM not found at $NPM"
    echo "Please check your NPM installation"
    exit 1
fi

# Check if app is already running
if [ -f "$PID_FILE" ]; then
    if ps -p "$(cat $PID_FILE)" > /dev/null 2>&1; then
        echo "Kijko app is already running (PID: $(cat $PID_FILE))"
        # Open browser to the app
        xdg-open "http://localhost:5173" &
        exit 0
    else
        # Remove stale PID file
        rm "$PID_FILE"
    fi
fi

echo "Starting Kijko app..."

# Source NVM and start the development server
# This ensures the Node.js environment is properly set up
source /home/david/.nvm/nvm.sh
nvm use 24.4.1
npm run dev &
DEV_PID=$!

# Save the main process ID
echo $DEV_PID > "$PID_FILE"

echo "Kijko app started with PID: $DEV_PID"
echo "PID saved to $PID_FILE"

# Wait a moment for server to start
sleep 3

# Open browser to the app
echo "Opening browser..."
xdg-open "http://localhost:5173" &

echo "Kijko app is now running!"
echo "Use the close button in the app or run kill-kijko.sh to stop it."

# Monitor for shutdown signals in background
{
    while true; do
        # Check if PID file still exists and process is running
        if [ ! -f "$PID_FILE" ] || ! ps -p "$(cat $PID_FILE 2>/dev/null)" > /dev/null 2>&1; then
            break
        fi
        
        # Check for shutdown signal file in Downloads (where browser downloads go)
        if [ -f "/home/david/Downloads/kijko-shutdown-signal.txt" ]; then
            echo "Shutdown signal detected, stopping app..."
            rm "/home/david/Downloads/kijko-shutdown-signal.txt" 2>/dev/null
            bash "$APP_DIR/kill-kijko.sh"
            break
        fi
        
        sleep 2
    done
} &
</file>

<file path="launch-kijko.py">
#!/usr/bin/env python3

import os
import sys
import subprocess
import time
import webbrowser
from pathlib import Path

def main():
    # Configuration
    APP_DIR = "/home/david/Projects/Kijko/MVP/MVP_Kijko"
    PID_FILE = "/tmp/kijko-app.pid"
    NODE_BIN = "/home/david/.nvm/versions/node/v24.4.1/bin"
    NPM = f"{NODE_BIN}/npm"
    NODE = f"{NODE_BIN}/node"
    PORT = 5173
    
    print("=== Kijko Python Launcher ===")
    print(f"App Directory: {APP_DIR}")
    print(f"Node Binary: {NODE}")
    print(f"NPM Binary: {NPM}")
    
    # Change to app directory
    os.chdir(APP_DIR)
    
    # Check if binaries exist
    if not os.path.exists(NODE):
        print(f"Error: Node.js not found at {NODE}")
        print("Please check your Node.js installation")
        return 1
        
    if not os.path.exists(NPM):
        print(f"Error: NPM not found at {NPM}")
        print("Please check your NPM installation")
        return 1
    
    # Check if app is already running
    if os.path.exists(PID_FILE):
        try:
            with open(PID_FILE, 'r') as f:
                pid = int(f.read().strip())
            
            # Check if process is still running
            try:
                os.kill(pid, 0)  # Doesn't actually kill, just checks if process exists
                print(f"Kijko app is already running (PID: {pid})")
                webbrowser.open(f"http://localhost:{PORT}")
                return 0
            except OSError:
                # Process doesn't exist, remove stale PID file
                os.remove(PID_FILE)
        except (ValueError, FileNotFoundError):
            # Invalid or missing PID file
            if os.path.exists(PID_FILE):
                os.remove(PID_FILE)
    
    print("Starting Kijko app...")
    
    # Set up environment with proper NVM configuration
    env = os.environ.copy()
    env['PATH'] = f"{NODE_BIN}:{env.get('PATH', '')}"
    env['NVM_BIN'] = NODE_BIN
    env['NVM_DIR'] = "/home/david/.nvm"
    
    try:
        # Start the development server using bash with NVM sourcing
        # This ensures the Node.js environment is properly set up
        process = subprocess.Popen(
            [
                "bash", "-c",
                f"source /home/david/.nvm/nvm.sh && nvm use 24.4.1 && npm run dev"
            ],
            cwd=APP_DIR,
            env=env,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True
        )
        
        # Save the process ID
        with open(PID_FILE, 'w') as f:
            f.write(str(process.pid))
        
        print(f"Kijko app started with PID: {process.pid}")
        print(f"PID saved to {PID_FILE}")
        
        # Wait for server to start
        print("Waiting for server to start...")
        time.sleep(3)
        
        # Open browser
        print("Opening browser...")
        webbrowser.open(f"http://localhost:{PORT}")
        
        print("Kijko app is now running!")
        print("Use the close button in the app or run kill-kijko.sh to stop it.")
        
        # Monitor the process and output
        while True:
            output = process.stdout.readline()
            if output == '' and process.poll() is not None:
                break
            if output:
                print(output.strip())
        
        # Clean up PID file when process ends
        if os.path.exists(PID_FILE):
            os.remove(PID_FILE)
            
    except FileNotFoundError:
        print(f"Error: Could not execute {NPM}")
        print("Please check your Node.js/NPM installation")
        return 1
    except Exception as e:
        print(f"Error starting Kijko app: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="launch-kijko.sh">
#!/bin/bash

# Kijko App Launcher Script
# This script starts the Kijko application and saves the process ID

# Source user's profile to get full environment (including nvm)
[ -f "$HOME/.bashrc" ] && source "$HOME/.bashrc"
[ -f "$HOME/.profile" ] && source "$HOME/.profile"
[ -f "$HOME/.bash_profile" ] && source "$HOME/.bash_profile"

# Load nvm environment to access node/npm
export NVM_DIR="$HOME/.nvm"
[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"  # This loads nvm
[ -s "$NVM_DIR/bash_completion" ] && \. "$NVM_DIR/bash_completion"  # This loads nvm bash_completion

# Fallback: Set PATH directly to node installation
export PATH="$HOME/.nvm/versions/node/v24.4.1/bin:$PATH"

APP_DIR="/home/david/Projects/Kijko/MVP/MVP_Kijko"
PID_FILE="/tmp/kijko-app.pid"

# Change to app directory
cd "$APP_DIR"

# Debug: Check if npm is available
echo "Checking npm availability..."
which npm || echo "npm not found in PATH"
echo "Current PATH: $PATH"
echo "Node version: $(node --version 2>/dev/null || echo 'node not found')"
echo "NPM version: $(npm --version 2>/dev/null || echo 'npm not found')"

# Check if app is already running
if [ -f "$PID_FILE" ]; then
    if ps -p "$(cat $PID_FILE)" > /dev/null 2>&1; then
        echo "Kijko app is already running (PID: $(cat $PID_FILE))"
        # Open browser to the app
        xdg-open "http://localhost:5173" &
        exit 0
    else
        # Remove stale PID file
        rm "$PID_FILE"
    fi
fi

echo "Starting Kijko app..."

# Start the development server in background
npm run dev &
DEV_PID=$!

# Save the main process ID
echo $DEV_PID > "$PID_FILE"

echo "Kijko app started with PID: $DEV_PID"
echo "PID saved to $PID_FILE"

# Wait a moment for server to start
sleep 3

# Open browser to the app
echo "Opening browser..."
xdg-open "http://localhost:5173" &

echo "Kijko app is now running!"
echo "Use the close button in the app or run kill-kijko.sh to stop it."

# Monitor for shutdown signals in background
{
    while true; do
        # Check if PID file still exists and process is running
        if [ ! -f "$PID_FILE" ] || ! ps -p "$(cat $PID_FILE 2>/dev/null)" > /dev/null 2>&1; then
            break
        fi
        
        # Check for shutdown signal file in Downloads (where browser downloads go)
        if [ -f "/home/david/Downloads/kijko-shutdown-signal.txt" ]; then
            echo "Shutdown signal detected, stopping app..."
            rm "/home/david/Downloads/kijko-shutdown-signal.txt" 2>/dev/null
            bash "$APP_DIR/kill-kijko.sh"
            break
        fi
        
        sleep 2
    done
} &
</file>

<file path="metadata.json">
{
  "name": "Kijko Video Brief Assistant",
  "description": "A multimodal, speech-enabled Video Brief Assistant that expertly guides users through creating comprehensive Video Requirements Documents (VRDs) and managing the entire video production process.",
  "requestFramePermissions": [
    "microphone"
  ]
}
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2022",
    "experimentalDecorators": true,
    "useDefineForClassFields": false,
    "module": "ESNext",
    "lib": [
      "ES2022",
      "DOM",
      "DOM.Iterable"
    ],
    "skipLibCheck": true,
    "types": [
      "node"
    ],
    "moduleResolution": "bundler",
    "isolatedModules": true,
    "moduleDetection": "force",
    "allowJs": true,
    "jsx": "react-jsx",
    "paths": {
      "@/*": [
        "./*"
      ]
    },
    "allowImportingTsExtensions": true,
    "noEmit": true
  }
}
</file>

<file path="types.ts">
export interface UIMessage {
  id: string;
  role: 'user' | 'model';
  text: string;
  attachments: UIAttachment[];
  isStreaming?: boolean;
}

export interface UIAttachment {
  name: string;
  type: string; 
  size: number;
}

export interface Attachment extends UIAttachment {
  data: string; // base64
}

export type MessagePart = {
  text?: string;
  inlineData?: {
    mimeType: string;
    data: string; // base64
  };
};
</file>

<file path="components/Header.tsx">
import React from 'react';
import { SpeakerOnIcon, SpeakerOffIcon } from './icons/SpeakerIcons';

interface HeaderProps {
    isTtsEnabled: boolean;
    setIsTtsEnabled: (enabled: boolean) => void;
    isSpeaking: boolean;
    stopSpeech: () => void;
}

export const Header: React.FC<HeaderProps> = ({ isTtsEnabled, setIsTtsEnabled, isSpeaking, stopSpeech }) => {
    const handleToggle = () => {
        if (isSpeaking) {
            stopSpeech();
        }
        setIsTtsEnabled(!isTtsEnabled);
    };

    const handleCloseApp = () => {
        if (confirm('Are you sure you want to close Kijko? This will stop the app and free all ports.')) {
            // Create a shutdown signal file that the launcher script will detect
            const shutdownSignal = new Blob(['shutdown-requested'], { type: 'text/plain' });
            const url = URL.createObjectURL(shutdownSignal);
            const a = document.createElement('a');
            a.href = url;
            a.download = 'kijko-shutdown-signal.txt';
            a.style.display = 'none';
            document.body.appendChild(a);
            a.click();
            
            // Clean up after a short delay
            setTimeout(() => {
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
            }, 1000);
            
            // Show shutdown message and close
            setTimeout(() => {
                document.body.innerHTML = '<div style="display:flex;align-items:center;justify-content:center;height:100vh;font-family:sans-serif;background:#111;color:white;flex-direction:column;text-align:center;"><h1 style="color:#ef4444;margin-bottom:20px;">🔴 Kijko Shutting Down</h1><p style="margin-bottom:10px;">The app is being closed and all processes will be terminated.</p><p style="margin-bottom:20px;">The server should stop automatically within a few seconds.</p><p style="font-size:14px;color:#888;">You can safely close this browser tab now.</p></div>';
            }, 500);
        }
    };

  return (
    <header className="flex items-center justify-between p-4 bg-gray-900 border-b border-gray-700 shadow-md flex-shrink-0">
      <div className="flex items-center space-x-2">
        <div className="w-8 h-8 bg-indigo-500 rounded-full"></div>
        <h1 className="text-2xl font-bold text-white tracking-wider">Kijko</h1>
      </div>
      <div className="flex items-center space-x-2">
        <button 
          onClick={handleToggle}
          className={`p-2 rounded-full transition-colors duration-200 ${isTtsEnabled ? 'bg-indigo-500 hover:bg-indigo-600' : 'bg-gray-600 hover:bg-gray-500'}`}
          aria-label={isTtsEnabled ? "Disable Text-to-Speech" : "Enable Text-to-Speech"}
        >
          {isTtsEnabled ? <SpeakerOnIcon className="w-6 h-6 text-white" /> : <SpeakerOffIcon className="w-6 h-6 text-white" />}
        </button>
        <button 
          onClick={handleCloseApp}
          className="p-2 rounded-full bg-red-500 hover:bg-red-600 transition-colors duration-200"
          aria-label="Close App"
          title="Close Kijko App"
        >
          <svg className="w-6 h-6 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
          </svg>
        </button>
      </div>
    </header>
  );
};
</file>

<file path="src/components/CircularProgress.tsx">
import React from 'react';

interface CircularProgressProps {
  percentage: number;
  size?: number;
  strokeWidth?: number;
  className?: string;
}

export const CircularProgress: React.FC<CircularProgressProps> = ({ 
  percentage, 
  size = 120,
  strokeWidth = 8,
  className = ''
}) => {
  const radius = (size - strokeWidth) / 2;
  const circumference = radius * 2 * Math.PI;
  const strokeDashoffset = circumference - (percentage / 100) * circumference;

  return (
    <svg 
      width={size} 
      height={size}
      className={className}
      role="progressbar"
      aria-valuenow={percentage}
      aria-valuemin={0}
      aria-valuemax={100}
      aria-label={`Progress: ${Math.round(percentage)}%`}
    >
      {/* Background circle */}
      <circle
        cx={size / 2}
        cy={size / 2}
        r={radius}
        fill="none"
        stroke="#374151"
        strokeWidth={strokeWidth}
        opacity={0.2}
      />
      
      {/* Progress circle */}
      <circle
        cx={size / 2}
        cy={size / 2}
        r={radius}
        fill="none"
        stroke="url(#progressGradient)"
        strokeWidth={strokeWidth}
        strokeDasharray={circumference}
        strokeDashoffset={strokeDashoffset}
        strokeLinecap="round"
        transform={`rotate(-90 ${size / 2} ${size / 2})`}
        style={{
          transition: 'stroke-dashoffset 0.5s cubic-bezier(0.4, 0, 0.2, 1)',
          filter: 'drop-shadow(0 0 6px rgba(147, 51, 234, 0.4))'
        }}
      />
      
      {/* Subtle glow effect on progress arc */}
      <circle
        cx={size / 2}
        cy={size / 2}
        r={radius}
        fill="none"
        stroke="url(#progressGradient)"
        strokeWidth={strokeWidth + 2}
        strokeDasharray={circumference}
        strokeDashoffset={strokeDashoffset}
        strokeLinecap="round"
        transform={`rotate(-90 ${size / 2} ${size / 2})`}
        opacity={0.2}
        style={{
          transition: 'stroke-dashoffset 0.5s cubic-bezier(0.4, 0, 0.2, 1)',
          filter: 'blur(4px)'
        }}
      />
      
      {/* Gradient definitions */}
      <defs>
        <linearGradient id="progressGradient" x1="0%" y1="0%" x2="100%" y2="100%">
          <stop offset="0%" stopColor="#9333ea">
            <animate attributeName="stop-color" values="#9333ea;#ec4899;#9333ea" dur="3s" repeatCount="indefinite" />
          </stop>
          <stop offset="100%" stopColor="#ec4899">
            <animate attributeName="stop-color" values="#ec4899;#9333ea;#ec4899" dur="3s" repeatCount="indefinite" />
          </stop>
        </linearGradient>
      </defs>
    </svg>
  );
};
</file>

<file path="src/components/GeminiVoiceChat.tsx">
import React, { useState, useRef, useEffect } from 'react';
import { GoogleGenerativeAI } from '@google/generative-ai';

interface Voice {
  id: string;
  name: string;
  description: string;
}

// Available browser speech synthesis voices (will be populated dynamically)
const getAvailableVoices = (): Voice[] => {
  if ('speechSynthesis' in window) {
    const voices = speechSynthesis.getVoices();
    return voices.map(voice => ({
      id: voice.name,
      name: voice.name,
      description: `${voice.lang} - ${voice.localService ? 'Local' : 'Remote'}`
    }));
  }
  return [
    { id: 'default', name: 'Default', description: 'System Default' }
  ];
};

const GeminiVoiceChat: React.FC = () => {
  const [availableVoices, setAvailableVoices] = useState<Voice[]>([]);
  const [selectedVoice, setSelectedVoice] = useState<string>('');
  const [inputText, setInputText] = useState<string>('');
  const [audioUrl, setAudioUrl] = useState<string | null>(null);
  const [loading, setLoading] = useState<boolean>(false);
  const [error, setError] = useState<string | null>(null);
  const [isListening, setIsListening] = useState<boolean>(false);
  const [responseText, setResponseText] = useState<string>('');
  const audioRef = useRef<HTMLAudioElement>(null);
  const recognitionRef = useRef<any>(null);

  // Initialize Gemini AI
  const genAI = new GoogleGenerativeAI(process.env.REACT_APP_GEMINI_API_KEY);

  // Load available voices
  useEffect(() => {
    const loadVoices = () => {
      const voices = getAvailableVoices();
      setAvailableVoices(voices);
      if (voices.length > 0 && !selectedVoice) {
        setSelectedVoice(voices[0].id);
      }
    };

    // Load voices immediately
    loadVoices();

    // Also load when voices change (some browsers load them asynchronously)
    if ('speechSynthesis' in window) {
      speechSynthesis.onvoiceschanged = loadVoices;
    }

    return () => {
      if ('speechSynthesis' in window) {
        speechSynthesis.onvoiceschanged = null;
      }
    };
  }, [selectedVoice]);

  // Initialize speech recognition
  useEffect(() => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognitionRef.current = new SpeechRecognition();
      recognitionRef.current.continuous = false;
      recognitionRef.current.interimResults = false;
      recognitionRef.current.lang = 'en-US';

      recognitionRef.current.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        setInputText(transcript);
        setIsListening(false);
      };

      recognitionRef.current.onerror = (event) => {
        console.error('Speech recognition error:', event.error);
        setIsListening(false);
        setError('Speech recognition failed. Please try again.');
      };

      recognitionRef.current.onend = () => {
        setIsListening(false);
      };
    }

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, []);

  // Handle voice selection
  const handleVoiceChange = (e: React.ChangeEvent<HTMLSelectElement>) => {
    setSelectedVoice(e.target.value);
  };

  // Start speech recognition
  const startListening = () => {
    if (recognitionRef.current && !isListening) {
      setError(null);
      setIsListening(true);
      recognitionRef.current.start();
    }
  };

  // Stop speech recognition
  const stopListening = () => {
    if (recognitionRef.current && isListening) {
      recognitionRef.current.stop();
      setIsListening(false);
    }
  };

  // Convert base64 to audio blob
  const base64ToBlob = (base64Data, mimeType = 'audio/wav') => {
    const byteCharacters = atob(base64Data);
    const byteNumbers = new Array(byteCharacters.length);
    for (let i = 0; i < byteCharacters.length; i++) {
      byteNumbers[i] = byteCharacters.charCodeAt(i);
    }
    const byteArray = new Uint8Array(byteNumbers);
    return new Blob([byteArray], { type: mimeType });
  };

  // Generate audio response using Gemini Live API
  const generateAudioResponse = async (text: string) => {
    try {
      setLoading(true);
      setError(null);
      setAudioUrl(null);
      setResponseText('');

      const model = genAI.getGenerativeModel({
        model: 'gemini-2.5-flash'
      });

      // First generate text response
      const result = await model.generateContent({
        contents: [{ 
          role: 'user', 
          parts: [{ text: text }] 
        }]
      });

      const textResponse = result.response.text();
      setResponseText(textResponse);
      
      // Then convert to speech using Web Speech API
      if ('speechSynthesis' in window) {
        const utterance = new SpeechSynthesisUtterance(textResponse);
        
        // Set voice based on selection
        const voices = speechSynthesis.getVoices();
        const selectedVoiceObj = voices.find(voice => voice.name === selectedVoice) || voices[0];
        if (selectedVoiceObj) {
          utterance.voice = selectedVoiceObj;
        }
        
        // Configure speech settings
        utterance.rate = 1.0;
        utterance.pitch = 1.0;
        utterance.volume = 1.0;
        
        // Speak the response
        speechSynthesis.speak(utterance);
        
        // Mark as playing
        setAudioUrl('speech-synthesis-playing');
        
        // Clear the playing status when done
        utterance.onend = () => {
          setAudioUrl(null);
        };
      } else {
        throw new Error('Speech synthesis not supported in this browser');
      }
    } catch (err: any) {
      console.error('Gemini API error:', err);
      setError(`Failed to generate audio: ${err.message}`);
    } finally {
      setLoading(false);
    }
  };

  // Handle form submission
  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!inputText.trim()) {
      setError('Please enter some text or use voice input');
      return;
    }
    await generateAudioResponse(inputText.trim());
  };

  // Cleanup audio URLs
  useEffect(() => {
    return () => {
      if (audioUrl) {
        URL.revokeObjectURL(audioUrl);
      }
    };
  }, [audioUrl]);

  return (
    <div className="max-w-2xl mx-auto p-6 bg-white rounded-lg shadow-lg">
      <h2 className="text-2xl font-bold mb-6 text-center text-gray-800">
        Gemini Voice Chat
      </h2>

      {/* Voice Selection */}
      <div className="mb-6">
        <label className="block text-sm font-medium text-gray-700 mb-2">
          Select Voice:
        </label>
        <select 
          value={selectedVoice}
          onChange={handleVoiceChange}
          className="w-full p-3 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
        >
          {availableVoices.map((voice) => (
            <option key={voice.id} value={voice.id}>
              {voice.name} ({voice.description})
            </option>
          ))}
        </select>
      </div>

      {/* Input Form */}
      <form onSubmit={handleSubmit} className="mb-6">
        <div className="mb-4">
          <label className="block text-sm font-medium text-gray-700 mb-2">
            Message:
          </label>
          <div className="flex gap-2">
            <textarea
              value={inputText}
              onChange={(e) => setInputText(e.target.value)}
              placeholder="Type your message here..."
              rows={3}
              className="flex-1 p-3 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
            />
            <div className="flex flex-col gap-2">
              {recognitionRef.current && (
                <button
                  type="button"
                  onClick={isListening ? stopListening : startListening}
                  className={`p-3 rounded-md text-white font-medium transition-colors ${
                    isListening 
                      ? 'bg-red-500 hover:bg-red-600' 
                      : 'bg-green-500 hover:bg-green-600'
                  }`}
                >
                  {isListening ? '🛑' : '🎤'}
                </button>
              )}
            </div>
          </div>
        </div>

        <button
          type="submit"
          disabled={loading || isListening}
          className={`w-full p-3 rounded-md text-white font-medium transition-colors ${
            loading || isListening
              ? 'bg-gray-400 cursor-not-allowed'
              : 'bg-blue-500 hover:bg-blue-600'
          }`}
        >
          {loading ? 'Generating Audio...' : 'Generate Voice Response'}
        </button>
      </form>

      {/* Status Messages */}
      {isListening && (
        <div className="mb-4 p-3 bg-blue-100 border border-blue-300 rounded-md text-blue-800">
          🎤 Listening... Speak now!
        </div>
      )}

      {error && (
        <div className="mb-4 p-3 bg-red-100 border border-red-300 rounded-md text-red-800">
          {error}
        </div>
      )}

      {/* Response Display */}
      {responseText && (
        <div className="mb-4">
          <div className="p-4 bg-green-50 border border-green-300 rounded-md">
            <div className="flex items-center justify-between mb-3">
              <p className="text-green-800">
                ✅ Response generated with voice: <strong>{availableVoices.find(v => v.id === selectedVoice)?.name || selectedVoice}</strong>
              </p>
              {audioUrl === 'speech-synthesis-playing' && (
                <span className="text-blue-600 text-sm flex items-center">
                  🔊 Speaking...
                </span>
              )}
            </div>
            <div className="bg-white p-3 rounded border text-gray-800">
              <strong>Response:</strong> {responseText}
            </div>
            <div className="mt-2 text-sm text-gray-600">
              Using browser speech synthesis
            </div>
          </div>
        </div>
      )}

      {/* Instructions */}
      <div className="text-sm text-gray-600 bg-gray-50 p-4 rounded-md">
        <h3 className="font-medium mb-2">Instructions:</h3>
        <ul className="list-disc list-inside space-y-1">
          <li>Select your preferred voice from the dropdown</li>
          <li>Type your message or use the microphone button for voice input</li>
          <li>Click "Generate Voice Response" to hear Gemini's reply</li>
          <li>The audio will auto-play when ready</li>
        </ul>
      </div>
    </div>
  );
};

export default GeminiVoiceChat;
</file>

<file path="src/components/ModelSelector.tsx">
import React, { useState, useRef, useEffect } from 'react';
import { ChevronDownIcon, SparklesIcon, CpuChipIcon, BeakerIcon, PhotoIcon, RocketLaunchIcon } from '@heroicons/react/24/outline';
import { GeminiModel, GEMINI_MODELS, ModelOption } from '../types/settings';

interface ModelSelectorProps {
  value: GeminiModel;
  onChange: (model: GeminiModel) => void;
  disabled?: boolean;
  error?: string;
}

export const ModelSelector: React.FC<ModelSelectorProps> = ({
  value,
  onChange,
  disabled = false,
  error
}) => {
  const [isOpen, setIsOpen] = useState(false);
  const dropdownRef = useRef<HTMLDivElement>(null);
  const buttonRef = useRef<HTMLButtonElement>(null);

  // Close dropdown when clicking outside
  useEffect(() => {
    const handleClickOutside = (event: MouseEvent) => {
      if (
        dropdownRef.current &&
        !dropdownRef.current.contains(event.target as Node) &&
        !buttonRef.current?.contains(event.target as Node)
      ) {
        setIsOpen(false);
      }
    };

    if (isOpen) {
      document.addEventListener('mousedown', handleClickOutside);
    }

    return () => {
      document.removeEventListener('mousedown', handleClickOutside);
    };
  }, [isOpen]);

  // Get selected model info
  const selectedModel = GEMINI_MODELS.find(model => model.value === value);

  // Group models by generation and category
  const modelsByGeneration = {
    '2.5': GEMINI_MODELS.filter(model => model.generation === '2.5'),
    '2.0': GEMINI_MODELS.filter(model => model.generation === '2.0'),
    '1.5': GEMINI_MODELS.filter(model => model.generation === '1.5')
  };

  const handleSelect = (model: GeminiModel) => {
    onChange(model);
    setIsOpen(false);
  };

  const getCategoryIcon = (category: ModelOption['category']) => {
    switch (category) {
      case 'live':
        return <div className="w-4 h-4 text-red-400 flex items-center justify-center">🎤</div>;
      case 'pro':
        return <CpuChipIcon className="w-4 h-4 text-blue-400" />;
      case 'flash':
        return <SparklesIcon className="w-4 h-4 text-yellow-400" />;
      case 'flash-lite':
        return <RocketLaunchIcon className="w-4 h-4 text-green-400" />;
      case 'experimental':
        return <BeakerIcon className="w-4 h-4 text-purple-400" />;
      case 'image':
        return <PhotoIcon className="w-4 h-4 text-pink-400" />;
      default:
        return <SparklesIcon className="w-4 h-4 text-gray-400" />;
    }
  };

  const getModelTip = (category: ModelOption['category']) => {
    switch (category) {
      case 'live':
        return 'Real-time conversational AI with integrated speech-to-text, language processing, and text-to-speech streaming. Perfect for natural voice conversations.';
      case 'pro':
        return 'Best for complex reasoning, analysis, and professional tasks requiring highest quality output.';
      case 'flash':
        return 'Perfect balance of speed and quality for most conversational AI applications.';
      case 'flash-lite':
        return 'Optimized for high-throughput scenarios where speed and cost efficiency are priorities.';
      case 'experimental':
        return 'Cutting-edge features but may have stability issues. Great for testing new capabilities.';
      case 'image':
        return 'Specialized for image understanding and analysis tasks with fast processing.';
      default:
        return 'General-purpose model suitable for various AI tasks.';
    }
  };

  const GenerationSection: React.FC<{ models: ModelOption[]; generation: string }> = ({
    models,
    generation
  }) => {
    if (models.length === 0) return null;
    
    const generationLabels = {
      '2.5': '2.5 Series - Latest & Most Powerful',
      '2.0': '2.0 Series - Current Generation', 
      '1.5': '1.5 Series - Legacy Support'
    };
    
    return (
      <div>
        <div className="flex items-center gap-2 px-3 py-2 text-xs font-medium text-gray-300 bg-gray-800/50 border-b border-gray-700">
          <span className="text-purple-400 font-bold">Gemini {generation}</span>
          <span className="text-gray-500">•</span>
          <span>{generationLabels[generation as keyof typeof generationLabels]}</span>
        </div>
        {models.map((model) => (
          <button
            key={model.value}
            onClick={() => handleSelect(model.value)}
            className={`
              w-full text-left px-4 py-3 hover:bg-gray-700/50 transition-colors border-b border-gray-800/50 last:border-b-0
              ${value === model.value ? 'bg-purple-600/20 text-purple-300' : 'text-gray-200'}
            `}
          >
            <div className="flex items-start justify-between gap-3">
              <div className="flex-1 min-w-0">
                <div className="flex items-center gap-2 mb-1">
                  {getCategoryIcon(model.category)}
                  <span className="font-medium">{model.label}</span>
                  {value === model.value && (
                    <div className="w-2 h-2 bg-purple-400 rounded-full"></div>
                  )}
                </div>
                <p className="text-sm text-gray-400 mb-2 line-clamp-2">
                  {model.description}
                </p>
                <div className="flex items-center gap-3 text-xs text-gray-500">
                  <span className="flex items-center gap-1">
                    <span className="w-1 h-1 bg-yellow-400 rounded-full"></span>
                    Speed: {model.performance}
                  </span>
                  <span className="flex items-center gap-1">
                    <span className="w-1 h-1 bg-green-400 rounded-full"></span>
                    Quality: {model.quality}
                  </span>
                  {model.contextLength && (
                    <span className="flex items-center gap-1">
                      <span className="w-1 h-1 bg-blue-400 rounded-full"></span>
                      Context: {model.contextLength}
                    </span>
                  )}
                </div>
              </div>
            </div>
          </button>
        ))}
      </div>
    );
  };

  return (
    <div className="space-y-4">
      {/* Header */}
      <div>
        <h3 className="text-lg font-semibold text-white">AI Model</h3>
        <p className="text-sm text-gray-400">
          Choose the Gemini model for conversation processing
        </p>
      </div>

      {/* Error Message */}
      {error && (
        <div className="p-3 bg-red-500/10 border border-red-500/20 rounded-lg">
          <p className="text-sm text-red-400">{error}</p>
        </div>
      )}

      {/* Model Selector */}
      <div className="relative">
        <button
          ref={buttonRef}
          onClick={() => !disabled && setIsOpen(!isOpen)}
          disabled={disabled}
          className={`
            w-full flex items-center justify-between gap-3 p-4
            bg-gray-800 border border-gray-700 rounded-lg
            hover:border-gray-600 focus:border-purple-500/50 focus:ring-1 focus:ring-purple-500/20
            transition-colors
            ${disabled ? 'opacity-50 cursor-not-allowed' : 'cursor-pointer'}
            ${isOpen ? 'border-purple-500/50 ring-1 ring-purple-500/20' : ''}
          `}
        >
          <div className="flex items-center gap-3 flex-1 min-w-0">
            {selectedModel && getCategoryIcon(selectedModel.category)}
            <div className="flex-1 min-w-0 text-left">
              <p className="font-medium text-white truncate">
                {selectedModel?.label || 'Select Model'}
              </p>
              {selectedModel && (
                <p className="text-sm text-gray-400 truncate">
                  {selectedModel.description}
                </p>
              )}
            </div>
          </div>
          <ChevronDownIcon 
            className={`w-5 h-5 text-gray-400 transition-transform ${
              isOpen ? 'rotate-180' : ''
            }`} 
          />
        </button>

        {/* Dropdown */}
        {isOpen && (
          <div
            ref={dropdownRef}
            className="
              absolute top-full left-0 right-0 mt-2 z-50
              bg-gray-800 border border-gray-700 rounded-lg
              shadow-xl shadow-black/20
              max-h-96 overflow-y-auto
            "
          >
            {Object.entries(modelsByGeneration).map(([generation, models]) => (
              <GenerationSection
                key={generation}
                models={models}
                generation={generation}
              />
            ))}
          </div>
        )}
      </div>

      {/* Model Information */}
      {selectedModel && (
        <div className="p-4 bg-gray-800/50 border border-gray-700 rounded-lg">
          <div className="flex items-center gap-3 mb-3">
            {getCategoryIcon(selectedModel.category)}
            <div>
              <span className="text-sm font-medium text-white block">
                Gemini {selectedModel.generation} • {selectedModel.category.charAt(0).toUpperCase() + selectedModel.category.slice(1).replace('-', ' ')}
              </span>
              <span className="text-xs text-gray-400">
                Performance: {selectedModel.performance} • Quality: {selectedModel.quality}
              </span>
            </div>
          </div>
          
          <div className="grid grid-cols-2 gap-3 text-xs">
            <div className="bg-gray-700/30 rounded p-2">
              <span className="text-gray-400 block">Speed</span>
              <span className="text-white font-medium">{selectedModel.performance}</span>
            </div>
            <div className="bg-gray-700/30 rounded p-2">
              <span className="text-gray-400 block">Quality</span>
              <span className="text-white font-medium">{selectedModel.quality}</span>
            </div>
            {selectedModel.contextLength && (
              <div className="bg-gray-700/30 rounded p-2 col-span-2">
                <span className="text-gray-400 block">Context Length</span>
                <span className="text-white font-medium">{selectedModel.contextLength}</span>
              </div>
            )}
          </div>
          
          <div className="mt-3 p-2 bg-blue-500/10 border border-blue-500/20 rounded text-xs text-blue-200">
            <strong>💡 Tip:</strong> {getModelTip(selectedModel.category)}
          </div>
        </div>
      )}
    </div>
  );
};
</file>

<file path="src/contexts/SettingsContext.tsx">
import React, { createContext, useContext, useReducer, useEffect, ReactNode } from 'react';
import { AppSettings, SettingsAction, GeminiModel } from '../types/settings';
import { loadSettings, saveSettings, resetSettings } from '../utils/settingsStorage';

// Settings reducer
const settingsReducer = (state: AppSettings, action: SettingsAction): AppSettings => {
  switch (action.type) {
    case 'SET_SYSTEM_PROMPT':
      return {
        ...state,
        systemPrompt: action.payload
      };
    
    case 'SET_MODEL':
      return {
        ...state,
        selectedModel: action.payload
      };
    
    case 'LOAD_SETTINGS':
      return action.payload;
    
    case 'RESET_TO_DEFAULTS':
      return resetSettings();
    
    default:
      return state;
  }
};

// Context interface
interface SettingsContextType {
  settings: AppSettings;
  updateSystemPrompt: (prompt: string) => Promise<boolean>;
  updateModel: (model: GeminiModel) => Promise<boolean>;
  updateSettings: (newSettings: AppSettings) => Promise<boolean>;
  resetToDefaults: () => Promise<boolean>;
  isLoading: boolean;
}

// Create context
const SettingsContext = createContext<SettingsContextType | undefined>(undefined);

// Provider props
interface SettingsProviderProps {
  children: ReactNode;
}

// Provider component
export const SettingsProvider: React.FC<SettingsProviderProps> = ({ children }) => {
  const [settings, dispatch] = useReducer(settingsReducer, loadSettings());
  const [isLoading, setIsLoading] = React.useState(false);

  // Load settings on mount
  useEffect(() => {
    const loadInitialSettings = async () => {
      setIsLoading(true);
      try {
        const loadedSettings = loadSettings();
        dispatch({ type: 'LOAD_SETTINGS', payload: loadedSettings });
      } catch (error) {
        console.error('Failed to load initial settings:', error);
      } finally {
        setIsLoading(false);
      }
    };

    loadInitialSettings();
  }, []);

  // Note: Auto-save removed - settings are only saved when user explicitly clicks Save

  // Context value methods
  const updateSystemPrompt = async (prompt: string): Promise<boolean> => {
    try {
      const newSettings = { ...settings, systemPrompt: prompt };
      const saved = saveSettings(newSettings);
      
      if (saved) {
        dispatch({ type: 'SET_SYSTEM_PROMPT', payload: prompt });
        return true;
      }
      return false;
    } catch (error) {
      console.error('Failed to update system prompt:', error);
      return false;
    }
  };

  const updateModel = async (model: GeminiModel): Promise<boolean> => {
    try {
      const newSettings = { ...settings, selectedModel: model };
      const saved = saveSettings(newSettings);
      
      if (saved) {
        dispatch({ type: 'SET_MODEL', payload: model });
        return true;
      }
      return false;
    } catch (error) {
      console.error('Failed to update model:', error);
      return false;
    }
  };

  const updateSettings = async (newSettings: AppSettings): Promise<boolean> => {
    try {
      const saved = saveSettings(newSettings);
      
      if (saved) {
        dispatch({ type: 'LOAD_SETTINGS', payload: newSettings });
        return true;
      }
      return false;
    } catch (error) {
      console.error('Failed to update settings:', error);
      return false;
    }
  };

  const resetToDefaults = async (): Promise<boolean> => {
    try {
      const defaultSettings = resetSettings();
      dispatch({ type: 'RESET_TO_DEFAULTS' });
      return true;
    } catch (error) {
      console.error('Failed to reset settings:', error);
      return false;
    }
  };

  const contextValue: SettingsContextType = {
    settings,
    updateSystemPrompt,
    updateModel,
    updateSettings,
    resetToDefaults,
    isLoading
  };

  return (
    <SettingsContext.Provider value={contextValue}>
      {children}
    </SettingsContext.Provider>
  );
};

// Hook to use settings context
export const useSettings = (): SettingsContextType => {
  const context = useContext(SettingsContext);
  
  if (context === undefined) {
    throw new Error('useSettings must be used within a SettingsProvider');
  }
  
  return context;
};
</file>

<file path="src/types/settings.ts">
export type GeminiModel = 
  // Live Real-Time Models (Experimental)
  | 'gemini-live-2.5-flash-preview-native-audio-09-2025'
  // Latest 2.5 Series (Most Powerful)
  | 'gemini-2.5-pro'
  | 'gemini-2.5-flash'
  | 'gemini-2.5-flash-lite'
  | 'gemini-2.5-flash-image'
  // 2.0 Series (Current Generation)
  | 'gemini-2.0-flash'
  | 'gemini-2.0-flash-lite'
  | 'gemini-2.0-flash-experimental'
  // Legacy 1.5 Series
  | 'gemini-1.5-pro'
  | 'gemini-1.5-flash'
  | 'gemini-1.5-flash-8b';

export interface ModelOption {
  value: GeminiModel;
  label: string;
  description: string;
  category: 'live' | 'pro' | 'flash' | 'flash-lite' | 'experimental' | 'image';
  generation: '1.5' | '2.0' | '2.5';
  contextLength?: string;
  performance: 'fastest' | 'fast' | 'medium' | 'high';
  quality: 'medium' | 'high' | 'very-high' | 'highest';
}

export const GEMINI_MODELS: ModelOption[] = [
  // Live Real-Time Models - Experimental
  {
    value: 'gemini-live-2.5-flash-preview-native-audio-09-2025',
    label: 'Gemini Live 2.5 Flash Native Audio',
    description: 'Real-time native audio conversational AI with ultra-low latency',
    category: 'live',
    generation: '2.5',
    contextLength: '1M+ tokens',
    performance: 'fastest',
    quality: 'high'
  },
  // Latest 2.5 Series - Most Powerful
  {
    value: 'gemini-2.5-pro',
    label: 'Gemini 2.5 Pro',
    description: 'Most powerful model with premium reasoning and extended context',
    category: 'pro',
    generation: '2.5',
    contextLength: '2M+ tokens',
    performance: 'medium',
    quality: 'highest'
  },
  {
    value: 'gemini-2.5-flash',
    label: 'Gemini 2.5 Flash',
    description: 'Latest fast model with improved cost and performance',
    category: 'flash',
    generation: '2.5',
    contextLength: '1M+ tokens',
    performance: 'fast',
    quality: 'high'
  },
  {
    value: 'gemini-2.5-flash-lite',
    label: 'Gemini 2.5 Flash Lite',
    description: 'Ultra-light model for maximum speed and economy',
    category: 'flash-lite',
    generation: '2.5',
    contextLength: '~1M tokens',
    performance: 'fastest',
    quality: 'medium'
  },
  {
    value: 'gemini-2.5-flash-image',
    label: 'Gemini 2.5 Flash Image',
    description: 'Specialized for high-speed image understanding tasks',
    category: 'image',
    generation: '2.5',
    performance: 'fast',
    quality: 'high'
  },
  
  // 2.0 Series - Current Generation
  {
    value: 'gemini-2.0-flash',
    label: 'Gemini 2.0 Flash',
    description: 'Fully multimodal with enhanced spatial and video understanding',
    category: 'flash',
    generation: '2.0',
    contextLength: '1-2M+ tokens',
    performance: 'fast',
    quality: 'high'
  },
  {
    value: 'gemini-2.0-flash-lite',
    label: 'Gemini 2.0 Flash Lite',
    description: 'Optimized for maximum speed with some quality trade-offs',
    category: 'flash-lite',
    generation: '2.0',
    contextLength: '~512K tokens',
    performance: 'fastest',
    quality: 'medium'
  },
  {
    value: 'gemini-2.0-flash-experimental',
    label: 'Gemini 2.0 Flash (Experimental)',
    description: 'Cutting-edge features with live multimodal API and agentic functions',
    category: 'experimental',
    generation: '2.0',
    contextLength: '1M+ tokens',
    performance: 'fast',
    quality: 'high'
  },
  
  // Legacy 1.5 Series - Still Supported
  {
    value: 'gemini-1.5-pro',
    label: 'Gemini 1.5 Pro',
    description: 'Large-scale context with strong reasoning (legacy)',
    category: 'pro',
    generation: '1.5',
    contextLength: 'Up to 1M tokens',
    performance: 'medium',
    quality: 'very-high'
  },
  {
    value: 'gemini-1.5-flash',
    label: 'Gemini 1.5 Flash',
    description: 'Fast multimodal processing (legacy)',
    category: 'flash',
    generation: '1.5',
    contextLength: 'Up to 1M tokens',
    performance: 'fast',
    quality: 'high'
  },
  {
    value: 'gemini-1.5-flash-8b',
    label: 'Gemini 1.5 Flash 8B',
    description: 'Smaller, high-speed model for basic tasks (legacy)',
    category: 'flash-lite',
    generation: '1.5',
    contextLength: 'Up to 1M tokens',
    performance: 'fastest',
    quality: 'medium'
  }
];

export interface AppSettings {
  systemPrompt: string;
  selectedModel: GeminiModel;
  // Future settings will be added here
  sttModel?: string;
  ttsModel?: string;
}

export interface SettingsFormData {
  systemPrompt: string;
  selectedModel: GeminiModel;
}

export type SettingsAction =
  | { type: 'SET_SYSTEM_PROMPT'; payload: string }
  | { type: 'SET_MODEL'; payload: GeminiModel }
  | { type: 'LOAD_SETTINGS'; payload: AppSettings }
  | { type: 'RESET_TO_DEFAULTS' };

export const DEFAULT_SETTINGS: AppSettings = {
  systemPrompt: '', // Will be set from KIJKO_SYSTEM_PROMPT constant
  selectedModel: 'gemini-2.5-pro' // Use the most powerful model by default
};
</file>

<file path="src/styles.css">
/* UI Overhaul - Dark Theme Variables & Animations */
:root {
  /* Core Color Palette */
  --bg-main: #0D0D12;
  --bg-bot: #1E1E28;
  --bg-input: #1E1E28;
  --text-primary: #FFFFFF;
  --text-secondary: #FFFFFFD6;
  
  /* Gradients */
  --gradient-user: linear-gradient(135deg, #FF2DBD 0%, #7D3CFD 100%);
  --gradient-accent: linear-gradient(135deg, #CF30FF 0%, #FF2DBD 100%);
  --gradient-send: linear-gradient(135deg, #7D3CFD 0%, #FF2DBD 100%);
  
  /* Layout & Spacing */
  --radius-xl: 18px;
  --radius-lg: 14px;
  --radius-md: 12px;
  --shadow-elev: 0 2px 6px #00000080;
  --spacing-outer: 1.25rem;
  --spacing-bubble: 0.9rem 1rem;
  
  /* Animation Timings */
  --timing-fast: 150ms;
  --timing-normal: 200ms;
  --timing-slow: 300ms;
}

/* Global Styles */
body {
  background-color: var(--bg-main);
  color: var(--text-primary);
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
  margin: 0;
  padding: 0;
  overflow-x: hidden;
}

/* Custom Animations */
@keyframes bounce-dots {
  0%, 20%, 50%, 80%, 100% { transform: translateY(0); }
  40% { transform: translateY(-6px); }
  60% { transform: translateY(-3px); }
}

@keyframes slide-up {
  from {
    opacity: 0;
    transform: translateY(8px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

@keyframes scale-press {
  from { transform: scale(1); }
  to { transform: scale(0.97); }
}

@keyframes glow-pulse {
  0% { box-shadow: 0 0 0 0 rgba(125, 60, 253, 0.4); }
  70% { box-shadow: 0 0 0 8px rgba(125, 60, 253, 0); }
  100% { box-shadow: 0 0 0 0 rgba(125, 60, 253, 0); }
}

@keyframes pulse {
  0% {
    opacity: 0.3;
    transform: scale(1);
  }
  50% {
    opacity: 0.5;
    transform: scale(1.03);
  }
  100% {
    opacity: 0.3;
    transform: scale(1);
  }
}

/* Utility Classes */
.gradient-user {
  background: var(--gradient-user);
}

.gradient-accent {
  background: var(--gradient-accent);
}

.gradient-send {
  background: var(--gradient-send);
}

.animate-slide-up {
  animation: slide-up var(--timing-fast) ease-out;
}

.animate-bounce-dots {
  animation: bounce-dots 0.8s infinite;
}

.animate-scale-press {
  animation: scale-press var(--timing-fast) ease-out;
}

.animate-glow-pulse {
  animation: glow-pulse 2s infinite;
}

/* Loading Dots */
.loading-dots {
  display: flex;
  gap: 4px;
  align-items: center;
}

.loading-dots .dot {
  width: 8px;
  height: 8px;
  border-radius: 50%;
  background-color: var(--text-secondary);
  animation: bounce-dots 0.8s infinite;
}

.loading-dots .dot:nth-child(2) {
  animation-delay: 0.1s;
}

.loading-dots .dot:nth-child(3) {
  animation-delay: 0.2s;
}

/* Scrollbar Styling */
::-webkit-scrollbar {
  width: 4px;
}

::-webkit-scrollbar-track {
  background: transparent;
}

::-webkit-scrollbar-thumb {
  background: var(--text-secondary);
  border-radius: 2px;
}

::-webkit-scrollbar-thumb:hover {
  background: var(--text-primary);
}

/* Focus States */
.focus-ring {
  @apply focus:outline-none focus:ring-2 focus:ring-purple-400 focus:ring-opacity-50;
}

/* Gradient Text */
.text-gradient {
  background: var(--gradient-accent);
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  background-clip: text;
}

/* Glass Effect */
.glass {
  backdrop-filter: blur(10px);
  background: rgba(30, 30, 40, 0.7);
  border: 1px solid rgba(255, 255, 255, 0.1);
}

/* Button Hover Effects */
.btn-interactive {
  transition: all var(--timing-fast) ease;
}

.btn-interactive:hover {
  transform: translateY(-1px);
  filter: brightness(1.1);
}

.btn-interactive:active {
  transform: translateY(0) scale(0.97);
}

/* Mobile Optimizations */
@media (max-width: 640px) {
  :root {
    --spacing-outer: 1rem;
    --spacing-bubble: 0.75rem 0.875rem;
  }
}

/* High contrast for accessibility */
@media (prefers-contrast: high) {
  :root {
    --text-secondary: #FFFFFF;
    --bg-bot: #000000;
  }
}

/* Reduced motion */
@media (prefers-reduced-motion: reduce) {
  * {
    animation-duration: 0.01ms !important;
    animation-iteration-count: 1 !important;
    transition-duration: 0.01ms !important;
  }
}
</file>

<file path="src/types.ts">
export interface UIMessage {
  id: string;
  role: 'user' | 'model';
  text: string;
  attachments?: Attachment[];
  isStreaming?: boolean;
  options?: MCQOption[];
  showOptions?: boolean; // Control whether to show MCQ options
}
export interface UIAttachment {
  name: string;
  type: string; 
  size: number;
}

export interface Attachment extends UIAttachment {
  data: string; // base64
}

export type MessagePart = {
  text?: string;
  inlineData?: {
    mimeType: string;
    data: string; // base64
  };
};
</file>

<file path=".gitignore">
# Dependencies
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Production builds
dist/
build/

# Environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local

# Vite
.vite/

# Cache directories
.npm/
.yarn/
.cache/

# Runtime data
*.pid
*.log
server.log

# IDE and editor files
.vscode/
.idea/
*.swp
*.swo
*~

# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Deployment
.vercel/

# Testing
coverage/

# Temporary files
*.tmp
*.temp

# Desktop integration
/tmp/kijko-app.pid
.vercel
</file>

<file path="vercel.json">
{
  "rewrites": [
    {
      "source": "/(.*)",
      "destination": "/index.html"
    }
  ],
  "headers": [
    {
      "source": "/(.*)",
      "headers": [
        {
          "key": "Permissions-Policy",
          "value": "microphone=(self)"
        }
      ]
    }
  ]
}
</file>

<file path="api/perplexity.js">
/**
 * Vercel serverless function to proxy Perplexity API calls
 * This keeps the API key secure on the server-side and prevents exposure to the browser
 */
export default async function handler(req, res) {
  // Add CORS headers
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');
  
  // Handle preflight OPTIONS request
  if (req.method === 'OPTIONS') {
    return res.status(200).end();
  }
  
  // Only allow POST requests
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  // Get API key from environment variables (stored securely in Vercel)
  const apiKey = process.env.PERPLEXITY_API_KEY;
  
  if (!apiKey) {
    console.error('PERPLEXITY_API_KEY is not set in Vercel environment variables');
    return res.status(500).json({ error: 'Perplexity API key is not configured' });
  }

  try {
    // Extract request body with safety check
    const { model, messages, stream, max_tokens, temperature } = req.body || {};

    // Validate required fields
    if (!messages || !Array.isArray(messages)) {
      return res.status(400).json({ error: 'Messages array is required' });
    }

    // Call Perplexity API
    const response = await fetch('https://api.perplexity.ai/chat/completions', {
      method: 'POST',
      headers: {
        'Accept': 'application/json',
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model: model || 'pplx-7b-online',
        messages,
        stream: stream || false,
        max_tokens: max_tokens || 1024,
        temperature: temperature || 0.2,
      }),
    });

    // Get response data
    const data = await response.json();

    // Return response with same status code
    if (!response.ok) {
      console.error('Perplexity API error:', data);
      return res.status(response.status).json(data);
    }

    return res.status(200).json(data);
    
  } catch (error) {
    console.error('Error in Perplexity serverless function:', error);
    return res.status(500).json({ 
      error: 'Internal server error',
      message: error.message 
    });
  }
}
</file>

<file path="src/components/ProgressIndicator.tsx">
import React, { useEffect, useState } from 'react';
import { CircularProgress } from './CircularProgress';

interface ProgressIndicatorProps {
  currentStep: number;
  totalSteps: number;
  currentStepLabel: string;
  nextStepLabel?: string;
  percentage: number;
  isVisible?: boolean;
}

export const ProgressIndicator: React.FC<ProgressIndicatorProps> = ({
  currentStep,
  totalSteps,
  currentStepLabel,
  nextStepLabel,
  percentage,
  isVisible = true
}) => {
  const [isAnimating, setIsAnimating] = useState(false);
  const [isMobile, setIsMobile] = useState(false);

  useEffect(() => {
    // Trigger animation on percentage change
    setIsAnimating(true);
    const timer = setTimeout(() => setIsAnimating(false), 500);
    return () => clearTimeout(timer);
  }, [percentage]);

  useEffect(() => {
    // Check for mobile screen size
    const checkMobile = () => {
      setIsMobile(window.innerWidth < 768);
    };
    checkMobile();
    window.addEventListener('resize', checkMobile);
    return () => window.removeEventListener('resize', checkMobile);
  }, []);

  if (!isVisible) return null;

  const progressSize = isMobile ? 60 : 80;
  // Add 10% of diameter as top offset: 8px for 80px desktop, 6px for 60px mobile
  const topOffset = isMobile ? 'top-[76px]' : 'top-24';
  
  const containerClasses = `
    fixed z-50 
    ${topOffset} right-4 lg:right-6
    flex flex-col items-center gap-2
    transition-all duration-300 ease-out
    ${isAnimating ? 'scale-105' : 'scale-100'}
  `;

  return (
    <div className={containerClasses}>
      {/* Progress Ring */}
      <div className="relative">
        <CircularProgress 
          percentage={percentage} 
          size={progressSize}
          strokeWidth={isMobile ? 6 : 8}
        />
        
        {/* Center Content */}
        <div className="absolute inset-0 flex flex-col items-center justify-center">
          <span className={`${isMobile ? 'text-sm' : 'text-lg'} font-bold text-white drop-shadow-lg`}>
            {Math.round(percentage)}%
          </span>
          <span className="text-[10px] text-gray-300 font-medium drop-shadow">
            {currentStep}/{totalSteps}
          </span>
        </div>
      </div>
      
      {/* Step Labels - Show below the ring, smaller on mobile */}
      <div className={`text-center space-y-1 ${isMobile ? 'max-w-[80px]' : 'max-w-[120px]'} mt-2`}>
        {/* Current Step */}
        <div className="animate-slide-up">
          <p className={`${isMobile ? 'text-[9px]' : 'text-[10px]'} text-gray-400 uppercase tracking-wider font-medium`}>
            Current
          </p>
          <p className={`${isMobile ? 'text-[10px]' : 'text-xs'} font-semibold text-gray-200 truncate drop-shadow`}>
            {currentStepLabel}
          </p>
        </div>
        
        {/* Next Step - Only show if not on last step and on desktop */}
        {!isMobile && nextStepLabel && percentage < 90 && (
          <div className="animate-slide-up" style={{ animationDelay: '0.1s' }}>
            <p className="text-[10px] text-gray-500 uppercase tracking-wider font-medium">
              Next
            </p>
            <p className="text-xs text-gray-400 truncate">
              {nextStepLabel}
            </p>
          </div>
        )}
      </div>
      
      {/* Visual indicator dots for steps */}
      <div className={`flex gap-1 ${isMobile ? 'mt-1' : 'mt-1'}`}>
        {Array.from({ length: totalSteps }, (_, i) => (
          <div
            key={i}
            className={`
              ${isMobile ? 'h-[3px]' : 'h-1'} transition-all duration-300
              ${i < currentStep 
                ? `${isMobile ? 'w-1.5' : 'w-2'} bg-gradient-to-r from-purple-500 to-pink-500 opacity-80` 
                : i === currentStep
                  ? `${isMobile ? 'w-3' : 'w-4'} bg-gradient-to-r from-purple-400 to-pink-400 animate-pulse`
                  : `${isMobile ? 'w-[3px]' : 'w-1'} bg-gray-600 opacity-50`
              }
              rounded-full
            `}
          />
        ))}
      </div>
    </div>
  );
};
</file>

<file path="src/services/geminiService.ts">
import { GoogleGenAI, Chat, GenerateContentResponse } from "@google/genai";
import { KIJKO_SYSTEM_PROMPT } from '../constants';
import { Attachment, MessagePart } from '../types';
import { GeminiModel } from '../types/settings';

// Get API keys with fallback support
const getApiKeys = () => {
  const keys = [
    process.env.GEMINI_API_KEY || process.env.API_KEY,
    process.env.GEMINI_API_KEY_BACKUP_1,
    process.env.GEMINI_API_KEY_BACKUP_2
  ].filter(Boolean);
  
  if (keys.length === 0) {
    throw new Error("No valid API keys found. Please set GEMINI_API_KEY environment variable");
  }
  
  return keys;
};

const apiKeys = getApiKeys();
let currentKeyIndex = 0;

// Create AI instance with current key
let ai = new GoogleGenAI({ apiKey: apiKeys[currentKeyIndex] });

// Function to switch to next API key if current one fails
const switchToNextKey = () => {
  currentKeyIndex = (currentKeyIndex + 1) % apiKeys.length;
  ai = new GoogleGenAI({ apiKey: apiKeys[currentKeyIndex] });
  console.log(`Switched to backup API key ${currentKeyIndex + 1}`);
};

/**
 * Creates a new chat instance using the traditional Gemini API (non-real-time).
 * This function is used for standard request-response interactions with Gemini models.
 * 
 * For real-time conversational AI with integrated STT/LLM/TTS, use the Gemini Live API
 * via the useGeminiLive hook instead.
 * 
 * @param model - The Gemini model to use (defaults to 'gemini-2.5-flash')
 * @param systemPrompt - Optional system prompt for the chat session
 * @returns A Chat instance for traditional message streaming
 */
export function startKijkoChat(model?: GeminiModel, systemPrompt?: string): Chat {
  try {
    const selectedModel = model || 'gemini-2.5-flash';
    const selectedPrompt = systemPrompt || KIJKO_SYSTEM_PROMPT;
    
    const chat = ai.chats.create({
      model: selectedModel,
      config: {
        systemInstruction: selectedPrompt,
      },
    });
    return chat;
  } catch (error) {
    console.error('Failed to create chat with current API key:', error);
    if (apiKeys.length > 1) {
      switchToNextKey();
      return startKijkoChat(model, systemPrompt);
    }
    throw error;
  }
}

const fileToGenerativePart = (file: Attachment): MessagePart => {
  return {
    inlineData: {
      data: file.data,
      mimeType: file.type,
    },
  };
};

/**
 * Sends a message to a Gemini chat session and returns streaming responses (non-real-time).
 * This function handles traditional message-response patterns with file attachments and YouTube URL detection.
 * 
 * For real-time conversational AI with live audio streaming, use the Gemini Live API
 * via the useGeminiLive hook instead.
 * 
 * @param chat - The chat instance created by startKijkoChat
 * @param text - The message text to send
 * @param attachments - File attachments (images, videos, audio, documents)
 * @param retryCount - Internal retry counter for API key rotation
 * @param model - Optional model override
 * @param systemPrompt - Optional system prompt override
 * @returns AsyncGenerator yielding streaming response chunks
 */
export async function sendMessageToKijkoStream(
  chat: Chat, 
  text: string, 
  attachments: Attachment[],
  retryCount = 0,
  model?: GeminiModel,
  systemPrompt?: string
): Promise<AsyncGenerator<GenerateContentResponse>> {
  try {
    const parts: MessagePart[] = attachments.map(fileToGenerativePart);
    
    const youtubeRegex = /(?:https?:\/\/)?(?:www\.)?(?:youtube\.com|youtu\.be)\/(?:watch\?v=)?([\w-]{11})/;
    const ytMatch = text.match(youtubeRegex);

    let promptText = text;
    if (ytMatch) {
      promptText += `\n\n[User has provided a YouTube link for context: ${ytMatch[0]}. Please analyze the content of this video as part of your response.]`;
    }

    if (promptText.trim()) {
      parts.push({ text: promptText });
    }
    
    const result = await chat.sendMessageStream({ message: parts });
    return result;
  } catch (error) {
    console.error('Failed to send message with current API key:', error);
    
    // If we have backup keys and haven't exceeded retry attempts
    if (apiKeys.length > 1 && retryCount < apiKeys.length - 1) {
      switchToNextKey();
      // Create new chat with the new API key and same settings
      const newChat = startKijkoChat(model, systemPrompt);
      return sendMessageToKijkoStream(newChat, text, attachments, retryCount + 1, model, systemPrompt);
    }
    
    throw error;
  }
}
</file>

<file path="src/constants.ts">
export const KIJKO_SYSTEM_PROMPT = `
### Structured-Output Requirement (MANDATORY - HIGHEST PRIORITY)
When you ask a multiple-choice question, respond in **one** of the two formats below—never mix them.

1. Plain-text block:
   QUESTION: <question text>
   OPTIONS:
   1 = '<option-1>'
   2 = '<option-2>'
   3 = '<option-3>'
   ...
   END_OPTIONS
   EXPLANATION: <optional commentary>

2. JSON block:
   <begin>{
     "question": "<question text>",
     "options": ["<option-1>", "<option-2>", "<option-3>"],
     "explanation": "<optional commentary>"
   }<end>

No other text may appear before, inside, or after the block.

Example (JSON format):
<begin>{
  "question": "How clear is your current video vision?",
  "options": ["1-3: I only know I need a video", "4-7: I have some ideas", "8-10: I have detailed specs"],
  "explanation": "Your selection tailors the depth of guidance."
}<end>

You are Kijko, a multimodal, speech-enabled Video Brief Assistant that expertly guides users through creating comprehensive Video Requirements Documents (VRDs) and managing the entire video production process. You adapt your guidance level based on each user's clarity and experience, ensuring everyone—from complete beginners to seasoned professionals—can articulate and realize their video vision.

Your primary capabilities are:
1.  **Adaptive Discovery Engine**:
    *   **Vision Assessment**: Early in the conversation (within the first 3 exchanges), gauge the user's clarity level on a 1-10 scale. The prompt is: "To help me tailor our session perfectly for you, could you rate your current vision clarity on a scale of 1-10? 1 = 'I just know I need a video to achieve a business goal', 5 = 'I have a general concept and some specific ideas', 10 = 'I have detailed requirements including script, style, and technical specs'. Your answer helps me adjust my guidance level to match your needs."
    *   **Dynamic Adjustment**: Modify questioning depth and guidance based on the assessed level.
    *   **Intelligent Extraction**: Pull relevant information from vague ideas or detailed specifications.
    *   **Context Building**: Accumulate understanding through natural conversation flow.

2.  **Multi-Modal Processing**:
    *   **Language Detection**: Automatically detect and respond in the user's spoken/written language.
    *   **File Analysis**: Process images, videos, documents, and audio for context and reference. You will receive these as base64 encoded data. When a user provides a YouTube URL, analyze its content as a video reference.
    *   **Visual Understanding**: Extract style, mood, and composition from uploaded references.
    *   **Document Parsing**: Extract requirements from existing briefs, scripts, or guidelines.

3.  **VRD Generation Pipeline**:
    *   **Structured Documentation**: Create professional VRDs matching industry standards.
    *   **Component Assembly**: Build all required sections from gathered information.
    *   **Format Flexibility**: Adjust the detail level based on user needs and project scope.
    *   **Export Ready**: Generate publication-ready documents for stakeholder review when requested via the /export command.

**Conversation Framework & Questioning Strategy:**

*   **Phase 1: Initial Assessment (First 2-3 exchanges)**: Start with the opening engagement: "Hello! I'm Kijko, your video brief assistant. I'll help you create a comprehensive production plan for your video project. To get started, could you tell me about your video idea? Feel free to share as much or as little as you have in mind, and we'll build from there." Then, perform the Vision Clarity Assessment.
*   **Phase 2: Adaptive Discovery (Based on Clarity Score)**:
    *   **Low Clarity (1-3)**: Start with fundamental business questions, provide multiple-choice options, offer industry examples, use analogies, and provide heavy scaffolding with pre-filled suggestions.
    *   **Medium Clarity (4-7)**: Mix open and guided questions, probe for specifics, suggest options for uncertain areas, validate assumptions explicitly, and provide moderate guidance.
    *   **High Clarity (8-10)**: Ask direct, specific questions, focus on technical requirements, validate completeness with minimal hand-holding, and use expert-level terminology.
*   **Phase 3: Information Gathering (Core Discovery Questions adapted to clarity level)**: Cover Purpose & Goals, Audience, Message, Style & Tone, and Practical Constraints.
*   **Phase 4: Intelligent Assistance**: When the user is unclear, offer help: "I notice you might need some help with [specific aspect]. Would you like me to: A) Generate suggestions based on our conversation so far, B) Show you similar examples from other projects, C) Research best practices for your industry, D) Move on and revisit this later. Just pick a letter or describe what would help most."

**Interaction Commands (User Commands you must recognize and act upon):**
*   \`/clarity\` [1-10]: User adjusts guidance level mid-session.
*   \`/research\` [topic]: User invokes a research agent. You should perform a targeted search on the topic and provide a summary.
*   \`/example\` [type]: User requests relevant examples.
*   \`/template\` [industry]: User wants to load an industry template.
*   \`/review\`: User wants to see the current VRD draft. Summarize the collected information in the standard VRD sections.
*   \`/missing\`: User wants to know what's missing. Show incomplete sections.
*   \`/suggest\`: User wants suggestions for the current section.
*   \`/export\`: User wants the final VRD document. Present the complete VRD in a well-formatted, clean way, ready for copying.

**System Behaviors:**
*   **Progress Indicator**: Periodically, show the completion percentage of the VRD.
*   **Smart Prompts**: Offer pre-written options when detecting hesitation.
*   **Validation Loops**: Confirm your understanding of critical points.
*   **Information Display**: Use bullet points for clarity, provide inline examples, summarize periodically, and confirm before moving to new sections.


**Tone Adaptation:**
*   **Low clarity users**: Be encouraging, educational, and patient.
*   **Medium clarity users**: Be collaborative, validating, and guiding.
*   **High clarity users**: Be efficient, professional, and technical.

Your ultimate goal is to extract a professional, comprehensive VRD from any user, regardless of their initial clarity or experience level. Be adaptive, intelligent, and supportive while maintaining efficiency and professionalism.
`;
</file>

<file path="src/index.tsx">
import React from 'react';
import ReactDOM from 'react-dom/client';
import { BrowserRouter, Routes, Route } from 'react-router-dom';
import App from './App';
import MCQTestDemo from './components/MCQTestDemo';
import './styles.css';

const rootElement = document.getElementById('root');
if (!rootElement) {
  throw new Error("Could not find root element to mount to");
}

const root = ReactDOM.createRoot(rootElement);
root.render(
  <React.StrictMode>
    <BrowserRouter>
      <Routes>
        <Route path="/" element={<App />} />
        <Route path="/mcq-test" element={<MCQTestDemo />} />
      </Routes>
    </BrowserRouter>
  </React.StrictMode>
);
</file>

<file path="vite.config.ts">
import path from 'path';
import { defineConfig, loadEnv } from 'vite';

export default defineConfig(({ mode }) => {
    const env = loadEnv(mode, '.', '');
    return {
      define: {
        // Support both local development and Vercel deployment
        'process.env.API_KEY': JSON.stringify(env.GEMINI_API_KEY || process.env.GEMINI_API_KEY),
        'process.env.GEMINI_API_KEY': JSON.stringify(env.GEMINI_API_KEY || process.env.GEMINI_API_KEY),
        'process.env.GEMINI_API_KEY_BACKUP_1': JSON.stringify(env.GEMINI_API_KEY_BACKUP_1 || process.env.GEMINI_API_KEY_BACKUP_1),
        'process.env.GEMINI_API_KEY_BACKUP_2': JSON.stringify(env.GEMINI_API_KEY_BACKUP_2 || process.env.GEMINI_API_KEY_BACKUP_2),
        'process.env.PERPLEXITY_API_KEY': JSON.stringify(env.PERPLEXITY_API_KEY || process.env.PERPLEXITY_API_KEY),
        'process.env.SUPABASE_URL': JSON.stringify(env.SUPABASE_URL || process.env.SUPABASE_URL),
        'process.env.SUPABASE_ANON_KEY': JSON.stringify(env.SUPABASE_ANON_KEY || process.env.SUPABASE_ANON_KEY)
      },
      resolve: {
        alias: {
          '@': path.resolve(__dirname, '.'),
        }
      }
    };
});
</file>

<file path="WARP.md">
# WARP.md

This file provides guidance to WARP (warp.dev) when working with the Chat VRD project.

## Project Overview

Chat VRD is a multimodal, speech-enabled Video Brief Assistant built with React 19, TypeScript, and Vite. It helps users create comprehensive Video Requirements Documents (VRDs) by guiding them through an adaptive discovery process using Google's Gemini AI.

### Key Features
- **Multimodal Chat Interface**: Text input with file attachments (images, videos, audio, documents)
- **Enhanced MCQ System**: Multi-select options with markdown rendering and auto-detection
- **Text-to-Speech**: Built-in speech synthesis for AI responses
- **Adaptive Discovery**: Adjusts guidance level based on user expertise (1-10 clarity scale)
- **YouTube Integration**: Automatic video URL detection and content analysis
- **Desktop Integration**: Native desktop launcher with process management

## Development Commands

### Essential Commands
```bash
# Install dependencies
npm install

# Start development server (default port 5173)
npm run dev

# Build for production
npm run build

# Preview production build
npm run preview
```

### Desktop Integration Commands
```bash
# Launch app with desktop integration
./launch-kijko.sh

# Stop all app processes and free ports
./kill-kijko.sh

# Check port usage
lsof -i :5173
```

### Environment Setup
1. Create `.env.local` file in project root
2. Add your Gemini API key: `GEMINI_API_KEY=your_api_key_here`
3. The Vite config automatically exposes this as `process.env.API_KEY` in the app

## Architecture

### Core Architecture Pattern
- **React 19** with TypeScript for type safety
- **Vite** for fast development and building
- **Component-based architecture** with clear separation of concerns
- **Service layer** for AI integration (Gemini API)
- **Custom hooks** for reusable functionality (Text-to-Speech)

### Key Architectural Concepts

#### 1. Adaptive AI System
The core innovation is the **Adaptive Discovery Engine** in `constants.ts` (KIJKO_SYSTEM_PROMPT):
- **Vision Clarity Assessment**: Rates user clarity 1-10 to adjust guidance level
- **Phase-based Conversation**: Initial Assessment → Adaptive Discovery → Information Gathering → Intelligent Assistance
- **Command System**: Special commands like `/clarity`, `/research`, `/review`, `/export` for advanced interactions

#### 2. Message Flow Architecture
```
User Input → ChatInput → App (state management) → GeminiService → Streaming Response → ChatHistory
```
- **Streaming responses** for real-time AI feedback
- **Attachment processing** converts files to base64 for AI analysis
- **YouTube URL detection** automatically analyzes video content

#### 3. Enhanced MCQ System
- **Markdown Rendering**: Uses `react-markdown` to properly display **bold** and *italic* text
- **Multi-Select Capability**: Checkbox-style options with array-based state management
- **Auto-Detection**: Intelligent detection of multi-select scenarios based on content keywords
- **Visual Indicators**: Clear checkboxes for multi-select, radio buttons for single-select
- **Accessibility**: Full ARIA support with proper roles and keyboard navigation
- **Testing Interface**: Comprehensive demo at `/mcq-test` route

#### 4. Desktop Integration System
- **Process management** via shell scripts with PID tracking
- **Port management** automatically handles 5173, 3000, 4173, 8080
- **Signal-based shutdown** using file-based communication
- **Browser automation** with `xdg-open` integration

### File Structure Significance

#### Component Architecture
- `components/`: Modular React components with single responsibilities
  - `ChatHistory.tsx`: Auto-scrolling message display
  - `ChatInput.tsx`: File upload + text input with validation
  - `EnhancedChatMessage.tsx`: Individual message rendering with MCQ integration
  - `OptionGroup.tsx`: Advanced MCQ system with multi-select and markdown support
  - `MCQTestDemo.tsx`: Comprehensive MCQ testing interface
  - `Header.tsx`: TTS controls and branding
  - `icons/`: UI icon components (SpeakerIcons, AttachmentIcon, SendIcon, FileIcons)

#### Core Services
- `services/geminiService.ts`: AI integration layer
  - Chat initialization with system prompts
  - Streaming message handling
  - File attachment processing
  - YouTube URL detection and context addition

#### Types & Configuration
- `types.ts`: TypeScript definitions for messages and attachments
- `constants.ts`: Contains the sophisticated AI system prompt (350+ lines)
- `hooks/useTextToSpeech.ts`: Web Speech API integration

### AI Integration Details

#### System Prompt Architecture
The system prompt in `constants.ts` implements:
- **Multi-phase conversation management**
- **Adaptive questioning based on user expertise**
- **Command recognition system**
- **VRD generation pipeline**
- **Tone adaptation for different user types**

#### Gemini Configuration
- Uses `gemini-2.5-flash` model
- Streaming responses for real-time feedback
- Multimodal support (text, images, video, audio)
- YouTube URL content analysis integration

## Development Patterns

### State Management
- React state with hooks (no external state management)
- Message state managed in main `App.tsx`
- Streaming state updates for real-time AI responses

### Error Handling
- Try-catch blocks around AI service calls
- User-friendly error messages
- Graceful fallbacks for TTS and file upload failures

### File Processing
- Client-side file conversion to base64
- File size limits (20MB) and count limits (5 files)
- Support for images, videos, audio, PDFs, and documents

## Desktop Integration Specifics

### Process Management
- PID tracking in `/tmp/kijko-app.pid`
- Signal file communication via `/home/david/Downloads/kijko-shutdown-signal.txt`
- Comprehensive port cleanup across common dev ports

### Desktop Shortcut
- Located at `/home/david/Desktop/Kijko.desktop`
- Categories: Development, AudioVideo, Graphics
- Automatic browser launching on startup

## Deployment Configuration

### Vercel Deployment
- Framework auto-detection for React/Vite
- Environment variables via Vercel dashboard
- Build command: `npm run build`
- Output directory: `dist/` (Vite default)

### Environment Variables Required
- `GEMINI_API_KEY`: Google Gemini API key (mark as sensitive in Vercel)

## Chat History Status

The chat history persistence exists at the service layer but is not accessible in the UI yet, and production writes are likely bypassed due to environment config.

Current implementation status:
- Database: `public.chat_sessions` and `public.messages` tables exist in Supabase with RLS enabled (policies allow users to manage their own sessions/messages).
- Writes: App attempts to create a session and write messages when Supabase is available.
- Reads: There is no UI to list previous chat sessions or load their messages.
- Config: The app uses `process.env.SUPABASE_URL` and `process.env.SUPABASE_ANON_KEY`, which do not work in a Vite React browser build. Vite requires `import.meta.env.VITE_*` variables. This likely makes Supabase unavailable in production, so no data is saved.
- Race condition: The initial welcome message is attempted to be saved using `currentChatId` immediately after setting state, so it never persists due to stale state in the `useEffect` closure.

Verified via Supabase MCP:
- Tables present with 0 rows (indicating no persisted history writes reached the DB in the targeted project).
- RLS policies present allowing authenticated users to manage their own data.

Action items to make Chat History accessible:
1) Environment variables (required)
   - Rename variables to Vite format and reference them via `import.meta.env` in code.
     - .env / Vercel:
       - VITE_SUPABASE_URL
       - VITE_SUPABASE_ANON_KEY
     - In `supabaseService.ts`:
       - `const supabaseUrl = import.meta.env.VITE_SUPABASE_URL;`
       - `const supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY;`
   - Update `.env.local.example` accordingly and add Vercel project envs.

2) Fix initialization race (should persist welcome message)
   - When creating a new chat session, use the returned `session.id` directly for the first writes instead of relying on `currentChatId` state inside the same effect.
   - Example pattern:
     - `const session = await supabaseService.createChatSession('Kijko Chat Session');`
     - `if (session) { await supabaseService.addMessage(session.id, welcomeMessage.text, 'assistant'); setCurrentChatId(session.id); }`

3) Add retrieval UI (make history accessible)
   - Add a Sessions list panel (e.g., left sidebar) that calls `supabaseService.getChatSessions()` and lets the user pick a session.
   - On session select, call `supabaseService.getMessages(sessionId)` and set `messages` in state to render past conversation.
   - Provide a “New chat” action that creates a new session and focuses input.

4) Optional quality-of-life improvements
   - Persist the last opened session ID in localStorage so the user returns to their last chat.
   - Add pagination or infinite scroll on messages if needed.
   - Add a simple search that calls `supabaseService.searchMessages(query)`.

Acceptance criteria:
- On page load, if a previous session exists, it is visible and can be opened.
- The user can explicitly switch between sessions via the UI.
- New sessions and messages persist to Supabase and are visible across reloads.
- No raw `process.env.*` usage in front-end code; only `import.meta.env.VITE_*`.

## Troubleshooting

### Common Issues
1. **Port conflicts**: Run `./kill-kijko.sh` to free all ports
2. **API key errors**: Ensure `.env.local` contains valid `GEMINI_API_KEY`
3. **Desktop launcher issues**: Check script permissions with `chmod +x launch-kijko.sh`
4. **Node/npm not found**: Scripts load nvm environment automatically

### Debugging Commands
```bash
# Check running processes
ps aux | grep kijko

# Monitor port usage
lsof -i :5173

# Test build locally
npm run build

# Test MCQ system enhancements
# Visit /mcq-test route to test multi-select and markdown rendering

# Verify environment
node --version && npm --version
```

## AI Interaction Guidelines

When working with this codebase, understand that:
- The AI system is designed for **video production consultation**
- User interactions follow a **structured conversation flow**
- The system adapts its **complexity based on user expertise**
- **Special commands** (`/clarity`, `/research`, `/export`) trigger specific behaviors
- **File attachments** are automatically analyzed as visual or document references
- **YouTube URLs** are detected and used for content analysis

## Development Notes

- Use **React 19** patterns and features
- Maintain **TypeScript strict mode** compliance
- Follow the existing **component composition** patterns
- **Streaming responses** require careful state management
- **File processing** happens client-side for privacy
- **Desktop integration** requires shell script testing on Linux

## Project Structure Consolidation

### Duplicate Files Resolution
This project has both root-level and `src/` directory structures:
- Root level: `App.tsx`, `constants.ts`, `types.ts`, `index.tsx`
- `src/` directory: Contains duplicates/alternatives

**Recommendation**: Consolidate to either root-level OR src/ structure for consistency.

### Component Organization
- Main components in `components/` directory
- Icon components in `components/icons/` subdirectory
- Custom hooks in `hooks/` directory
- Services and utilities in `services/` directory
</file>

<file path="src/components/ChatInput.tsx">
import React, { useState, useRef, useEffect } from 'react';
import { Attachment } from '../types';
import { SendIcon } from './icons/SendIcon';
import { AttachmentIcon } from './icons/AttachmentIcon';
import { XCircleIcon } from './icons/FileIcons';
import { MicrophoneIcon } from './icons/MicrophoneIcon';

interface ChatInputProps {
  onSendMessage: (text: string, attachments: Attachment[]) => void;
  isLoading: boolean;
  isListening: boolean;
  startListening: () => void;
  stopListening: () => void;
  transcript: string;
  isSttSupported: boolean;
  // Gemini Live props
  isGeminiLiveMode?: boolean;
  startGeminiLive?: () => void;
  stopGeminiLive?: () => void;
  isGeminiLiveListening?: boolean;
  isGeminiLiveSupported?: boolean;
}

const MAX_FILES = 5;
const MAX_FILE_SIZE_MB = 20;

const fileToBase64 = (file: File): Promise<string> =>
  new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.readAsDataURL(file);
    reader.onload = () => resolve((reader.result as string).split(',')[1]);
    reader.onerror = (error) => reject(error);
  });

export const ChatInput: React.FC<ChatInputProps> = ({ 
    onSendMessage, 
    isLoading, 
    isListening, 
    startListening, 
    stopListening,
    transcript,
    isSttSupported,
    // Gemini Live props
    isGeminiLiveMode = false,
    startGeminiLive,
    stopGeminiLive,
    isGeminiLiveListening = false,
    isGeminiLiveSupported = false,
}) => {
  const [text, setText] = useState('');
  const [attachments, setAttachments] = useState<Attachment[]>([]);
  const fileInputRef = useRef<HTMLInputElement>(null);
  const textAreaRef = useRef<HTMLTextAreaElement>(null);

  useEffect(() => {
    setText(transcript);
  }, [transcript]);

  // Auto-resize textarea
  useEffect(() => {
    if (textAreaRef.current) {
      textAreaRef.current.style.height = 'auto';
      textAreaRef.current.style.height = `${textAreaRef.current.scrollHeight}px`;
    }
  }, [text]);


  const handleSendMessage = () => {
    if (isLoading || (!text.trim() && attachments.length === 0)) return;
    onSendMessage(text, attachments);
    setText('');
    setAttachments([]);
  };

  const handleKeyDown = (e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSendMessage();
    }
  };

  const handleFileChange = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const files = e.target.files;
    if (!files) return;

    if (attachments.length + files.length > MAX_FILES) {
        alert(`You can only upload a maximum of ${MAX_FILES} files.`);
        return;
    }

    const newAttachments: Attachment[] = [];
    for (const file of files) {
        if (file.size > MAX_FILE_SIZE_MB * 1024 * 1024) {
            alert(`File ${file.name} is too large. Maximum size is ${MAX_FILE_SIZE_MB}MB.`);
            continue;
        }
        try {
            const data = await fileToBase64(file);
            newAttachments.push({ name: file.name, type: file.type, size: file.size, data });
        } catch (error) {
            console.error("Error converting file to base64", error);
        }
    }
    setAttachments(prev => [...prev, ...newAttachments]);
  };

  const removeAttachment = (index: number) => {
    setAttachments(prev => prev.filter((_, i) => i !== index));
  };

  const handleMicClick = () => {
      if (isGeminiLiveMode) {
          // Gemini Live mode
          if (isGeminiLiveListening) {
              stopGeminiLive?.();
          } else {
              startGeminiLive?.();
          }
      } else {
          // Traditional Web Speech API mode
          if (isListening) {
              stopListening();
          } else {
              startListening();
          }
      }
  }

  return (
    <div className="p-6 border-t border-white/10 flex-shrink-0" style={{ background: 'var(--bg-input)' }}>
      <div className="relative">
        {/* Composer Container */}
        <div className="glass rounded-2xl border border-white/10 overflow-hidden">
          {/* Attachments Preview */}
          {attachments.length > 0 && (
            <div className="p-4 border-b border-white/10">
              <div className="grid grid-cols-2 md:grid-cols-3 lg:grid-cols-4 gap-2">
                {attachments.map((file, index) => (
                  <div key={index} className="bg-gray-700/50 p-3 rounded-xl flex items-center justify-between text-sm backdrop-blur">
                    <span className="truncate text-white/90" title={file.name}>{file.name}</span>
                    <button 
                      onClick={() => removeAttachment(index)} 
                      className="ml-2 text-gray-400 hover:text-red-400 transition-colors p-1 rounded-md hover:bg-red-500/10"
                      aria-label={`Remove ${file.name}`}
                    >
                      <XCircleIcon className="w-4 h-4" />
                    </button>
                  </div>
                ))}
              </div>
            </div>
          )}
          
          {/* Input Row */}
          <div className="flex items-end p-2">
            {/* Attachment Button */}
            <button
              onClick={() => fileInputRef.current?.click()}
              className="p-3 text-gray-400 hover:text-white transition-all duration-200 rounded-lg hover:bg-white/5 focus-ring"
              aria-label="Attach files"
              title="Attach files"
            >
              <AttachmentIcon className="w-5 h-5" />
            </button>
            
            {/* Microphone Button */}
            <button
              onClick={handleMicClick}
              disabled={isGeminiLiveMode ? !isGeminiLiveSupported : !isSttSupported}
              className={`
                p-3 transition-all duration-200 rounded-lg focus-ring
                disabled:opacity-50 disabled:cursor-not-allowed
                ${(isGeminiLiveMode ? isGeminiLiveListening : isListening)
                  ? 'text-red-400 bg-red-500/10 animate-glow-pulse' 
                  : 'text-gray-400 hover:text-white hover:bg-white/5'
                }
                ${isGeminiLiveMode ? 'ring-2 ring-blue-500/30' : ''}
              `}
              aria-label={(isGeminiLiveMode ? isGeminiLiveListening : isListening) ? 'Stop listening' : 'Start listening'}
              title={
                isGeminiLiveMode 
                  ? (isGeminiLiveSupported 
                      ? (isGeminiLiveListening ? 'Stop Gemini Live conversation' : 'Start Gemini Live conversation')
                      : 'Gemini Live is not supported in your browser')
                  : (isSttSupported 
                      ? (isListening ? 'Stop listening' : 'Start listening') 
                      : 'Speech-to-text is not supported in your browser')
              }
            >
              <MicrophoneIcon className="w-5 h-5" />
            </button>
            
            {/* Hidden File Input */}
            <input
              type="file"
              multiple
              ref={fileInputRef}
              onChange={handleFileChange}
              className="hidden"
              accept="image/*,video/*,audio/*,.pdf,.doc,.docx,.txt"
            />
            
            {/* Text Input */}
            <textarea
              ref={textAreaRef}
              value={text}
              onChange={(e) => setText(e.target.value)}
              onKeyDown={handleKeyDown}
              placeholder={
                isGeminiLiveMode 
                  ? (isGeminiLiveListening ? "🎤 Live conversation..." : "Send message or start live conversation...")
                  : (isListening ? "🎤 Listening..." : "Send message...")
              }
              className={`
                flex-1 bg-transparent p-3 resize-none outline-none max-h-40
                text-white placeholder:text-gray-500
                ${(isGeminiLiveMode ? isGeminiLiveListening : isListening) ? 'placeholder:animate-pulse' : ''}
              `}
              rows={1}
              disabled={isLoading}
            />
            
            {/* Send Button */}
            <button
              onClick={handleSendMessage}
              disabled={isLoading || (!text.trim() && attachments.length === 0)}
              className={`
                p-3 rounded-xl transition-all duration-200 focus-ring
                ${isLoading || (!text.trim() && attachments.length === 0)
                  ? 'bg-gray-600/50 text-gray-400 cursor-not-allowed'
                  : 'gradient-send text-white shadow-lg btn-interactive hover:shadow-xl'
                }
              `}
              aria-label="Send message"
              title="Send message"
            >
              {isLoading ? (
                <div className="w-5 h-5 border-2 border-white border-t-transparent rounded-full animate-spin"></div>
              ) : (
                <svg className="w-5 h-5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M2.01 21L23 12 2.01 3 2 10l15 2-15 2z"/>
                </svg>
              )}
            </button>
          </div>
        </div>
      </div>
    </div>
  );
};
</file>

<file path="src/components/ChatSidebar.tsx">
import React, { useState } from 'react';
import { XMarkIcon, PlusIcon, ChatBubbleLeftIcon, DocumentTextIcon, CogIcon } from '@heroicons/react/24/outline';
import { useChat } from '../contexts/ChatContext';
import { DocumentsSidebar } from './DocumentsSidebar';
import { SettingsTab } from './SettingsTab';

interface SessionItemProps {
  session: {
    id: string;
    title?: string;
    summary?: string;
    created_at: string;
    updated_at?: string;
  };
  isActive: boolean;
  onClick: () => void;
}

const SessionItem: React.FC<SessionItemProps> = ({ session, isActive, onClick }) => {
  const formatDate = (dateStr: string) => {
    const date = new Date(dateStr);
    const now = new Date();
    const diff = now.getTime() - date.getTime();
    const days = Math.floor(diff / (1000 * 60 * 60 * 24));
    
    if (days === 0) return 'Today';
    if (days === 1) return 'Yesterday';
    if (days < 7) return `${days} days ago`;
    return date.toLocaleDateString();
  };

  return (
    <button
      onClick={onClick}
      className={`
        w-full text-left p-3 rounded-lg transition-all duration-200
        hover:bg-gray-700/50 group
        ${isActive 
          ? 'bg-gradient-to-r from-purple-600/20 to-blue-600/20 border border-purple-400/30' 
          : 'bg-gray-800/30 hover:bg-gray-700/50'
        }
      `}
    >
      <div className="flex items-start space-x-3">
        <div className="flex-shrink-0 mt-0.5">
          <ChatBubbleLeftIcon className={`w-4 h-4 ${isActive ? 'text-purple-400' : 'text-gray-400'}`} />
        </div>
        <div className="flex-1 min-w-0">
          <p className={`text-sm font-medium truncate ${isActive ? 'text-white' : 'text-gray-200'}`}>
            {session.summary || session.title || 'Untitled Chat'}
          </p>
          <p className="text-xs text-gray-400 mt-1">
            {formatDate(session.updated_at || session.created_at)}
          </p>
        </div>
      </div>
    </button>
  );
};

const LoadingSkeleton: React.FC = () => (
  <div className="space-y-3">
    {[1, 2, 3].map((i) => (
      <div key={i} className="animate-pulse">
        <div className="flex items-start space-x-3 p-3 rounded-lg bg-gray-800/30">
          <div className="w-4 h-4 bg-gray-600 rounded mt-0.5"></div>
          <div className="flex-1 space-y-2">
            <div className="h-4 bg-gray-600 rounded w-3/4"></div>
            <div className="h-3 bg-gray-600 rounded w-1/2"></div>
          </div>
        </div>
      </div>
    ))}
  </div>
);

type TabType = 'chat' | 'documents' | 'settings';

export const ChatSidebar: React.FC = () => {
  const {
    sidebarOpen,
    setSidebarOpen,
    currentChatId,
    sessions,
    loadingSessions,
    createNewChat,
    switchToSession,
  } = useChat();
  
  const [activeTab, setActiveTab] = useState<TabType>('chat');
  
  // DEBUG: Log sidebar render state
  console.log('[DEBUG] ChatSidebar render - sidebarOpen:', sidebarOpen);

  const handleNewChat = async () => {
    const newChatId = await createNewChat();
    if (newChatId) {
      switchToSession(newChatId);
    }
  };

  const handleSessionClick = (sessionId: string) => {
    switchToSession(sessionId);
  };

  if (!sidebarOpen) return null;

  return (
    <>
      {/* Overlay */}
      <div 
        className="fixed inset-0 bg-black/50 backdrop-blur-sm z-40 transition-opacity"
        onClick={() => setSidebarOpen(false)}
      />
      
      {/* Sidebar */}
      <div className="fixed inset-y-0 left-0 w-80 bg-gray-900/95 backdrop-blur-xl border-r border-gray-700/50 z-50 transform transition-transform duration-300 ease-in-out">
        <div className="flex flex-col h-full">
          {/* Header */}
          <div className="flex items-center justify-between p-4 border-b border-gray-700/50">
            <h2 className="text-lg font-semibold text-white">
              {activeTab === 'chat' ? 'Chat History' : activeTab === 'documents' ? 'Documents' : 'Settings'}
            </h2>
            <button
              onClick={() => setSidebarOpen(false)}
              className="p-2 rounded-lg text-gray-400 hover:text-white hover:bg-gray-700/50 transition-colors"
              aria-label="Close sidebar"
            >
              <XMarkIcon className="w-5 h-5" />
            </button>
          </div>

          {/* Tab Navigation */}
          <div className="flex border-b border-gray-700/30">
            <button
              onClick={() => setActiveTab('chat')}
              className={`
                flex-1 flex items-center justify-center gap-1 px-3 py-3
                transition-all duration-200 relative
                ${activeTab === 'chat' 
                  ? 'text-purple-400' 
                  : 'text-gray-400 hover:text-white'
                }
              `}
              role="tab"
              aria-selected={activeTab === 'chat'}
            >
              <ChatBubbleLeftIcon className="w-4 h-4" />
              <span className="text-xs font-medium">Chats</span>
              {activeTab === 'chat' && (
                <div className="absolute bottom-0 left-0 right-0 h-0.5 bg-gradient-to-r from-purple-500 to-blue-500" />
              )}
            </button>
            <button
              onClick={() => setActiveTab('documents')}
              className={`
                flex-1 flex items-center justify-center gap-1 px-3 py-3
                transition-all duration-200 relative
                ${activeTab === 'documents' 
                  ? 'text-purple-400' 
                  : 'text-gray-400 hover:text-white'
                }
              `}
              role="tab"
              aria-selected={activeTab === 'documents'}
            >
              <DocumentTextIcon className="w-4 h-4" />
              <span className="text-xs font-medium">Documents</span>
              {activeTab === 'documents' && (
                <div className="absolute bottom-0 left-0 right-0 h-0.5 bg-gradient-to-r from-purple-500 to-blue-500" />
              )}
            </button>
            <button
              onClick={() => setActiveTab('settings')}
              className={`
                flex-1 flex items-center justify-center gap-1 px-3 py-3
                transition-all duration-200 relative
                ${activeTab === 'settings' 
                  ? 'text-purple-400' 
                  : 'text-gray-400 hover:text-white'
                }
              `}
              role="tab"
              aria-selected={activeTab === 'settings'}
            >
              <CogIcon className="w-4 h-4" />
              <span className="text-xs font-medium">Settings</span>
              {activeTab === 'settings' && (
                <div className="absolute bottom-0 left-0 right-0 h-0.5 bg-gradient-to-r from-purple-500 to-blue-500" />
              )}
            </button>
          </div>

          {/* Tab Content */}
          <div className="flex-1 overflow-hidden">
            {activeTab === 'chat' ? (
              <>
                {/* New Chat Button */}
                <div className="p-4 border-b border-gray-700/30">
                  <button
                    onClick={handleNewChat}
                    className="
                      w-full flex items-center justify-center space-x-2 
                      p-3 rounded-xl font-medium text-white
                      bg-gradient-to-r from-purple-600 to-blue-600 
                      hover:from-purple-700 hover:to-blue-700 
                      active:scale-[0.98] transition-all duration-150
                      shadow-lg hover:shadow-xl
                    "
                  >
                    <PlusIcon className="w-5 h-5" />
                    <span>New Chat</span>
                  </button>
                </div>

                {/* Sessions List */}
                <div className="flex-1 overflow-y-auto p-4">
                  {loadingSessions ? (
                    <LoadingSkeleton />
                  ) : sessions.length === 0 ? (
                    <div className="flex flex-col items-center justify-center py-8 text-center">
                      <ChatBubbleLeftIcon className="w-12 h-12 text-gray-500 mb-4" />
                      <p className="text-gray-400 text-sm">No previous conversations</p>
                      <p className="text-gray-500 text-xs mt-1">Start a new chat to begin!</p>
                    </div>
                  ) : (
                    <div className="space-y-2">
                      <h3 className="text-xs font-semibold text-gray-400 uppercase tracking-wide mb-3">
                        Recent Chats
                      </h3>
                      {sessions.map((session) => (
                        <SessionItem
                          key={session.id}
                          session={session}
                          isActive={session.id === currentChatId}
                          onClick={() => handleSessionClick(session.id)}
                        />
                      ))}
                    </div>
                  )}
                </div>
              </>
            ) : activeTab === 'documents' ? (
              /* Documents Tab */
              <DocumentsSidebar />
            ) : (
              /* Settings Tab */
              <SettingsTab />
            )}
          </div>

          {/* Footer - Only show for chat tab */}
          {activeTab === 'chat' && (
            <div className="p-4 border-t border-gray-700/30">
              <p className="text-xs text-gray-500 text-center">
                Chat history is automatically saved
              </p>
            </div>
          )}
        </div>
      </div>
    </>
  );
};
</file>

<file path="src/components/SettingsTab.tsx">
import React, { useState, useEffect } from 'react';
import { useForm } from 'react-hook-form';
import { zodResolver } from '@hookform/resolvers/zod';
import { z } from 'zod';
import { CheckIcon, XMarkIcon, ExclamationTriangleIcon } from '@heroicons/react/24/outline';
import { SystemPromptEditor } from './SystemPromptEditor';
import { ModelSelector } from './ModelSelector';
import { Toast, ToastType } from './Toast';
import { useSettings } from '../contexts/SettingsContext';
import { SettingsFormData, GEMINI_MODELS } from '../types/settings';
import { KIJKO_SYSTEM_PROMPT } from '../constants';

// Validation schema
const settingsSchema = z.object({
  systemPrompt: z
    .string()
    .min(10, 'System prompt must be at least 10 characters')
    .max(50000, 'System prompt must be less than 50,000 characters'),
  selectedModel: z.enum([
    // Latest 2.5 Series
    'gemini-2.5-pro', 'gemini-2.5-flash', 'gemini-2.5-flash-lite', 'gemini-2.5-flash-image',
    // 2.0 Series 
    'gemini-2.0-flash', 'gemini-2.0-flash-lite', 'gemini-2.0-flash-experimental',
    // Legacy 1.5 Series
    'gemini-1.5-pro', 'gemini-1.5-flash', 'gemini-1.5-flash-8b'
  ])
});

export const SettingsTab: React.FC = () => {
  const { settings, updateSettings, resetToDefaults, isLoading } = useSettings();
  const [isSaving, setIsSaving] = useState(false);
  const [saveMessage, setSaveMessage] = useState<{ type: 'success' | 'error'; text: string } | null>(null);
  const [toast, setToast] = useState<{ type: ToastType; message: string; visible: boolean }>({ 
    type: 'success', 
    message: '', 
    visible: false 
  });
  const [saveSuccess, setSaveSuccess] = useState(false);

  const {
    handleSubmit,
    setValue,
    watch,
    formState: { errors, isDirty, isValid }
  } = useForm<SettingsFormData>({
    resolver: zodResolver(settingsSchema),
    defaultValues: {
      systemPrompt: settings.systemPrompt,
      selectedModel: settings.selectedModel
    },
    mode: 'onChange'
  });

  const watchedValues = watch();

  // Update form when settings change
  useEffect(() => {
    setValue('systemPrompt', settings.systemPrompt);
    setValue('selectedModel', settings.selectedModel);
  }, [settings, setValue]);

  // Clear save message after 3 seconds
  useEffect(() => {
    if (saveMessage) {
      const timer = setTimeout(() => setSaveMessage(null), 3000);
      return () => clearTimeout(timer);
    }
  }, [saveMessage]);

  const onSubmit = async (data: SettingsFormData) => {
    setIsSaving(true);
    setSaveMessage(null);

    try {
      const success = await updateSettings({
        ...settings,
        ...data
      });

      if (success) {
        setSaveSuccess(true);
        setToast({ type: 'success', message: 'Settings saved successfully! Changes will apply to new conversations.', visible: true });
        setSaveMessage({ type: 'success', text: 'Settings saved successfully!' });
        
        // Reset success animation after delay
        setTimeout(() => setSaveSuccess(false), 2000);
      } else {
        setToast({ type: 'error', message: 'Failed to save settings. Please check your input and try again.', visible: true });
        setSaveMessage({ type: 'error', text: 'Failed to save settings. Please try again.' });
      }
    } catch (error) {
      console.error('Error saving settings:', error);
      setToast({ type: 'error', message: 'An unexpected error occurred while saving settings.', visible: true });
      setSaveMessage({ type: 'error', text: 'An error occurred while saving settings.' });
    } finally {
      setIsSaving(false);
    }
  };

  const handleReset = async () => {
    if (window.confirm('Are you sure you want to reset all settings to default values? This action cannot be undone.')) {
      try {
        await resetToDefaults();
        setToast({ type: 'success', message: 'Settings have been reset to default values.', visible: true });
        setSaveMessage({ type: 'success', text: 'Settings reset to default values.' });
      } catch (error) {
        console.error('Error resetting settings:', error);
        setToast({ type: 'error', message: 'Failed to reset settings. Please try again.', visible: true });
        setSaveMessage({ type: 'error', text: 'Failed to reset settings.' });
      }
    }
  };

  const handleResetSystemPrompt = () => {
    setValue('systemPrompt', KIJKO_SYSTEM_PROMPT, { shouldDirty: true });
  };

  return (
    <div className="h-full flex flex-col">
      <div className="flex-1 overflow-y-auto p-4">
        <form id="settings-form" onSubmit={handleSubmit(onSubmit)} className="space-y-8 max-w-4xl pb-8">
        {/* Header */}
        <div className="border-b border-gray-700 pb-4">
          <h2 className="text-2xl font-bold text-white mb-2">Settings</h2>
          <p className="text-gray-400">
            Configure your Kijko assistant's behavior and model preferences.
          </p>
        </div>

        {/* Save Message */}
        {saveMessage && (
          <div className={`
            p-4 rounded-lg border flex items-center gap-3
            ${saveMessage.type === 'success' 
              ? 'bg-green-500/10 border-green-500/20 text-green-200' 
              : 'bg-red-500/10 border-red-500/20 text-red-200'
            }
          `}>
            {saveMessage.type === 'success' ? (
              <CheckIcon className="w-5 h-5 text-green-400 flex-shrink-0" />
            ) : (
              <ExclamationTriangleIcon className="w-5 h-5 text-red-400 flex-shrink-0" />
            )}
            <span className="text-sm">{saveMessage.text}</span>
          </div>
        )}

        {/* System Prompt Section */}
        <div className="bg-gray-800/30 rounded-xl p-6 border border-gray-700/50">
          <SystemPromptEditor
            value={watchedValues.systemPrompt}
            onChange={(value) => setValue('systemPrompt', value, { shouldDirty: true })}
            onReset={handleResetSystemPrompt}
            isLoading={isLoading || isSaving}
            error={errors.systemPrompt?.message}
          />
        </div>

        {/* Model Selection Section */}
        <div className="bg-gray-800/30 rounded-xl p-6 border border-gray-700/50">
          <ModelSelector
            value={watchedValues.selectedModel}
            onChange={(model) => setValue('selectedModel', model, { shouldDirty: true })}
            disabled={isLoading || isSaving}
            error={errors.selectedModel?.message}
          />
        </div>

        {/* Spacer for fixed footer */}
        <div className="h-32"></div>
        </form>
      </div>
      
      {/* Fixed Footer with Action Buttons */}
      <div className="border-t border-gray-700 bg-gray-900/95 backdrop-blur p-4">
        <div className="flex flex-col sm:flex-row gap-3 max-w-4xl">
          {/* Action Buttons */}
          <div className="flex gap-3 flex-1">
            <button
              type="submit"
              form="settings-form"
              disabled={!isDirty || !isValid || isLoading || isSaving}
              className="
                flex items-center justify-center gap-2 px-6 py-3 rounded-lg font-medium
                bg-gradient-to-r from-purple-600 to-blue-600 text-white
                hover:from-purple-700 hover:to-blue-700
                disabled:from-gray-600 disabled:to-gray-600 disabled:cursor-not-allowed
                transition-all duration-200
                flex-1 sm:flex-initial
              "
            >
              {isSaving ? (
                <>
                  <div className="w-4 h-4 border-2 border-white border-t-transparent rounded-full animate-spin"></div>
                  Saving...
                </>
              ) : saveSuccess ? (
                <>
                  <CheckIcon className="w-4 h-4 text-green-300" />
                  <span className="text-green-300">Saved!</span>
                </>
              ) : (
                <>
                  <CheckIcon className="w-4 h-4" />
                  Save Changes
                </>
              )}
            </button>

            {/* Reset to Defaults - moved from right side for better visibility */}
            <button
              type="button"
              onClick={handleReset}
              disabled={isLoading || isSaving}
              className="
                flex items-center justify-center gap-2 px-6 py-3 rounded-lg font-medium
                bg-red-600/20 text-red-400 border border-red-600/30
                hover:bg-red-600/30 hover:border-red-600/50
                disabled:bg-gray-800 disabled:text-gray-500 disabled:border-gray-700
                disabled:cursor-not-allowed
                transition-all duration-200
                flex-1 sm:flex-initial
              "
            >
              <ExclamationTriangleIcon className="w-4 h-4" />
              Reset to Defaults
            </button>
          </div>
        </div>
        
        {/* Status Info */}
        <div className="text-xs text-gray-500 space-y-1 mt-3">
          <p>• Settings are automatically saved to your browser's local storage</p>
          <p>• Changes will apply to new conversations</p>
          <p>• Current conversations will continue using previous settings</p>
        </div>
      </div>
      
      {/* Toast Notification */}
      <Toast
        message={toast.message}
        type={toast.type}
        isVisible={toast.visible}
        onClose={() => setToast(prev => ({ ...prev, visible: false }))}
      />
    </div>
  );
};
</file>

<file path="src/services/perplexityService.ts">
interface PerplexityMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

interface PerplexityResponse {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: {
    index: number;
    message: {
      role: string;
      content: string;
    };
    finish_reason: string;
  }[];
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

interface FeedbackImprovementRequest {
  systemPrompt: string;
  userQuestion: string;
  originalResponse?: string;
}

export class PerplexityService {
  private apiKey: string | undefined;
  
  constructor() {
    // For local development, check if API key is available via Vite
    // @ts-ignore
    this.apiKey = typeof process !== 'undefined' && process.env?.PERPLEXITY_API_KEY;
  }

  /**
   * Gets an improved response from Perplexity API based on user feedback
   * Uses serverless API endpoint in production, direct API in development
   */
  async getImprovedResponse(request: FeedbackImprovementRequest): Promise<string> {
    const messages: PerplexityMessage[] = [
      {
        role: 'system',
        content: `${request.systemPrompt}\n\nADDITIONAL INSTRUCTION: The user was unsatisfied with a previous response. Please provide a more comprehensive, accurate, and helpful answer to their question. Focus on being more detailed and addressing potential gaps in the original response.`
      },
      {
        role: 'user',
        content: request.userQuestion
      }
    ];

    // If original response is provided, include it for context
    if (request.originalResponse) {
      messages.push({
        role: 'assistant',
        content: request.originalResponse
      });
      messages.push({
        role: 'user',
        content: 'This response wasn\'t quite what I was looking for. Could you provide a better, more detailed answer?'
      });
    }

    try {
      let response: Response;
      
      // Check if we're in development with a local API key
      if (this.apiKey && window.location.hostname === 'localhost') {
        // Direct API call for local development
        response = await fetch('https://api.perplexity.ai/chat/completions', {
          method: 'POST',
          headers: {
            'Accept': 'application/json',
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${this.apiKey}`,
          },
          body: JSON.stringify({
            model: 'pplx-7b-online', // Use sonar-pro if available for higher quality
            stream: false,
            max_tokens: 1024,
            temperature: 0.2, // Slightly higher than 0 for more natural responses
            messages: messages
          }),
        });
      } else {
        // Call our serverless API endpoint in production
        response = await fetch('/api/perplexity', {
          method: 'POST',
          headers: {
            'Accept': 'application/json',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: 'pplx-7b-online', 
            stream: false,
            max_tokens: 1024,
            temperature: 0.2,
            messages: messages
          }),
        });
      }

      if (!response.ok) {
        const errorText = await response.text();
        console.error('Perplexity API error:', errorText);
        throw new Error(`Perplexity API request failed: ${response.status} ${response.statusText}`);
      }

      const data: PerplexityResponse = await response.json();
      
      if (!data.choices || data.choices.length === 0) {
        throw new Error('No response received from Perplexity API');
      }

      return data.choices[0].message.content.trim();
    } catch (error) {
      console.error('Error calling Perplexity API:', error);
      throw new Error('Failed to get improved response from Perplexity API');
    }
  }

  /**
   * Check if the Perplexity service is available
   */
  isAvailable(): boolean {
    // Available if we have a local API key or in production (serverless)
    return !!(this.apiKey || window.location.hostname !== 'localhost');
  }
}

// Export a singleton instance
export const perplexityService = new PerplexityService();
</file>

<file path="README.md">
# Chat VRD - Video Requirements Document Assistant

<!-- Vercel GitHub integration test - Connection test at 2025-09-19 12:59 - Ready for deployment -->

A multimodal, speech-enabled AI assistant built with React 19, TypeScript, and Vite that helps users create comprehensive Video Requirements Documents (VRDs) through an adaptive discovery process.

## 🚀 Features

- **Multimodal Chat Interface** - Text input with file attachments (images, videos, audio, documents)
- **Text-to-Speech Integration** - Built-in speech synthesis for AI responses
- **Adaptive Discovery Engine** - Adjusts guidance level based on user expertise (1-10 clarity scale)
- **YouTube Integration** - Automatic video URL detection and content analysis
- **Desktop Integration** - Native desktop launcher with process management
- **Streaming AI Responses** - Real-time responses from Google Gemini AI

## 📋 Prerequisites

- **Node.js** 18+ (recommended 20+)
- **npm** or **yarn**
- **Google Gemini API Key**

## 🛠️ Installation & Setup

### 1. Install Dependencies
```bash
npm install
```

### 2. Environment Configuration
Create a `.env.local` file in the project root:
```bash
GEMINI_API_KEY=your_gemini_api_key_here
```

### 3. Run Development Server
```bash
npm run dev
```

The app will be available at `http://localhost:5173`

## 🎯 Available Commands

### Development
```bash
npm run dev          # Start development server
npm run build        # Build for production  
npm run preview      # Preview production build
```

### Desktop Integration (Linux)
```bash
./launch-kijko.sh    # Launch app with desktop integration
./kill-kijko.sh      # Stop app and free all ports
```

## 🏗️ Architecture

### Core Stack
- **Frontend**: React 19 + TypeScript
- **Build Tool**: Vite 6.2.0
- **AI Integration**: Google Gemini API (@google/genai)
- **Speech**: Web Speech API for text-to-speech

### Key Components
- **Adaptive AI System**: 350+ line system prompt that adjusts conversation complexity
- **Streaming Interface**: Real-time AI responses with loading states
- **File Processing**: Client-side file conversion (images, videos, audio, PDFs)
- **Command System**: Special commands (`/clarity`, `/research`, `/review`, `/export`)

### File Structure
```
src/
├── components/           # React components
│   ├── ChatHistory.tsx  # Message display
│   ├── ChatInput.tsx    # Input with file uploads
│   ├── ChatMessage.tsx  # Individual messages
│   ├── Header.tsx       # TTS controls
│   └── icons/           # UI icons
├── services/
│   └── geminiService.ts # AI integration
├── hooks/
│   └── useTextToSpeech.ts # TTS functionality
├── constants.ts         # AI system prompt
└── types.ts            # TypeScript definitions
```

## 🎨 Key Features

### Adaptive Discovery Engine
The AI system rates user clarity (1-10) and adjusts its guidance:
- **Low Clarity (1-3)**: Provides scaffolding, examples, multiple-choice options
- **Medium Clarity (4-7)**: Balanced guidance with validation
- **High Clarity (8-10)**: Direct, technical questions with minimal hand-holding

### Multimodal Capabilities
- **File Support**: Images, videos, audio, PDFs, documents (max 5 files, 20MB each)
- **YouTube Analysis**: Automatic video content analysis from URLs
- **Real-time Processing**: Client-side file conversion for privacy

### Command System
Special commands trigger specific behaviors:
- `/clarity [1-10]` - Adjust guidance level
- `/research [topic]` - Research mode
- `/review` - Show current VRD draft  
- `/export` - Generate final VRD document

## 🖥️ Desktop Integration

### Process Management
- **PID Tracking**: App process saved to `/tmp/kijko-app.pid`
- **Port Management**: Automatically handles ports 5173, 3000, 4173, 8080
- **Browser Automation**: Opens in default browser automatically
- **Graceful Shutdown**: Signal-based communication for clean termination

### Desktop Shortcut
The launcher creates a desktop shortcut at `/home/david/Desktop/Kijko.desktop` with:
- Categories: Development, AudioVideo, Graphics
- Automatic browser launching
- Process monitoring

## 🚀 Deployment

### Vercel Deployment
The project is configured for Vercel deployment:

1. **Connect Repository** to Vercel
2. **Add Environment Variables** in Vercel dashboard:
   - `GEMINI_API_KEY` (mark as sensitive)
3. **Deploy** - Vercel auto-detects Vite configuration

Build settings:
- **Build Command**: `npm run build`
- **Output Directory**: `dist`
- **Framework**: Vite

## 🔧 Development

### File Processing
- Files converted to base64 client-side
- Size limits: 20MB per file, max 5 files
- Supported formats: Images, videos, audio, PDFs, documents

### State Management
- React hooks for state management
- Streaming updates for real-time AI responses
- Message history with auto-scroll

### Error Handling
- Graceful fallbacks for TTS and file upload failures
- User-friendly error messages
- Comprehensive try-catch around AI service calls

## 🎤 Text-to-Speech

The app includes built-in TTS functionality:
- **Web Speech API** integration
- **Toggle Control** in header
- **Auto-narration** of AI responses (when enabled)
- **Stop/Start Controls** for user control

## 📝 License

This project is part of the Kijko Video Brief Assistant system.

## 🔗 Related

This is the frontend component of a larger video production workflow system. For other components or enterprise features, please contact the development team.
</file>

<file path="src/contexts/ChatContext.tsx">
import React, { createContext, useContext, useState, useEffect, ReactNode } from 'react';
import { supabaseService, ChatSession } from '../services/supabaseService';

interface ChatSessionSummary extends ChatSession {
  summary?: string;
}

interface ChatContextType {
  // Sidebar state
  sidebarOpen: boolean;
  setSidebarOpen: (open: boolean) => void;
  
  // Session management
  currentChatId: string | null;
  setCurrentChatId: (id: string | null) => void;
  sessions: ChatSessionSummary[];
  setSessions: (sessions: ChatSessionSummary[]) => void;
  
  // Loading states
  loadingSessions: boolean;
  setLoadingSessions: (loading: boolean) => void;
  
  // Actions
  loadChatSessions: () => Promise<void>;
  createNewChat: () => Promise<string | null>;
  switchToSession: (sessionId: string) => void;
}

const ChatContext = createContext<ChatContextType | null>(null);

export const useChat = () => {
  const context = useContext(ChatContext);
  if (!context) {
    throw new Error('useChat must be used within a ChatProvider');
  }
  return context;
};

interface ChatProviderProps {
  children: ReactNode;
}

export const ChatProvider: React.FC<ChatProviderProps> = ({ children }) => {
  const [sidebarOpen, setSidebarOpen] = useState(false);
  const [currentChatId, setCurrentChatId] = useState<string | null>(null);
  const [sessions, setSessions] = useState<ChatSessionSummary[]>([]);
  const [loadingSessions, setLoadingSessions] = useState(false);

  // Load chat sessions from Supabase
  const loadChatSessions = async () => {
    if (!supabaseService.isAvailable()) return;
    
    setLoadingSessions(true);
    try {
      const chatSessions = await supabaseService.getChatSessions();
      
      // Add summaries to sessions (truncate title or use first message)
      const sessionsWithSummaries: ChatSessionSummary[] = chatSessions.map(session => ({
        ...session,
        summary: session.title || `Chat from ${new Date(session.created_at).toLocaleDateString()}`
      }));
      
      setSessions(sessionsWithSummaries);
    } catch (error) {
      console.error('Failed to load chat sessions:', error);
    } finally {
      setLoadingSessions(false);
    }
  };

  // Create a new chat session
  const createNewChat = async (): Promise<string | null> => {
    if (!supabaseService.isAvailable()) return null;
    
    try {
      const session = await supabaseService.createChatSession('Kijko Chat Session');
      if (session) {
        // Add to sessions list
        const newSessionWithSummary: ChatSessionSummary = {
          ...session,
          summary: session.title || `New Chat ${new Date().toLocaleDateString()}`
        };
        setSessions(prev => [newSessionWithSummary, ...prev]);
        return session.id;
      }
    } catch (error) {
      console.error('Failed to create new chat:', error);
    }
    return null;
  };

  // Switch to a specific session
  const switchToSession = (sessionId: string) => {
    setCurrentChatId(sessionId);
    setSidebarOpen(false); // Close sidebar after selection
  };

  // Initialize Supabase and load sessions on mount
  useEffect(() => {
    const initializeAndLoad = async () => {
      // Initialize Supabase auth first (anonymous sign-in if needed)
      await supabaseService.initialize();
      // Then load conversations
      await loadChatSessions();
    };
    initializeAndLoad();
  }, []);

  const value: ChatContextType = {
    sidebarOpen,
    setSidebarOpen,
    currentChatId,
    setCurrentChatId,
    sessions,
    setSessions,
    loadingSessions,
    setLoadingSessions,
    loadChatSessions,
    createNewChat,
    switchToSession,
  };

  return (
    <ChatContext.Provider value={value}>
      {children}
    </ChatContext.Provider>
  );
};
</file>

<file path="src/services/supabaseService.ts">
import { createClient, SupabaseClient } from '@supabase/supabase-js';

// Database types
export interface User {
  id: string;
  email: string;
}

export interface ChatSession {
  id: string;
  user_id: string;
  title?: string;
  created_at: string;
  updated_at?: string;
}

export interface Message {
  id: string;
  chat_id: string;
  user_id: string;
  content: string;
  role: 'user' | 'assistant';
  parent_message_id?: string;
  created_at: string;
  updated_at?: string;
}

export interface Database {
  public: {
    Tables: {
      chat_sessions: {
        Row: ChatSession;
        Insert: {
          user_id: string;
          title?: string;
          updated_at?: string;
        };
        Update: {
          title?: string;
          updated_at?: string;
        };
      };
      messages: {
        Row: Message;
        Insert: {
          chat_id: string;
          user_id: string;
          content: string;
          role: 'user' | 'assistant';
          parent_message_id?: string;
        };
        Update: {
          content?: string;
          updated_at?: string;
        };
      };
    };
  };
}

class SupabaseService {
  private client: any; // TODO: Fix Supabase types properly
  private initializePromise: Promise<any> | null = null;

  constructor() {
    const supabaseUrl = import.meta.env.VITE_SUPABASE_URL || '';
    const supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY || '';
    
    // Debug logging
    console.log('[Supabase] Initializing with URL:', supabaseUrl ? 'Set' : 'Missing');
    console.log('[Supabase] Anon key:', supabaseAnonKey ? 'Set' : 'Missing');
    
    if (!supabaseUrl || !supabaseAnonKey) {
      console.warn('Supabase configuration is missing. Chat history features will not be available.');
      this.client = null as any; // Will cause errors if used without proper config
      return;
    }

    this.client = createClient<Database>(supabaseUrl, supabaseAnonKey);
    console.log('[Supabase] Client created successfully');
  }

  /**
   * Initialize the service and ensure user authentication
   */
  async initialize(): Promise<any> {
    if (!this.client) {
      console.warn('Supabase client not configured');
      return null;
    }

    // If initialization is already in progress, return the existing promise
    if (this.initializePromise) {
      return this.initializePromise;
    }

    // Start a new initialization process
    this.initializePromise = (async () => {
      try {
        const { data: { session } } = await this.client.auth.getSession();
        if (session && session.user) {
          console.log('Using existing session for user:', session.user.id);
          return session.user;
        }

        console.log('No existing session, signing in anonymously...');
        const { data, error } = await this.client.auth.signInAnonymously();
        if (error) {
          console.error('Failed to sign in anonymously:', error);
          return null;
        }

        console.log('Signed in anonymously as:', data.user?.id);
        return data.user;
      } catch (error) {
        console.error('Failed to initialize auth:', error);
        return null;
      } finally {
        // Reset the promise after completion
        this.initializePromise = null;
      }
    })();

    return this.initializePromise;
  }

  /**
   * Get the current user
   */
  async getCurrentUser() {
    if (!this.client) return null;
    
    const { data: { session } } = await this.client.auth.getSession();
    if (session?.user) {
      return session.user;
    }
    
    // If no session, initialize to sign in anonymously
    return this.initialize();
  }

  /**
   * Sign in anonymously for demo purposes
   */
  async signInAnonymously() {
    const { data, error } = await this.client.auth.signInAnonymously();
    if (error) {
      console.error('Error signing in anonymously:', error);
      throw error;
    }
    return data.user;
  }

  /**
   * Create a new chat session
   */
  async createChatSession(title?: string): Promise<ChatSession | null> {
    const user = await this.getCurrentUser();
    if (!user) {
      console.error('No authenticated user');
      return null;
    }

    const { data, error } = await this.client
      .from('chat_sessions')
      .insert([
        { 
          user_id: user.id, 
          title: title || `Chat ${new Date().toLocaleDateString()}`,
          updated_at: new Date().toISOString()
        }
      ])
      .select()
      .single();

    if (error) {
      console.error('Error creating chat session:', error);
      return null;
    }

    return data;
  }

  /**
   * Get all chat sessions for the current user
   */
  async getChatSessions(): Promise<ChatSession[]> {
    const user = await this.getCurrentUser();
    if (!user) return [];

    const { data, error } = await this.client
      .from('chat_sessions')
      .select('*')
      .eq('user_id', user.id)
      .order('updated_at', { ascending: false });

    if (error) {
      console.error('Error fetching chat sessions:', error);
      return [];
    }

    return data || [];
  }

  /**
   * Get a specific chat session
   */
  async getChatSession(sessionId: string): Promise<ChatSession | null> {
    const { data, error } = await this.client
      .from('chat_sessions')
      .select('*')
      .eq('id', sessionId)
      .single();

    if (error) {
      console.error('Error fetching chat session:', error);
      return null;
    }

    return data;
  }

  /**
   * Update a chat session
   */
  async updateChatSession(sessionId: string, updates: Partial<ChatSession>): Promise<boolean> {
    const { error } = await this.client
      .from('chat_sessions')
      .update({
        ...updates,
        updated_at: new Date().toISOString()
      })
      .eq('id', sessionId);

    if (error) {
      console.error('Error updating chat session:', error);
      return false;
    }

    return true;
  }

  /**
   * Delete a chat session and all its messages
   */
  async deleteChatSession(sessionId: string): Promise<boolean> {
    // Delete messages first due to foreign key constraints
    const { error: messagesError } = await this.client
      .from('messages')
      .delete()
      .eq('chat_id', sessionId);

    if (messagesError) {
      console.error('Error deleting messages:', messagesError);
      return false;
    }

    // Then delete the session
    const { error: sessionError } = await this.client
      .from('chat_sessions')
      .delete()
      .eq('id', sessionId);

    if (sessionError) {
      console.error('Error deleting chat session:', sessionError);
      return false;
    }

    return true;
  }

  /**
   * Add a message to a chat session
   */
  async addMessage(
    chatId: string,
    content: string,
    role: 'user' | 'assistant',
    parentMessageId?: string
  ): Promise<Message | null> {
    const user = await this.getCurrentUser();
    if (!user) return null;

    const { data, error } = await this.client
      .from('messages')
      .insert([
        {
          chat_id: chatId,
          user_id: user.id,
          content,
          role,
          parent_message_id: parentMessageId
        }
      ])
      .select()
      .single();

    if (error) {
      console.error('Error adding message:', error);
      return null;
    }

    // Update session's updated_at timestamp
    await this.updateChatSession(chatId, {});

    return data;
  }

  /**
   * Get messages for a chat session
   */
  async getMessages(chatId: string, limit = 100): Promise<Message[]> {
    const { data, error } = await this.client
      .from('messages')
      .select('*')
      .eq('chat_id', chatId)
      .order('created_at', { ascending: true })
      .limit(limit);

    if (error) {
      console.error('Error fetching messages:', error);
      return [];
    }

    return data || [];
  }

  /**
   * Update a message (for editing functionality)
   */
  async updateMessage(messageId: string, content: string): Promise<boolean> {
    const { error } = await this.client
      .from('messages')
      .update({
        content,
        updated_at: new Date().toISOString()
      })
      .eq('id', messageId);

    if (error) {
      console.error('Error updating message:', error);
      return false;
    }

    return true;
  }

  /**
   * Delete a message
   */
  async deleteMessage(messageId: string): Promise<boolean> {
    const { error } = await this.client
      .from('messages')
      .delete()
      .eq('id', messageId);

    if (error) {
      console.error('Error deleting message:', error);
      return false;
    }

    return true;
  }

  /**
   * Get quoted message details for reply context
   */
  async getQuotedMessage(messageId: string): Promise<Message | null> {
    const { data, error } = await this.client
      .from('messages')
      .select('*')
      .eq('id', messageId)
      .single();

    if (error) {
      console.error('Error fetching quoted message:', error);
      return null;
    }

    return data;
  }

  /**
   * Search messages across all user's chat sessions
   */
  async searchMessages(query: string, limit = 50): Promise<Message[]> {
    const user = await this.getCurrentUser();
    if (!user) return [];

    const { data, error } = await this.client
      .from('messages')
      .select(`
        *,
        chat_sessions!inner(user_id)
      `)
      .eq('chat_sessions.user_id', user.id)
      .textSearch('content', query)
      .order('created_at', { ascending: false })
      .limit(limit);

    if (error) {
      console.error('Error searching messages:', error);
      return [];
    }

    return data || [];
  }

  /**
   * Check if service is properly configured
   */
  isAvailable(): boolean {
    return !!this.client;
  }

  /**
   * Get the Supabase client for advanced operations
   */
  getClient(): any {
    return this.client;
  }
}

// Export singleton instance
export const supabaseService = new SupabaseService();
</file>

<file path="src/App.tsx">
import React, { useState, useEffect, useCallback } from 'react';
import { Chat } from '@google/genai';
import { ChatHistory } from './components/ChatHistory';
import { ChatInput } from './components/ChatInput';
import { Header } from './components/Header';
import EnhancedChatMessage from './components/EnhancedChatMessage';
import { ChatSidebar } from './components/ChatSidebar';
import { ChatWindow } from './components/ChatWindow';
import { ChatProvider, useChat } from './contexts/ChatContext';
import { SettingsProvider } from './contexts/SettingsContext';
import { UIMessage, Attachment } from './types';
import { startKijkoChat, sendMessageToKijkoStream } from './services/geminiService';
import { perplexityService } from './services/perplexityService';
import { supabaseService } from './services/supabaseService';
import { useTextToSpeech } from './hooks/useTextToSpeech';
import { useSpeechToText } from './hooks/useSpeechToText';
import { MCQOption, stripMarkdownForTTS } from './utils/messageClassifier';
import { KIJKO_SYSTEM_PROMPT } from './constants';

const AppContent: React.FC = () => {
  const { isSpeaking, isTtsEnabled, setIsTtsEnabled, speak, stop: stopTts } = useTextToSpeech();


  return (
    <div className="flex flex-col h-screen" style={{ background: 'var(--bg-main)' }}>
      <Header isTtsEnabled={isTtsEnabled} setIsTtsEnabled={setIsTtsEnabled} isSpeaking={isSpeaking} stopSpeech={stopTts} />
      {/* Chat Sidebar */}
      <ChatSidebar />
      {/* Chat Window */}
      <ChatWindow 
        isTtsEnabled={isTtsEnabled}
        isSpeaking={isSpeaking}
        speak={speak}
        stopTts={stopTts}
      />
    </div>
  );
};

// Main App component with providers
const App: React.FC = () => {
  return (
    <SettingsProvider>
      <ChatProvider>
        <AppContent />
      </ChatProvider>
    </SettingsProvider>
  );
};

export default App;
</file>

<file path="src/components/Header.tsx">
import React from 'react';
import { Bars3Icon, SpeakerWaveIcon, SpeakerXMarkIcon, XMarkIcon } from '@heroicons/react/24/outline';
import { SpeakerOnIcon, SpeakerOffIcon } from './icons/SpeakerIcons';
import { useChat } from '../contexts/ChatContext';

interface HeaderProps {
    isTtsEnabled: boolean;
    setIsTtsEnabled: (enabled: boolean) => void;
    isSpeaking: boolean;
    stopSpeech: () => void;
}

export const Header: React.FC<HeaderProps> = ({ isTtsEnabled, setIsTtsEnabled, isSpeaking, stopSpeech }) => {
    const { setSidebarOpen } = useChat();
    
    const handleToggle = () => {
        if (isSpeaking) {
            stopSpeech();
        }
        setIsTtsEnabled(!isTtsEnabled);
    };
    
    const handleMenuClick = () => {
        setSidebarOpen(true);
    };

    const handleClose = () => {
        // Create shutdown signal file that the launch script monitors
        const shutdownSignal = new Blob(['shutdown'], { type: 'text/plain' });
        const url = URL.createObjectURL(shutdownSignal);
        const a = document.createElement('a');
        a.href = url;
        a.download = 'kijko-shutdown-signal.txt';
        a.style.display = 'none';
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(url);
        
        // Try to close the window (may not work in all browsers)
        setTimeout(() => {
            window.close();
        }, 1000);
    };

  return (
    <header className="flex items-center justify-between px-6 py-4 glass border-b border-white/10 flex-shrink-0">
      <div className="flex items-center space-x-3">
        {/* Menu Button */}
        <button 
          onClick={handleMenuClick}
          className="p-2 rounded-lg text-gray-400 hover:text-white transition-colors focus-ring"
          aria-label="Open chat history"
          aria-haspopup="true"
        >
          <Bars3Icon className="w-6 h-6" />
        </button>
        
        {/* App Icon with Gradient */}
        <div className="w-10 h-10 rounded-full gradient-accent flex items-center justify-center">
          <svg className="w-6 h-6 text-white" fill="currentColor" viewBox="0 0 24 24">
            <path d="M12 2L13.09 8.26L20 9L13.09 9.74L12 16L10.91 9.74L4 9L10.91 8.26L12 2Z" />
          </svg>
        </div>
        
        <div>
          <h1 className="text-xl font-bold text-gradient">Kijko</h1>
          <p className="text-sm text-gray-400">Video Brief Assistant</p>
        </div>
      </div>
      
      <div className="flex items-center space-x-2">
        {/* Text-to-Speech Toggle */}
        <button 
          onClick={handleToggle}
          className={`
            p-3 rounded-xl transition-all duration-200 btn-interactive focus-ring
            ${isTtsEnabled 
              ? 'gradient-accent text-white shadow-lg' 
              : 'bg-gray-700/50 text-gray-400 hover:text-white hover:bg-gray-600/50'
            }
            ${isSpeaking ? 'animate-glow-pulse' : ''}
          `}
          aria-label={isTtsEnabled ? "Disable Text-to-Speech" : "Enable Text-to-Speech"}
          title={isTtsEnabled ? "Disable Text-to-Speech" : "Enable Text-to-Speech"}
        >
          <div className={isSpeaking ? 'animate-bounce-dots' : ''}>
            {isTtsEnabled ? <SpeakerWaveIcon className="w-5 h-5" /> : <SpeakerXMarkIcon className="w-5 h-5" />}
          </div>
        </button>
        
        {/* Close Button */}
        <button
          onClick={handleClose}
          className="p-3 rounded-xl bg-red-500/20 text-red-400 hover:bg-red-500/30 hover:text-red-300 transition-all duration-200 btn-interactive focus-ring"
          aria-label="Close Kijko App"
          title="Close Kijko App"
        >
          <XMarkIcon className="w-5 h-5" />
        </button>
      </div>
    </header>
  );
};
</file>

<file path="src/components/OptionGroup.tsx">
import React, { useState, useCallback } from 'react';
import ReactMarkdown from 'react-markdown';
import { MCQOption } from '../utils/messageClassifier';

interface OptionGroupProps {
  options: MCQOption[];
  onSelect: (option: MCQOption) => void;
  onSubmit?: (selectedOptions: MCQOption[], openText?: string) => void;
  disabled?: boolean;
  short?: boolean;
  allowMultiple?: boolean;
  showOpenText?: boolean; // Add option to show/hide open text field
}

interface OptionButtonProps {
  option: MCQOption;
  onToggle: (option: MCQOption) => void;
  disabled?: boolean;
  selected?: boolean;
  allowMultiple?: boolean;
}

interface OptionRowProps {
  option: MCQOption;
  onToggle: (option: MCQOption) => void;
  disabled?: boolean;
  selected?: boolean;
  allowMultiple?: boolean;
}

const OptionButton: React.FC<OptionButtonProps> = ({ option, onToggle, disabled = false, selected = false, allowMultiple = false }) => {
  const [isPressed, setIsPressed] = useState(false);

  const handleClick = useCallback(() => {
    if (!disabled) {
      onToggle(option);
    }
  }, [option, onToggle, disabled]);

  const handleMouseDown = () => setIsPressed(true);
  const handleMouseUp = () => setIsPressed(false);
  const handleMouseLeave = () => setIsPressed(false);

  // Strip markdown for clean text extraction
  const stripMarkdown = (text: string) => {
    return text.replace(/\*\*([^*]+)\*\*/g, '$1').replace(/\*([^*]+)\*/g, '$1');
  };

  return (
    <button
      onClick={handleClick}
      onMouseDown={handleMouseDown}
      onMouseUp={handleMouseUp}
      onMouseLeave={handleMouseLeave}
      disabled={disabled}
      className={`
        w-full text-left px-4 py-3 rounded-xl font-medium text-white
        transition-all duration-150 ease-out
        btn-interactive focus-ring flex items-center
        ${selected 
          ? 'gradient-user shadow-lg transform scale-[0.98]' 
          : disabled 
            ? 'bg-gray-600 opacity-50 cursor-not-allowed' 
            : 'bg-gray-700 hover:bg-gray-600 active:scale-[0.97]'
        }
        ${isPressed ? 'animate-glow-pulse' : ''}
      `}
      aria-pressed={selected}
      role={allowMultiple ? 'checkbox' : 'button'}
      aria-checked={allowMultiple ? selected : undefined}
    >
      {allowMultiple && (
        <div className={`
          w-5 h-5 rounded border-2 flex items-center justify-center mr-3 flex-shrink-0
          transition-all duration-200
          ${selected 
            ? 'border-white bg-white' 
            : 'border-gray-400'
          }
        `}>
          {selected && (
            <svg className="w-3 h-3 text-gray-800" fill="currentColor" viewBox="0 0 20 20">
              <path fillRule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clipRule="evenodd" />
            </svg>
          )}
        </div>
      )}
      <div className="flex-1">
        <span className="text-sm opacity-90">{option.label}.</span>
        <span className="ml-2">
          <ReactMarkdown 
            components={{ 
              p: React.Fragment,
              strong: ({ children }) => <strong className="font-bold">{children}</strong>,
              em: ({ children }) => <em className="italic">{children}</em>
            }}
          >
            {option.text}
          </ReactMarkdown>
        </span>
      </div>
    </button>
  );
};

const OptionRow: React.FC<OptionRowProps> = ({ option, onToggle, disabled = false, selected = false, allowMultiple = false }) => {
  const handleClick = useCallback(() => {
    if (!disabled) {
      onToggle(option);
    }
  }, [option, onToggle, disabled]);

  return (
    <button
      onClick={handleClick}
      disabled={disabled}
      className={`
        w-full flex items-center justify-between p-4 rounded-lg
        transition-all duration-150 ease-out
        btn-interactive focus-ring
        ${selected 
          ? 'bg-purple-900/50 border border-purple-400' 
          : disabled 
            ? 'bg-gray-800/50 opacity-50 cursor-not-allowed' 
            : 'bg-gray-800/30 hover:bg-gray-700/50 active:scale-[0.98]'
        }
      `}
      aria-checked={selected}
      role={allowMultiple ? 'checkbox' : 'radio'}
    >
      <div className="flex items-center space-x-4 flex-1">
        <div className={`
          flex items-center justify-center w-8 h-8 rounded-full text-sm font-bold
          ${selected ? 'gradient-accent text-white' : 'bg-gray-600 text-gray-300'}
        `}>
          {option.label}
        </div>
        <span className="text-left text-white/90 flex-1">
          <ReactMarkdown 
            components={{ 
              p: React.Fragment,
              strong: ({ children }) => <strong className="font-bold">{children}</strong>,
              em: ({ children }) => <em className="italic">{children}</em>
            }}
          >
            {option.text}
          </ReactMarkdown>
        </span>
      </div>
      
      {allowMultiple ? (
        <div className={`
          w-5 h-5 rounded border-2 flex items-center justify-center
          transition-all duration-200
          ${selected 
            ? 'border-purple-400 bg-purple-400' 
            : 'border-gray-500'
          }
        `}>
          {selected && (
            <svg className="w-3 h-3 text-white" fill="currentColor" viewBox="0 0 20 20">
              <path fillRule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clipRule="evenodd" />
            </svg>
          )}
        </div>
      ) : (
        <div className={`
          w-5 h-5 rounded-full border-2 flex items-center justify-center
          transition-all duration-200
          ${selected 
            ? 'border-purple-400 bg-purple-400' 
            : 'border-gray-500'
          }
        `}>
          {selected && (
            <div className="w-2 h-2 bg-white rounded-full animate-scale-press" />
          )}
        </div>
      )}
    </button>
  );
};

// Intelligent MCQ type detection
function detectShouldAllowMultiple(
  questionText: string | undefined, 
  options: MCQOption[], 
  allowMultipleProp?: boolean
): boolean {
  // If explicitly set, use that
  if (allowMultipleProp !== undefined) return allowMultipleProp;
  
  const optionTexts = options.map(opt => opt.text.toLowerCase());
  
  // Check if all options are numbers (ratings, scales, etc) - ALWAYS single select
  const allNumbers = options.every(opt => /^\d+(\.\d+)?$/.test(opt.text.trim()));
  if (allNumbers) return false; // Numbers like 1-10 ratings are NEVER multi-select
  
  // For all non-scale questions, default to multi-select
  // This ensures users can select multiple options as per requirements
  return true; // Changed to always return true for non-scale questions
}

export const OptionGroup: React.FC<OptionGroupProps> = ({ 
  options, 
  onSelect,
  onSubmit,
  disabled = false, 
  short,
  allowMultiple = false,
  showOpenText = true // Default to showing open text for all questions
}) => {
  const [selectedOptions, setSelectedOptions] = useState<MCQOption[]>([]);
  const [isProcessing, setIsProcessing] = useState(false);
  const [openTextValue, setOpenTextValue] = useState<string>('');

  // Use intelligent detection
  const shouldAllowMultiple = detectShouldAllowMultiple(undefined, options, allowMultiple);
  
  // Check if this is a rating scale (all numbers)
  const isRatingScale = options.every(opt => /^\d+(\.\d+)?$/.test(opt.text.trim()));

  // Determine layout based on option length or explicit short prop
  const isShortLayout = short ?? options.every(option => option.text.length <= 30);

  const handleToggle = useCallback((option: MCQOption) => {
    if (disabled || isProcessing) return; // Prevent clicks during processing

    if (shouldAllowMultiple) {
      setSelectedOptions(prev => 
        prev.find(opt => opt.label === option.label)
          ? prev.filter(opt => opt.label !== option.label)
          : [...prev, option]
      );
    } else {
      // Single select behavior
      setSelectedOptions(prev => {
        const isAlreadySelected = prev.find(opt => opt.label === option.label);
        if (isAlreadySelected) {
          // Deselect if clicking the same option
          return [];
        } else {
          // Select this option
          if (isRatingScale) {
            // For rating scales, auto-submit immediately with guard
            setIsProcessing(true);
            // Format as "I choose: X" will happen in ChatWindow
            onSelect(option);
            // Keep processing state to prevent double-clicks
            setTimeout(() => {
              setIsProcessing(false);
              setSelectedOptions([]);
            }, 500);
          }
          return [option];
        }
      });
    }
  }, [disabled, shouldAllowMultiple, isRatingScale, onSelect, isProcessing]);

  const handleSubmit = useCallback(() => {
    // Allow submit if options selected OR open text provided
    if (selectedOptions.length > 0 || openTextValue.trim()) {
      setIsProcessing(true);
      
      // Combine selected options with open text
      const combinedText = [
        ...selectedOptions.map(opt => opt.text),
        ...(openTextValue.trim() ? [`Other: ${openTextValue.trim()}`] : [])
      ].join('; ');
      
      if (onSubmit) {
        onSubmit(selectedOptions, openTextValue.trim());
      } else {
        // For single callback, submit combined option with text
        const combinedOption: MCQOption = {
          label: selectedOptions.length > 0 ? selectedOptions.map(opt => opt.label).join(',') : 'custom',
          text: combinedText,
          fullText: combinedText
        };
        onSelect(combinedOption);
      }
      
      // Reset after submission
      setTimeout(() => {
        setIsProcessing(false);
        setSelectedOptions([]);
        setOpenTextValue('');
      }, 150);
    }
  }, [selectedOptions, openTextValue, onSelect, onSubmit]);

  // Check if we should show the submit button
  const canSubmit = selectedOptions.length > 0 || openTextValue.trim().length > 0;
  const showSubmitButton = shouldAllowMultiple || (!isRatingScale && canSubmit);

  return (
    <div className="mt-4 space-y-3 animate-slide-up">
      {shouldAllowMultiple && !isRatingScale && (
        <div className="text-sm text-gray-400 mb-3 flex items-center">
          <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 20 20">
            <path fillRule="evenodd" d="M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7-4a1 1 0 11-2 0 1 1 0 012 0zM9 9a1 1 0 000 2v3a1 1 0 001 1h1a1 1 0 100-2v-3a1 1 0 00-1-1H9z" clipRule="evenodd" />
          </svg>
          Select all that apply, or enter your own answer below
        </div>
      )}
      
      {isShortLayout ? (
        // Short layout: Full-width gradient buttons
        <div className="space-y-2">
          {options.map((option) => (
            <OptionButton
              key={option.label}
              option={option}
              onToggle={handleToggle}
              disabled={disabled}
              selected={selectedOptions.some(opt => opt.label === option.label)}
              allowMultiple={shouldAllowMultiple}
            />
          ))}
        </div>
      ) : (
        // Long layout: Vertical list with checkboxes/radio buttons
        <div className="space-y-3" role={shouldAllowMultiple ? 'group' : 'radiogroup'} aria-label="Multiple choice options">
          {options.map((option) => (
            <OptionRow
              key={option.label}
              option={option}
              onToggle={handleToggle}
              disabled={disabled}
              selected={selectedOptions.some(opt => opt.label === option.label)}
              allowMultiple={shouldAllowMultiple}
            />
          ))}
        </div>
      )}
      
      {/* Open-ended text input for all non-scale questions */}
      {showOpenText && !isRatingScale && (
        <div className="pt-2">
          <label className="block text-sm text-gray-400 mb-2">
            <span className="flex items-center">
              <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 20 20">
                <path fillRule="evenodd" d="M18 13V5a2 2 0 00-2-2H4a2 2 0 00-2 2v8a2 2 0 002 2h3l3 3 3-3h3a2 2 0 002-2zM5 7a1 1 0 011-1h8a1 1 0 110 2H6a1 1 0 01-1-1zm1 3a1 1 0 100 2h3a1 1 0 100-2H6z" clipRule="evenodd" />
              </svg>
              Or provide your own answer (optional):
            </span>
          </label>
          <textarea
            value={openTextValue}
            onChange={(e) => setOpenTextValue(e.target.value)}
            placeholder="Type your answer here..."
            disabled={disabled || isProcessing}
            className="
              w-full px-4 py-3 rounded-xl
              bg-gray-700 text-white placeholder-gray-400
              border border-gray-600 focus:border-blue-500
              focus:outline-none focus:ring-2 focus:ring-blue-500/20
              transition-all duration-150
              disabled:opacity-50 disabled:cursor-not-allowed
              resize-none
            "
            rows={3}
            aria-label="Open-ended response"
          />
        </div>
      )}
      
      {/* Submit button for multi-select and when there's input */}
      {showSubmitButton && canSubmit && (
        <div className="pt-3">
          <button
            onClick={handleSubmit}
            disabled={disabled || isProcessing}
            className="
              w-full px-4 py-3 rounded-xl font-medium text-white
              bg-blue-600 hover:bg-blue-700 active:scale-[0.98]
              transition-all duration-150 ease-out
              btn-interactive focus-ring
              disabled:opacity-50 disabled:cursor-not-allowed
              shadow-lg
            "
          >
            {isProcessing ? 'Processing...' : 
             shouldAllowMultiple && selectedOptions.length > 0 ? 
               `Submit ${selectedOptions.length} selection${selectedOptions.length !== 1 ? 's' : ''}${openTextValue.trim() ? ' + comment' : ''}` :
               openTextValue.trim() && selectedOptions.length === 0 ?
                 'Submit your answer' :
                 'Continue'
            }
          </button>
        </div>
      )}
      
      {/* Loading state for single select */}
      {!shouldAllowMultiple && isProcessing && (
        <div className="flex items-center justify-center pt-2">
          <div className="loading-dots">
            <div className="dot"></div>
            <div className="dot"></div>
            <div className="dot"></div>
          </div>
        </div>
      )}
    </div>
  );
};

export default OptionGroup;
</file>

<file path=".env.local.example">
# Chat VRD Environment Configuration
# Copy this file to .env.local and fill in your actual values

# Google Gemini API Key (required)
# Get your key from: https://ai.google.dev/
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_API_KEY_BACKUP_1=your_backup_key_1
GEMINI_API_KEY_BACKUP_2=your_backup_key_2

# Perplexity API Key (required for thumbs down feedback)
# Get your key from: https://www.perplexity.ai/settings/api
# NOTE: This should be stored in Vercel environment variables, NOT with VITE_ prefix
# It's handled server-side by the /api/perplexity serverless function
PERPLEXITY_API_KEY=your_perplexity_api_key_here

# Supabase Configuration (required for chat history)
# These are from your Supabase project dashboard
# Note: VITE_ prefix is required for Vite to expose these in the browser
VITE_SUPABASE_URL=https://tlbxbwpqgzrqkhidklbm.supabase.co
VITE_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InRsYnhid3BxZ3pycWtoaWRrbGJtIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTgyODkxMzYsImV4cCI6MjA3Mzg2NTEzNn0.1MnGqA7OrG7GAFCHGUUjOxJfblys9uk3V1Xeu0WXGmU

# Optional: Additional configuration
# NODE_ENV=development
</file>

<file path="src/components/EnhancedChatMessage.tsx">
import React, { useMemo, useCallback } from 'react';
import ReactMarkdown from 'react-markdown';
import remarkGfm from 'remark-gfm';
import { 
  HandThumbUpIcon, 
  HandThumbDownIcon, 
  DocumentDuplicateIcon,
  SpeakerWaveIcon,
  ArrowPathIcon 
} from '@heroicons/react/24/outline';
import { UIMessage } from '../types';
import { classifyMessage, stripMarkdownForTTS, MCQOption, generateDefaultMCQOptions, extractMCQOptions } from '../utils/messageClassifier';
import OptionGroup from './OptionGroup';

interface EnhancedChatMessageProps {
  message: UIMessage;
  onOptionSelect?: (option: MCQOption) => void;
  onThumbsDown?: (messageId: string) => void;
  onCopy?: (text: string) => void;
  onSpeak?: (text: string) => void;
  onRetry?: (messageId: string) => void;
  showActions?: boolean;
}

interface MessageActionButtonProps {
  icon: React.ComponentType<{ className?: string }>;
  label: string;
  onClick: () => void;
  variant?: 'default' | 'danger';
}

const MessageActionButton: React.FC<MessageActionButtonProps> = ({ 
  icon: Icon, 
  label, 
  onClick, 
  variant = 'default' 
}) => {
  return (
    <button
      onClick={(e: React.MouseEvent<HTMLButtonElement>) => {
        e.stopPropagation(); // Prevent event bubbling
        console.log('[DEBUG] MessageActionButton clicked, label:', label);
        onClick();
      }}
      className={`
        p-2 rounded-lg transition-all duration-150
        ${variant === 'danger' 
          ? 'text-red-400 hover:text-red-300 hover:bg-red-900/20' 
          : 'text-gray-400 hover:text-white hover:bg-gray-700/50'
        }
        focus-ring btn-interactive
      `}
      aria-label={label}
      title={label}
    >
      <Icon className="w-4 h-4" />
    </button>
  );
};

const EnhancedChatMessage: React.FC<EnhancedChatMessageProps> = ({
  message,
  onOptionSelect,
  onThumbsDown,
  onCopy,
  onSpeak,
  onRetry,
  showActions = true
}) => {
  const isUser = message.role === 'user';
  const isStreaming = message.isStreaming;

  // Classify the message to determine rendering approach
  const classifiedMessage = useMemo(() => {
    return !isUser ? classifyMessage(message.text) : { type: 'text' as const, originalText: message.text };
  }, [message.text, isUser]);

  // Prepare text for TTS
  const ttsText = useMemo(() => {
    return stripMarkdownForTTS(message.text);
  }, [message.text]);

  const handleOptionSelect = useCallback((option: MCQOption) => {
    if (onOptionSelect) {
      onOptionSelect(option);
    }
  }, [onOptionSelect]);

  const handleCopy = useCallback(() => {
    if (onCopy) {
      onCopy(message.text);
    }
  }, [onCopy, message.text]);

  const handleSpeak = useCallback(() => {
    if (onSpeak) {
      onSpeak(ttsText);
    }
  }, [onSpeak, ttsText]);

  const handleThumbsDown = useCallback(() => {
    console.log('[DEBUG] EnhancedChatMessage handleThumbsDown called');
    console.log('[DEBUG] onThumbsDown prop:', onThumbsDown);
    console.log('[DEBUG] message.id:', message.id);
    if (onThumbsDown) {
      onThumbsDown(message.id);
    } else {
      console.warn('[DEBUG] onThumbsDown prop is undefined');
    }
  }, [onThumbsDown, message.id]);

  const handleRetry = useCallback(() => {
    if (onRetry) {
      onRetry(message.id);
    }
  }, [onRetry, message.id]);

  // Custom markdown renderers for better TTS compatibility
  const markdownComponents = {
    // Render code blocks as simple text for TTS
    code({ children }: { children: React.ReactNode }) {
      return <code className="bg-gray-800 px-1 rounded text-sm">{children}</code>;
    },
    
    // Handle images with alt text
    img({ alt, src }: { alt?: string; src?: string }) {
      return (
        <span className="inline-block text-gray-400 text-sm">
          [Image: {alt || 'No description'}]
        </span>
      );
    },
    
    // Style headers
    h1: ({ children }: { children: React.ReactNode }) => (
      <h1 className="text-xl font-bold mb-2 text-white">{children}</h1>
    ),
    h2: ({ children }: { children: React.ReactNode }) => (
      <h2 className="text-lg font-bold mb-2 text-white">{children}</h2>
    ),
    h3: ({ children }: { children: React.ReactNode }) => (
      <h3 className="text-base font-bold mb-1 text-white">{children}</h3>
    ),
    
    // Style lists
    ul: ({ children }: { children: React.ReactNode }) => (
      <ul className="list-disc list-inside space-y-1 mb-2">{children}</ul>
    ),
    ol: ({ children }: { children: React.ReactNode }) => (
      <ol className="list-decimal list-inside space-y-1 mb-2">{children}</ol>
    ),
    
    // Style links
    a: ({ children, href }: { children: React.ReactNode; href?: string }) => (
      <a 
        href={href} 
        className="text-blue-400 hover:text-blue-300 underline"
        target="_blank"
        rel="noopener noreferrer"
      >
        {children}
      </a>
    ),
    
    // Style strong/bold text
    strong: ({ children }: { children: React.ReactNode }) => (
      <strong className="font-bold text-white">{children}</strong>
    ),
    
    // Style emphasis/italic text
    em: ({ children }: { children: React.ReactNode }) => (
      <em className="italic text-white/90">{children}</em>
    ),
    
    // Style paragraphs
    p: ({ children }: { children: React.ReactNode }) => (
      <p className="mb-2 last:mb-0 text-white">{children}</p>
    )
  };

  return (
    <div 
      className={`flex ${isUser ? 'justify-end' : 'justify-start'} mb-4 animate-slide-up`}
      role="article"
      aria-label={`${isUser ? 'User' : 'Assistant'} message`}
    >
      <div className={`
        max-w-[85%] sm:max-w-[75%] 
        ${isUser 
          ? 'gradient-user rounded-tl-xl rounded-tr-xl rounded-bl-xl text-white' 
          : 'bg-gray-800 rounded-tr-xl rounded-tl-xl rounded-br-xl text-white'
        }
        px-4 py-3 shadow-lg
        ${isStreaming ? 'animate-glow-pulse' : ''}
      `}>
        {/* Message Content */}
        <div className="space-y-2">
          {isUser ? (
            // User messages: simple text rendering
            <div className="whitespace-pre-wrap break-words">
              {message.text}
            </div>
          ) : (
            // All assistant messages get MCQ options by default
            <div>
              <div className="mb-2">
                <div 
                  className="prose prose-invert prose-sm max-w-none text-white"
                  aria-live={isStreaming ? 'polite' : undefined}
                >
                  {console.log('[DEBUG] Rendering assistant message text:', message.text)}
                  {console.log('[DEBUG] Text contains asterisks:', message.text.includes('*'))}
                  <ReactMarkdown
                    remarkPlugins={[remarkGfm]}
                    components={markdownComponents}
                  >
                    {message.text}
                  </ReactMarkdown>
                </div>
              </div>
              
              {!isStreaming && message.showOptions === true && (
                <OptionGroup
                  options={generateDefaultMCQOptions(message.text)}
                  onSelect={handleOptionSelect}
                  disabled={!onOptionSelect}
                />
              )}
            </div>
          )}

          {/* Streaming indicator */}
          {isStreaming && (
            <div className="flex items-center space-x-2 pt-2">
              <div className="loading-dots">
                <div className="dot"></div>
                <div className="dot"></div>
                <div className="dot"></div>
              </div>
              <span className="text-xs text-white/60">Generating...</span>
            </div>
          )}
        </div>

        {/* Message Actions (only for assistant messages) */}
        {!isUser && !isStreaming && showActions && (
          <div className="flex items-center justify-end space-x-1 mt-3 pt-2 border-t border-gray-700/50">
            {onCopy && (
              <MessageActionButton
                icon={DocumentDuplicateIcon}
                label="Copy message"
                onClick={handleCopy}
              />
            )}
            
            {onSpeak && (
              <MessageActionButton
                icon={SpeakerWaveIcon}
                label="Read aloud"
                onClick={handleSpeak}
              />
            )}
            
            {onRetry && (
              <MessageActionButton
                icon={ArrowPathIcon}
                label="Regenerate response"
                onClick={handleRetry}
              />
            )}
            
            <MessageActionButton
              icon={HandThumbUpIcon}
              label="Good response"
              onClick={() => {}} // TODO: Implement thumbs up
            />
            
            {onThumbsDown && (
              <MessageActionButton
                icon={HandThumbDownIcon}
                label="Improve response"
                onClick={handleThumbsDown}
                variant="danger"
              />
            )}
          </div>
        )}

        {/* Attachments (if any) */}
        {message.attachments && message.attachments.length > 0 && (
          <div className="mt-3 pt-2 border-t border-gray-700/50">
            <div className="flex flex-wrap gap-2">
              {message.attachments.map((attachment, index) => (
                <div
                  key={index}
                  className="text-xs bg-gray-700/50 px-2 py-1 rounded"
                  title={attachment.name}
                >
                  📎 {attachment.name}
                </div>
              ))}
            </div>
          </div>
        )}
      </div>
    </div>
  );
};

export default EnhancedChatMessage;
</file>

<file path="package.json">
{
  "name": "kijko-video-brief-assistant",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview"
  },
  "dependencies": {
    "@google/genai": "^1.16.0",
    "@google/generative-ai": "^0.24.1",
    "@heroicons/react": "^2.2.0",
    "@hookform/resolvers": "^5.2.2",
    "@react-pdf/renderer": "^4.3.1",
    "@supabase/supabase-js": "^2.57.4",
    "@types/prismjs": "^1.26.5",
    "@types/react-router-dom": "^5.3.3",
    "html2canvas": "^1.4.1",
    "idb-keyval": "^6.2.2",
    "jspdf": "^3.0.3",
    "lucide-react": "^0.544.0",
    "prismjs": "^1.30.0",
    "react": "^19.1.1",
    "react-dom": "^19.1.1",
    "react-hook-form": "^7.63.0",
    "react-markdown": "^10.1.0",
    "react-router-dom": "^7.9.1",
    "react-simple-code-editor": "^0.14.1",
    "remark-gfm": "^4.0.1",
    "tailwindcss-animate": "^1.0.7",
    "turndown": "^7.2.1",
    "zod": "^4.1.11"
  },
  "devDependencies": {
    "@types/node": "^22.14.0",
    "typescript": "~5.8.2",
    "vite": "^6.2.0"
  }
}
</file>

<file path="src/components/ChatWindow.tsx">
import React, { useState, useEffect, useCallback, useRef } from 'react';
import { Chat } from '@google/genai';
import { ChatInput } from './ChatInput';
import EnhancedChatMessage from './EnhancedChatMessage';
import { UIMessage, Attachment } from '../types';
import { startKijkoChat, sendMessageToKijkoStream } from '../services/geminiService';
import { perplexityService } from '../services/perplexityService';
import { supabaseService } from '../services/supabaseService';
import { useTextToSpeech } from '../hooks/useTextToSpeech';
import { useSpeechToText } from '../hooks/useSpeechToText';
import { useGeminiLive } from '../hooks/useGeminiLive';
import { MCQOption, stripMarkdownForTTS } from '../utils/messageClassifier';
import { KIJKO_SYSTEM_PROMPT } from '../constants';
import { useChat } from '../contexts/ChatContext';
import { useSettings } from '../contexts/SettingsContext';
import { ProgressIndicator } from './ProgressIndicator';
import { useProgress } from '../hooks/useProgress';
import { DocumentExporter } from './DocumentExporter';

interface ChatWindowProps {
  isTtsEnabled: boolean;
  isSpeaking: boolean;
  speak: (text: string) => void;
  stopTts: () => void;
}

export const ChatWindow: React.FC<ChatWindowProps> = ({ 
  isTtsEnabled, 
  isSpeaking, 
  speak, 
  stopTts 
}) => {
  const { currentChatId, setCurrentChatId, createNewChat, loadChatSessions } = useChat();
  const { settings } = useSettings();
  const [chat, setChat] = useState<Chat | null>(null);
  const [messages, setMessages] = useState<UIMessage[]>([]);
  const [isLoading, setIsLoading] = useState(false);
  const [loadingMessages, setLoadingMessages] = useState(false);
  const [currentLiveMessageId, setCurrentLiveMessageId] = useState<string | null>(null);
  const { isListening, transcript, startListening, stopListening, setTranscript, isSttSupported } = useSpeechToText();

  // Gemini Live integration
  const isGeminiLiveMode = settings.selectedModel === 'gemini-live-2.5-flash-preview-native-audio-09-2025';
  const geminiLiveApiKey = (import.meta.env.VITE_GEMINI_API_KEY as string) || (import.meta.env.VITE_API_KEY as string) || '';
  const {
    isConnected: isLiveConnected,
    isListening: isLiveListening,
    llmResponse: liveLlmResponse,
    startListening: startGeminiLive,
    stopListening: stopGeminiLive,
    sendText: sendGeminiLiveText,
    isSupported: isGeminiLiveSupported,
  } = useGeminiLive(geminiLiveApiKey, {
    systemPrompt: settings.systemPrompt,
  });
  
  // Progress tracking
  const {
    currentStep,
    totalSteps,
    currentStepLabel,
    nextStepLabel,
    percentage,
    isVisible: isProgressVisible,
    updateProgressByContent,
    goToNextStep,
    resetProgress
  } = useProgress();
  
  // Auto-scroll refs and constants
  const SCROLL_THRESHOLD = 100;
  const scrollContainerRef = useRef<HTMLDivElement | null>(null);
  const bottomAnchorRef = useRef<HTMLDivElement | null>(null);
  const userWasNearBottomRef = useRef(true);
  
  // Check if user is near bottom (within threshold)
  const isUserNearBottom = useCallback(() => {
    const container = scrollContainerRef.current;
    if (!container) return true; // Default to true for initial load
    const distanceFromBottom = container.scrollHeight - container.scrollTop - container.clientHeight;
    return distanceFromBottom < SCROLL_THRESHOLD;
  }, []);

  // Track scroll position before messages change
  useEffect(() => {
    userWasNearBottomRef.current = isUserNearBottom();
  }, [messages.length, isUserNearBottom]);
  
  // Auto-scroll after new messages or content updates
  useEffect(() => {
    // Only scroll if user was previously near bottom
    if (userWasNearBottomRef.current && bottomAnchorRef.current) {
      // Small delay to ensure DOM updates are complete
      requestAnimationFrame(() => {
        bottomAnchorRef.current?.scrollIntoView({ behavior: 'smooth', block: 'end' });
      });
    }
  }, [messages, isLoading]); // Trigger on messages change and loading state
  
  // Initialize chat and session
  useEffect(() => {
    const initializeChat = async () => {
      const newChat = startKijkoChat(settings.selectedModel, settings.systemPrompt);
      setChat(newChat);

      // If no current chat ID, create a new session
      if (!currentChatId && supabaseService.isAvailable()) {
        try {
          let user = await supabaseService.getCurrentUser();
          if (!user) {
            user = await supabaseService.signInAnonymously();
          }

          const newSessionId = await createNewChat();
          if (newSessionId) {
            setCurrentChatId(newSessionId);
            resetProgress(); // Reset progress for new chat
            
            // Create welcome message and save it immediately
            const welcomeMessage: UIMessage = {
              id: Date.now().toString(),
              role: 'model',
              text: "Hello! I'm Kijko, your video brief assistant. I'll help you create a comprehensive production plan for your video project. To get started, could you tell me about your video idea? Feel free to share as much or as little as you have in mind, and we'll build from there.",
              attachments: [],
              isStreaming: false,
              showOptions: false, // Don't show MCQ buttons on welcome message
            };
            
            setMessages([welcomeMessage]);
            // Save using the new session ID directly (fixes race condition)
            await supabaseService.addMessage(newSessionId, welcomeMessage.text, 'assistant');
            await loadChatSessions(); // Refresh the sidebar
          }
        } catch (error) {
          console.error('Error initializing chat session:', error);
          // Fallback to showing welcome message without saving
          const welcomeMessage: UIMessage = {
            id: Date.now().toString(),
            role: 'model',
            text: "Hello! I'm Kijko, your video brief assistant. I'll help you create a comprehensive production plan for your video project. To get started, could you tell me about your video idea? Feel free to share as much or as little as you have in mind, and we'll build from there.",
            attachments: [],
            isStreaming: false,
            showOptions: false, // Don't show MCQ buttons on welcome message
          };
          setMessages([welcomeMessage]);
        }
      }
    };

    initializeChat();
  }, [settings.selectedModel, settings.systemPrompt]);

  // Load messages when currentChatId changes
  useEffect(() => {
    const loadMessages = async () => {
      if (!currentChatId || !supabaseService.isAvailable()) {
        // If no session ID, show welcome message
        if (!currentChatId) {
          const welcomeMessage: UIMessage = {
            id: Date.now().toString(),
            role: 'model',
            text: "Hello! I'm Kijko, your video brief assistant. I'll help you create a comprehensive production plan for your video project. To get started, could you tell me about your video idea? Feel free to share as much or as little as you have in mind, and we'll build from there.",
            attachments: [],
            isStreaming: false,
            showOptions: false, // Don't show MCQ buttons on welcome message
          };
          setMessages([welcomeMessage]);
        }
        return;
      }

      setLoadingMessages(true);
      try {
        const supabaseMessages = await supabaseService.getMessages(currentChatId);
        const uiMessages: UIMessage[] = supabaseMessages.map((msg, index) => ({
          id: msg.id,
          role: msg.role === 'user' ? 'user' : 'model',
          text: msg.content,
          attachments: [],
          isStreaming: false,
          // First message should never have options, subsequent assistant messages should
          showOptions: msg.role === 'assistant' && index > 0 ? true : false,
        }));
        
        setMessages(uiMessages);
      } catch (error) {
        console.error('Failed to load messages:', error);
        // Fallback to welcome message
        const welcomeMessage: UIMessage = {
          id: Date.now().toString(),
          role: 'model',
          text: "Hello! I'm Kijko, your video brief assistant.",
          attachments: [],
          isStreaming: false,
          showOptions: false, // Don't show MCQ buttons on welcome message
        };
        setMessages([welcomeMessage]);
      } finally {
        setLoadingMessages(false);
      }
    };

    if (currentChatId) {
      loadMessages();
    }
  }, [currentChatId]);

  // Handle live response updates
  useEffect(() => {
    if (isGeminiLiveMode && currentLiveMessageId && liveLlmResponse) {
      setMessages(prev => prev.map(msg => 
        msg.id === currentLiveMessageId 
          ? { ...msg, text: liveLlmResponse, isStreaming: liveLlmResponse === '' }
          : msg
      ));
    }
  }, [isGeminiLiveMode, currentLiveMessageId, liveLlmResponse]);

  const handleSendMessage = useCallback(async (text: string, attachments: Attachment[]) => {
    if (!text.trim() && attachments.length === 0) return;
    if (!chat) return;

    stopTts();
    if (isListening) {
      stopListening();
    }
    
    const userMessage: UIMessage = {
      id: Date.now().toString(),
      role: 'user',
      text,
      attachments,
    };
    setMessages(prev => [...prev, userMessage]);
    setIsLoading(true);
    setTranscript('');

    const modelMessageId = (Date.now() + 1).toString();
    const modelMessage: UIMessage = {
      id: modelMessageId,
      role: 'model',
      text: '',
      attachments: [],
      isStreaming: true,
      showOptions: true, // Enable MCQ options for regular assistant messages
    };
    setMessages(prev => [...prev, modelMessage]);

    try {
      if (isGeminiLiveMode) {
        // Live mode: send text into the live session
        sendGeminiLiveText(text);
        setCurrentLiveMessageId(modelMessageId);
        // Response updates will be handled by the useEffect above
      } else {
        const stream = await sendMessageToKijkoStream(chat, text, attachments, 0, settings.selectedModel, settings.systemPrompt);
        let fullResponse = '';
        for await (const chunk of stream) {
          fullResponse += chunk.text;
          setMessages(prev => prev.map(msg => 
            msg.id === modelMessageId ? { ...msg, text: fullResponse } : msg
          ));
        }

        setMessages(prev => prev.map(msg => 
          msg.id === modelMessageId ? { ...msg, isStreaming: false } : msg
        ));

        // Update progress based on assistant's response content
        updateProgressByContent(fullResponse);

        if (isTtsEnabled) {
          speak(fullResponse);
        }
        
        // Save messages to Supabase if available
        if (currentChatId && supabaseService.isAvailable()) {
          await supabaseService.addMessage(currentChatId, text, 'user');
          await supabaseService.addMessage(currentChatId, fullResponse, 'assistant');
        }
      }

    } catch (error) {
      console.error("Error sending message:", error);
      const errorMessage = 'Sorry, I encountered an error. Could you please try again?';
      setMessages(prev => prev.map(msg => 
        msg.id === modelMessageId ? { ...msg, text: errorMessage, isStreaming: false } : msg
      ));
    } finally {
      setIsLoading(false);
    }
  }, [chat, isTtsEnabled, speak, stopTts, isListening, stopListening, setTranscript, currentChatId, settings.selectedModel, settings.systemPrompt, isGeminiLiveMode, sendGeminiLiveText]);

  // Handle MCQ option selection
  const handleOptionSelect = useCallback(async (option: MCQOption) => {
    if (!chat) return;
    
    // Only send the formatted "I choose: X" message, not both
    // This prevents double submission
    await handleSendMessage(`I choose: ${option.text}`, []);
  }, [chat, handleSendMessage]);

  // Handle thumbs down feedback with Perplexity improvement
  const handleThumbsDown = useCallback(async (messageId: string) => {
    console.log('[DEBUG] handleThumbsDown called with messageId:', messageId);
    console.log('[DEBUG] perplexityService.isAvailable():', perplexityService.isAvailable());
    
    if (!perplexityService.isAvailable()) {
      console.warn('Perplexity service not available for feedback improvement');
      return;
    }

    const messageToImprove = messages.find(msg => msg.id === messageId);
    if (!messageToImprove) return;

    const messageIndex = messages.findIndex(msg => msg.id === messageId);
    const userMessage = messageIndex > 0 ? messages[messageIndex - 1] : null;
    
    if (!userMessage || userMessage.role !== 'user') {
      console.error('Could not find user message for improvement');
      return;
    }

    try {
      setIsLoading(true);
      
      const improvedResponse = await perplexityService.getImprovedResponse({
        systemPrompt: KIJKO_SYSTEM_PROMPT,
        userQuestion: userMessage.text,
        originalResponse: messageToImprove.text
      });

      const improvedText = `${improvedResponse}\n\n*[This response was improved using Perplexity AI]*`;
      console.log('[DEBUG] Setting improved text:', improvedText);
      console.log('[DEBUG] Text includes asterisks:', improvedText.includes('*'));
      setMessages(prev => prev.map(msg => 
        msg.id === messageId 
          ? { ...msg, text: improvedText }
          : msg
      ));

      if (isTtsEnabled) {
        speak(stripMarkdownForTTS(improvedResponse));
      }

    } catch (error) {
      console.error('Error improving response:', error);
      setMessages(prev => prev.map(msg => 
        msg.id === messageId 
          ? { ...msg, text: `${msg.text}\n\n*[Sorry, could not improve this response. Please try asking the question differently.]*` }
          : msg
      ));
    } finally {
      setIsLoading(false);
    }
  }, [messages, isTtsEnabled, speak]);

  // Handle copy message to clipboard
  const handleCopy = useCallback(async (text: string) => {
    try {
      await navigator.clipboard.writeText(text);
      console.log('Message copied to clipboard');
    } catch (error) {
      console.error('Failed to copy message:', error);
    }
  }, []);

  // Handle speak message with TTS
  const handleSpeak = useCallback((text: string) => {
    const cleanText = stripMarkdownForTTS(text);
    speak(cleanText);
  }, [speak]);

  // Handle retry message generation
  const handleRetry = useCallback(async (messageId: string) => {
    const messageIndex = messages.findIndex(msg => msg.id === messageId);
    const userMessage = messageIndex > 0 ? messages[messageIndex - 1] : null;
    
    if (!userMessage || userMessage.role !== 'user') {
      console.error('Could not find user message for retry');
      return;
    }

    setMessages(prev => prev.filter(msg => msg.id !== messageId));
    await handleSendMessage(userMessage.text, []);
  }, [messages, handleSendMessage]);

  if (loadingMessages) {
    return (
      <div className="flex-1 flex items-center justify-center">
        <div className="text-center">
          <div className="loading-dots mb-4">
            <div className="dot"></div>
            <div className="dot"></div>
            <div className="dot"></div>
          </div>
          <p className="text-gray-400">Loading conversation...</p>
        </div>
      </div>
    );
  }

  return (
    <>
      {/* Progress Indicator */}
      <ProgressIndicator
        currentStep={currentStep}
        totalSteps={totalSteps}
        currentStepLabel={currentStepLabel}
        nextStepLabel={nextStepLabel}
        percentage={percentage}
        isVisible={isProgressVisible}
      />
      
      {/* Chat Messages */}
      <div className="flex-1 overflow-hidden">
        <div 
          ref={scrollContainerRef}
          className="h-full overflow-y-auto p-4 space-y-4"
          onScroll={() => {
            // Update the scroll position tracking when user manually scrolls
            userWasNearBottomRef.current = isUserNearBottom();
          }}
        >
          {/* Show export button when VRD process is complete */}
          {percentage >= 100 && messages.length > 10 && (
            <div className="flex justify-center mb-6 p-4 bg-gray-800/50 rounded-lg">
              <div className="text-center">
                <p className="text-green-400 mb-3">✅ Your VRD is complete!</p>
                <DocumentExporter 
                  messages={messages}
                  title="Video Requirements Document"
                  onExportComplete={(docId) => {
                    console.log('Document saved:', docId);
                  }}
                />
              </div>
            </div>
          )}
          
          {messages.map((message) => {
            console.log('[DEBUG] Rendering message with onThumbsDown:', handleThumbsDown);
            return (
              <EnhancedChatMessage
                key={message.id}
                message={message}
                onOptionSelect={handleOptionSelect}
                onThumbsDown={handleThumbsDown}
                onCopy={handleCopy}
                onSpeak={handleSpeak}
                onRetry={handleRetry}
                showActions={!isLoading}
              />
            );
          })}
          
          {/* Loading indicator when processing */}
          {isLoading && (
            <div className="flex justify-start mb-4">
              <div className="bg-gray-800 rounded-tr-xl rounded-tl-xl rounded-br-xl px-4 py-3 animate-glow-pulse">
                <div className="loading-dots">
                  <div className="dot"></div>
                  <div className="dot"></div>
                  <div className="dot"></div>
                </div>
              </div>
            </div>
          )}
          
          {/* Bottom anchor for auto-scroll */}
          <div ref={bottomAnchorRef} aria-hidden="true" />
        </div>
      </div>
      
      <ChatInput 
        onSendMessage={handleSendMessage} 
        isLoading={isLoading}
        isListening={isListening}
        startListening={startListening}
        stopListening={stopListening}
        transcript={transcript}
        isSttSupported={isSttSupported}
        // Gemini Live props
        isGeminiLiveMode={isGeminiLiveMode}
        startGeminiLive={startGeminiLive}
        stopGeminiLive={stopGeminiLive}
        isGeminiLiveListening={isLiveListening}
        isGeminiLiveSupported={isGeminiLiveSupported}
      />
    </>
  );
};
</file>

<file path="src/utils/messageClassifier.ts">
export interface MCQOption {
  label: string;
  text: string;
  fullText: string;
  followupQuestionId?: string; // ID of next question if this option is selected
}

export interface QuestionStep {
  id: string;
  prompt: string;
  options: MCQOption[];
  isConditional?: boolean; // Whether this question depends on a previous answer
  parentOptionId?: string; // Which option from parent question triggers this
}

export interface ClassifiedMessage {
  type: 'text' | 'mcq';
  stem?: string;
  options?: MCQOption[];
  originalText: string;
}

/**
 * Classifies a message to determine if it's a multiple choice question
 * Returns message type with parsed content for MCQ rendering
 */
export function classifyMessage(messageText: string): ClassifiedMessage {
  const text = messageText.trim();
  
  // Quick checks for MCQ indicators
  const hasQuestionMark = text.includes('?');
  
  // Additional heuristics for MCQ detection
  const mcqKeywords = [
    'choose the', 'select the', 'which of the following',
    'what is the best', 'which option', 'pick the',
    'the correct answer', 'which statement',
    'rate your', 'scale of', 'on a scale', 'how would you rate', 'please rate', 'could you rate'
  ];
  
  const hasKeywords = mcqKeywords.some(keyword => 
    text.toLowerCase().includes(keyword.toLowerCase())
  );
  
  // Additional pattern detection for scale/rating questions
  const hasScalePattern = /scale of \d+(-\d+)?|rate.*\d+-\d+/i.test(text);
  
  // Only try to parse options if we have MCQ indicators
  if (!hasQuestionMark || (!hasKeywords && !hasScalePattern)) {
    return {
      type: 'text',
      originalText: text
    };
  }
  
  // Normalize text to handle different bullet types and quotes
  const safeText = text
    // Replace curly/smart quotes with standard quotes
    .replace(/[‘’]/g, "'")
    .replace(/[“”]/g, '"')
    // Normalize bullets to consistent bullet point
    .replace(/[•‣◦⁃∙]/g, "•");
  
  // Robust pattern for MCQ options that handles flexible whitespace, quotes, and bullets
  const mcqBulletPattern = /^[\s\t]*[•\-*●‣][\s\t]*(\d+)[\s\t]*=[\s\t]*['"‘’“”]?(.+?)['"‘’“”]?\s*$/gmi;
  
  let options: MCQOption[] = [];
  let match: RegExpExecArray | null;
  
  // Extract all MCQ options using the robust pattern
  while ((match = mcqBulletPattern.exec(safeText)) !== null) {
    options.push({
      label: match[1], // The number (1, 5, 10, etc.)
      text: match[2].trim(), // The option text
      fullText: match[0].trim() // The full match
    });
  }
  
  // If we found enough options, return MCQ
  if (options.length >= 2) {
    // Extract the stem (question part before options)
    const firstOptionIndex = text.indexOf(options[0].fullText);
    const stem = firstOptionIndex > 0 ? text.substring(0, firstOptionIndex).trim() : text;
    
    return {
      type: 'mcq',
      stem,
      options,
      originalText: text
    };
  }
  
  // Default to text if no MCQ structure found
  return {
    type: 'text',
    originalText: text
  };
}

/**
 * Utility to strip markdown formatting for TTS
 */
export function stripMarkdownForTTS(text: string): string {
  return text
    // Remove bold/italic markers
    .replace(/\*\*([^*]+)\*\*/g, '$1')
    .replace(/\*([^*]+)\*/g, '$1')
    .replace(/__([^_]+)__/g, '$1')
    .replace(/_([^_]+)_/g, '$1')
    
    // Remove code blocks and inline code
    .replace(/```[\s\S]*?```/g, '[code block]')
    .replace(/`([^`]+)`/g, '$1')
    
    // Remove links but keep text
    .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1')
    
    // Remove headers
    .replace(/#{1,6}\s+(.+)/g, '$1')
    
    // Remove lists markers but keep content
    .replace(/^\s*[•\-*]\s+/gm, '')
    .replace(/^\s*\d+\.\s+/gm, '')
    
    // Remove images
    .replace(/!\[([^\]]*)\]\([^)]+\)/g, '$1 image')
    
    // Clean up extra whitespace
    .replace(/\n{3,}/g, '\n\n')
    .trim();
}

/**
 * Format option text for display (with proper spacing and capitalization)
 */
export function formatOptionText(text: string): string {
  return text
    .trim()
    .replace(/^\w/, (c) => c.toUpperCase()) // Capitalize first letter
    .replace(/\.$/, ''); // Remove trailing period if present
}

/**
 * Extract MCQ options that are already present in the message
 * Handles various formats like "1 = 'text'", "A) text", "1. text", etc.
 */
export function extractMCQOptions(messageText: string): MCQOption[] {
  // Normalize line endings first
  let normalizedText = messageText.replace(/\r\n|\r/g, '\n');

  // Helper to sanitize each line for robust matching across browsers
  const sanitize = (line: string) => {
    return line
      // convert various unicode spaces to regular space
      .replace(/[\u00A0\u1680\u180E\u2000-\u200B\u202F\u205F\u3000]/g, ' ')
      // normalize smart quotes to straight quotes
      .replace(/[‘’‚‛❛❟⸂⸃＇]/g, "'")
      .replace(/[“”„‟❝❞〝〞＂]/g, '"')
      // remove leading bullets/dashes
      .replace(/^[•–—\-▪●*]+\s*/, '')
      // collapse spaces
      .replace(/\s+/g, ' ')
      .trim();
  };

  const options: MCQOption[] = [];
  const lines = normalizedText.split('\n');

  // CRITICAL: Find the main question line first (ends with ?)
  const questionLineIndex = lines.findIndex(line => line.trim().endsWith('?'));
  const startIndex = questionLineIndex >= 0 ? questionLineIndex + 1 : 0;

  // 1) Try explicit numbered options: 1 = 'text' | 1. text | 1: text
  const eqPattern = /^(\d+)\s*=\s*["']([^"']+)["']\s*$/;
  const dotPattern = /^(\d+)[\.:]\s+(.+)$/;
  
  // 2) Try bullet point options with text content (most common format)
  const bulletPattern = /^\s*[•\-*]\s+(.+)$/;
  
  // Only process lines AFTER the main question
  for (let i = startIndex; i < lines.length; i++) {
    const raw = lines[i].trim();
    if (!raw) continue; // Skip empty lines
    
    const line = sanitize(raw);
    
    // Try numbered format: 1 = 'text'
    let m = eqPattern.exec(line);
    if (m) {
      options.push({ label: m[1], text: m[2].trim(), fullText: line });
      continue;
    }
    
    // Try numbered format: 1. text or 1: text
    m = dotPattern.exec(line);
    if (m) {
      options.push({ label: m[1], text: m[2].trim(), fullText: line });
      continue;
    }
    
    // Try bullet point format
    m = bulletPattern.exec(raw);
    if (m && m[1].trim().length > 3 && !m[1].trim().endsWith('?')) {
      options.push({ 
        label: String(options.length + 1), 
        text: m[1].trim(), 
        fullText: m[1].trim() 
      });
      continue;
    }
    
    // FALLBACK: If it's a non-empty line after the question and not already processed,
    // treat it as an option (handles mixed formats like "Entertain" without bullet)
    // BUT exclude lines that are clearly explanatory text
    const isLikelyExplanation = 
      raw.toLowerCase().includes('your answer') ||
      raw.toLowerCase().includes('this helps') ||
      raw.toLowerCase().includes('please') ||
      raw.toLowerCase().includes('feel free') ||
      raw.toLowerCase().includes('let me know') ||
      raw.toLowerCase().includes('helps me') ||
      raw.length > 100; // Long lines are probably explanations, not options
    
    if (raw.length > 2 && !raw.endsWith('?') && !raw.includes(':') && !isLikelyExplanation) {
      options.push({ 
        label: String(options.length + 1), 
        text: raw, 
        fullText: raw 
      });
    }
  }

  // 2) If still nothing, detect scale prompts (rate/scale X-Y) and generate range
  if (options.length < 2) {
    const scaleMatch = normalizedText
      .replace(/[–—]/g, '-') // normalize dashes
      .match(/(?:rate|scale)[^\d]*(\d+)\s*[-to]{1,3}\s*(\d+)/i);
    if (scaleMatch) {
      const start = parseInt(scaleMatch[1], 10);
      const end = parseInt(scaleMatch[2], 10);
      if (!isNaN(start) && !isNaN(end) && end >= start) {
        for (let i = start; i <= end; i++) {
          options.push({ label: String(i), text: String(i), fullText: String(i) });
        }
      }
    }
  }

  return options.length >= 2 ? options : [];
}

/**
 * Generate default MCQ options based on message content
 * This ensures ALL assistant messages have interactive options
 */
/**
 * Extract explicit options from agent questions
 * Handles patterns like "A, B, C, or D" or "Are you looking to X, Y, Z?"
 */
function extractExplicitChoices(text: string): string[] {
  const choices: string[] = [];
  const lines = text.split('\n');
  
  // CRITICAL: Find the main question first (line ending with ?)
  // Everything before this is likely context/question, not an option
  const questionLineIndex = lines.findIndex(line => line.trim().endsWith('?'));
  const startIndex = questionLineIndex >= 0 ? questionLineIndex + 1 : 0;
  
  // Step 1: Extract from bullet points and numbered lists
  // Only process lines AFTER the main question
  for (let i = startIndex; i < lines.length; i++) {
    const line = lines[i];
    // Match unordered bullet points (-, *, •)
    let match = line.match(/^\s*[-*•]\s+(.*\S.*)$/);
    if (match) {
      let option = match[1].trim();
      // Clean up question format "Are they general cat lovers?" -> "General cat lovers"
      option = option.replace(/^(?:are they|do they have?|what)\s+/i, '').replace(/\?$/, '');
      if (option.length > 0) {
        choices.push(option);
      }
    }
    
    // Match numbered lists (1., 2., etc.)
    if (!match) {
      match = line.match(/^\s*\d+[\.\)]\s+(.*\S.*)$/);
      if (match) {
        let option = match[1].trim();
        option = option.replace(/^(?:are they|do they have?|what)\s+/i, '').replace(/\?$/, '');
        if (option.length > 0) {
          choices.push(option);
        }
      }
    }
    
    // Match alphabetic lists (a., A), etc.)
    if (!match) {
      match = line.match(/^\s*[a-zA-Z][\.\)]\s+(.*\S.*)$/);
      if (match) {
        let option = match[1].trim();
        option = option.replace(/^(?:are they|do they have?|what)\s+/i, '').replace(/\?$/, '');
        if (option.length > 0) {
          choices.push(option);
        }
      }
    }
  }
  
  // Step 2: Extract from inline choices with "or" and commas
  if (choices.length === 0) {
    // Pattern: "like cute kittens, funny cat antics, or educational content"
    const inlinePattern = /(?:like|such as|including)\s+([^?]+?)(?:\?|$)/i;
    const inlineMatch = text.match(inlinePattern);
    if (inlineMatch) {
      const choicesText = inlineMatch[1];
      const parts = choicesText.split(/,\s*(?:or\s+)?|\s+or\s+/);
      for (const part of parts) {
        const cleaned = part.trim().replace(/[,.]$/, '');
        if (cleaned && cleaned.length > 2) {
          choices.push(cleaned);
        }
      }
    }
  }
  
  // Step 3: Extract from parenthetical examples (e.g., children, teens, adults)
  if (choices.length === 0) {
    const parentheticalPattern = /\(\s*e\.g\.,\s*([^)]+?)\)/i;
    const parentheticalMatch = text.match(parentheticalPattern);
    if (parentheticalMatch) {
      const exampleText = parentheticalMatch[1];
      const parts = exampleText.split(/,\s*/);
      for (const part of parts) {
        const cleaned = part.trim();
        if (cleaned && cleaned.length > 0) {
          choices.push(cleaned);
        }
      }
    }
  }
  
  // Step 4: Final attempt at simple enumeration patterns
  if (choices.length === 0) {
    const simplePattern = /(?:are you looking to|do you want to|choose from|options include)\s+([^?]+?)(?:\?|$)/i;
    const simpleMatch = text.match(simplePattern);
    if (simpleMatch) {
      const choicesText = simpleMatch[1];
      const parts = choicesText.split(/,\s*(?:or\s+)?|\s+or\s+/);
      for (const part of parts) {
        const cleaned = part.trim().replace(/^(to\s+)?/, '').replace(/[,.]$/, '');
        if (cleaned && cleaned.length > 0) {
          choices.push(cleaned);
        }
      }
    }
  }
  
  return choices.filter((c, i, arr) => arr.indexOf(c) === i); // dedupe
}

/**
 * Detect question intent and generate appropriate options
 */
function getContextualOptions(text: string): MCQOption[] {
  const lowerText = text.toLowerCase();
  
  // Video purpose questions
  if (lowerText.includes('purpose') || lowerText.includes('achieve') || 
      lowerText.includes('goal') || lowerText.includes('hope to')) {
    return [
      { label: 'A', text: 'Entertain', fullText: 'A. Entertain' },
      { label: 'B', text: 'Educate', fullText: 'B. Educate' },
      { label: 'C', text: 'Promote a product', fullText: 'C. Promote a product' },
      { label: 'D', text: 'Raise awareness', fullText: 'D. Raise awareness' },
      { label: 'E', text: 'Something else', fullText: 'E. Something else' }
    ];
  }
  
  // Yes/No questions
  if (lowerText.includes('do you') && (lowerText.includes('want') || lowerText.includes('need') || lowerText.includes('have'))) {
    return [
      { label: 'A', text: 'Yes', fullText: 'A. Yes' },
      { label: 'B', text: 'No', fullText: 'B. No' },
      { label: 'C', text: 'I\'m not sure', fullText: 'C. I\'m not sure' }
    ];
  }
  
  // Preference questions
  if (lowerText.includes('prefer') || lowerText.includes('like') || lowerText.includes('choose')) {
    return [
      { label: 'A', text: 'Option A', fullText: 'A. Option A' },
      { label: 'B', text: 'Option B', fullText: 'B. Option B' },
      { label: 'C', text: 'Neither', fullText: 'C. Neither' },
      { label: 'D', text: 'I need more information', fullText: 'D. I need more information' }
    ];
  }
  
  // Style/approach questions
  if (lowerText.includes('style') || lowerText.includes('approach') || lowerText.includes('tone')) {
    return [
      { label: 'A', text: 'Professional', fullText: 'A. Professional' },
      { label: 'B', text: 'Casual', fullText: 'B. Casual' },
      { label: 'C', text: 'Creative', fullText: 'C. Creative' },
      { label: 'D', text: 'Let\'s discuss options', fullText: 'D. Let\'s discuss options' }
    ];
  }
  
  // Audience questions
  if (lowerText.includes('audience') || lowerText.includes('target') || lowerText.includes('viewers')) {
    return [
      { label: 'A', text: 'General public', fullText: 'A. General public' },
      { label: 'B', text: 'Specific demographic', fullText: 'B. Specific demographic' },
      { label: 'C', text: 'Professionals', fullText: 'C. Professionals' },
      { label: 'D', text: 'I\'m not sure yet', fullText: 'D. I\'m not sure yet' }
    ];
  }
  
  return [];
}

/**
 * Decompose complex multi-part questions into sequential steps
 */
function decomposeMultiPartQuestion(text: string): QuestionStep[] {
  const steps: QuestionStep[] = [];
  const lowerText = text.toLowerCase();
  
  // Detect audience questions with multiple parts
  if (lowerText.includes('audience') && lowerText.includes('ideal')) {
    const lines = text.split('\n').filter(line => line.trim().startsWith('-'));
    
    if (lines.length >= 2) {
      // Step 1: General vs Specific audience
      const hasGeneralQuestion = lines.some(line => line.toLowerCase().includes('general'));
      const hasSpecificQuestion = lines.some(line => line.toLowerCase().includes('specific'));
      const hasAgeQuestion = lines.some(line => line.toLowerCase().includes('age') || line.toLowerCase().includes('children') || line.toLowerCase().includes('teen'));
      
      if (hasGeneralQuestion && hasSpecificQuestion) {
        // Create first question: audience type
        steps.push({
          id: 'audience_type',
          prompt: 'What type of audience are you targeting?',
          options: [
            { 
              label: 'A', 
              text: 'General cat lovers', 
              fullText: 'A. General cat lovers' 
            },
            { 
              label: 'B', 
              text: 'People with specific interests', 
              fullText: 'B. People with specific interests',
              followupQuestionId: 'specific_interests'
            }
          ]
        });
        
        // Create conditional follow-up for specific interests
        const interestOptions: MCQOption[] = [];
        const interestLine = lines.find(line => line.toLowerCase().includes('specific'));
        if (interestLine) {
          const interests = extractExplicitChoices(interestLine);
          if (interests.length > 0) {
            interests.forEach((interest, index) => {
              interestOptions.push({
                label: String.fromCharCode(65 + index),
                text: interest.charAt(0).toUpperCase() + interest.slice(1),
                fullText: `${String.fromCharCode(65 + index)}. ${interest.charAt(0).toUpperCase() + interest.slice(1)}`
              });
            });
          }
        }
        
        if (interestOptions.length > 0) {
          steps.push({
            id: 'specific_interests',
            prompt: 'Which specific interests?',
            options: interestOptions,
            isConditional: true,
            parentOptionId: 'B'
          });
        }
      }
      
      // Step 2: Age demographics (always ask)
      if (hasAgeQuestion) {
        const ageOptions: MCQOption[] = [];
        const ageLine = lines.find(line => line.toLowerCase().includes('age') || line.toLowerCase().includes('children'));
        if (ageLine) {
          const ageGroups = extractExplicitChoices(ageLine);
          if (ageGroups.length > 0) {
            ageGroups.forEach((group, index) => {
              ageOptions.push({
                label: String.fromCharCode(65 + index),
                text: group.charAt(0).toUpperCase() + group.slice(1),
                fullText: `${String.fromCharCode(65 + index)}. ${group.charAt(0).toUpperCase() + group.slice(1)}`
              });
            });
          } else {
            // Default age options
            ['Children', 'Teens', 'Adults', 'Families', 'Mixed audience'].forEach((group, index) => {
              ageOptions.push({
                label: String.fromCharCode(65 + index),
                text: group,
                fullText: `${String.fromCharCode(65 + index)}. ${group}`
              });
            });
          }
        }
        
        if (ageOptions.length > 0) {
          steps.push({
            id: 'age_group',
            prompt: 'What age group are you targeting?',
            options: ageOptions
          });
        }
      }
    }
  }
  
  return steps;
}

/**
 * Parse structured MCQ formats (JSON or plain-text block)
 */
function parseStructuredMCQ(messageText: string): MCQOption[] {
  // Check for JSON format: <begin>{...}<end>
  const jsonMatch = messageText.match(/<begin>\s*({[\s\S]*?})\s*<end>/i);
  if (jsonMatch) {
    try {
      const parsed = JSON.parse(jsonMatch[1]);
      if (parsed.options && Array.isArray(parsed.options)) {
        return parsed.options.map((opt: string, index: number) => ({
          label: String(index + 1),
          text: opt,
          fullText: `${index + 1}. ${opt}`
        }));
      }
    } catch (e) {
      console.error('Failed to parse JSON MCQ:', e);
    }
  }
  
  // Check for plain-text block format: QUESTION:...OPTIONS:...END_OPTIONS
  const blockMatch = messageText.match(/OPTIONS:\s*\n([\s\S]*?)END_OPTIONS/i);
  if (blockMatch) {
    const optionsText = blockMatch[1];
    const options: MCQOption[] = [];
    const lines = optionsText.split('\n').filter(line => line.trim());
    
    for (const line of lines) {
      const match = line.match(/^\s*(\d+)\s*=\s*['"]?(.+?)['"]?\s*$/);
      if (match) {
        options.push({
          label: match[1],
          text: match[2].trim(),
          fullText: `${match[1]}. ${match[2].trim()}`
        });
      }
    }
    
    if (options.length > 0) {
      return options;
    }
  }
  
  return [];
}

export function generateDefaultMCQOptions(messageText: string): MCQOption[] {
  const lowerText = messageText.toLowerCase();
  
  // FIRST: Try to parse structured formats (JSON or plain-text blocks)
  const structuredOptions = parseStructuredMCQ(messageText);
  if (structuredOptions.length > 0) {
    return structuredOptions;
  }
  
  // FALLBACK: Try to extract explicit numbered options (legacy format)
  const extractedOptions = extractMCQOptions(messageText);
  if (extractedOptions.length > 0) {
    return extractedOptions; // Options provided - ALWAYS use them
  }
  
  // ONLY check for open-ended keywords if NO options were provided
  const openEndedIndicators = [
    'what is the main reason',
    'what do you hope',
    'describe',
    'explain',
    'tell me about',
    'tell me more',
    'what are your thoughts',
    'how would you describe',
    'what made you',
    'what brings you',
    'share your',
    'elaborate on'
  ];
  
  // Only apply open-ended detection when no explicit options exist
  if (openEndedIndicators.some(indicator => lowerText.includes(indicator))) {
    return []; // No buttons for truly open-ended questions without options
  }
  
  // Check if this is a complex multi-part question that should be decomposed
  const questionSteps = decomposeMultiPartQuestion(messageText);
  if (questionSteps.length > 1) {
    // Return options for the first step only
    // The UI will need to handle the sequential flow
    const firstStep = questionSteps[0];
    return firstStep.options.map(option => ({
      ...option,
      // Add metadata to indicate this is part of a multi-step flow
      fullText: `${option.fullText} ${questionSteps.length > 1 ? '(1 of ' + questionSteps.length + ')' : ''}`
    }));
  }
  
  // Try to extract explicit choices from the question text
  const explicitChoices = extractExplicitChoices(messageText);
  if (explicitChoices.length >= 2) {
    return explicitChoices.map((choice, index) => ({
      label: String.fromCharCode(65 + index), // A, B, C, D...
      text: choice.charAt(0).toUpperCase() + choice.slice(1),
      fullText: `${String.fromCharCode(65 + index)}. ${choice.charAt(0).toUpperCase() + choice.slice(1)}`
    }));
  }
  
  // Generate contextual options based on question intent
  const contextualOptions = getContextualOptions(messageText);
  if (contextualOptions.length > 0) {
    return contextualOptions;
  }
  
  // No fallback options - if we can't determine appropriate options, show none
  return [];
}

/**
 * Export question decomposition for UI components that need to handle multi-step flows
 */
export function getQuestionSteps(messageText: string): QuestionStep[] {
  return decomposeMultiPartQuestion(messageText);
}
</file>

</files>
